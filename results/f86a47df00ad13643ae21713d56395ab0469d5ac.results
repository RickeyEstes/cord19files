In the full dataset, 19 observations were classified as having "high" trend, 42 as "medium" trend, 55 as trend "low", and 55 as "zero" (Tables 1 and 2) . For the forecasting of PEDV trends, the confusion matrix in Table 1 provides accuracy measures on the training set for a static 70-30 split of the data. Table 2 provides accuracy measures on the test dataset for the same split, with random forest, artificial neural nets, and classification trees reporting an overall accuracy of 71%, 75%, and 45% respectively. If non-tolerable errors are considered as misclassification into non-adjacent categories (e.g. high as low, high as zero, medium as zero, and vice versa), and tolerable errors considered as misclassification into adjacent categories (e.g. high as medium, medium as low, low as zero, and vice versa), then random forest had 3 non-tolerable errors and 11 tolerable ones, neural nets had 4 non-tolerable errors and 8 tolerable ones, while classification trees had 10 nontolerable errors and 20 tolerable ones. For the additional models constructed with random training and test sets (using 10-fold cross validation on the entire dataset), the summary confusion matrix in Table 3 indicates overall accuracy values of 68%, 57%, and 55% for random forest, neural nets, and classification trees respectively. Paired t-test results confirmed accuracy estimates for random forests as being different from neural nets (p = 0.02) and classification trees (p < 0.01), whereas there was no difference in accuracy estimates between neural nets and classification trees (p = 0.68). With non-tolerable errors and tolerable errors defined as before, random forest had 5 non-tolerable errors and 50 tolerable ones, neural nets had 16 non-tolerable errors and 58 tolerable ones, while classification trees had 18 non-tolerable errors and 59 tolerable ones. The sensitivity and specificity for all models are presented in Table 4 , while the boxplot of sensitivity and specificity values across 10 folds on the entire dataset is presented in Fig. 1 . The boxplot of sensitivity and specificity values indicate higher median values for the random forest model across all 10-folds, with the only exception being trends "zero" and "low" for sensitivity and specificity respectively, where neural nets had a higher median value. The variable importance plot for the random forest model is presented in Fig. 2 , while a description of variable names for the 30 explanatory variables in all classification models is provided in S- Table 1. For random forest classification, prevalence-related variables, whether current or lagged, were the driving force for the 4-week incidence trend (Fig. 2) , however, the current week's mean low temperature (i.e. ont_meanlowtemp) was also highly ranked. It appears the current week's low temperature, alongside prior and current prevalence values, determine the PEDV trend 4 weeks into the future. Time series decomposition plots for weekly PEDV incident cases and prevalence, as well as weekly low temperature, average temperature, and average humidity are available in S- Figures 2, 3, 4 , 5, and 6 respectively. Each plot shows a strong seasonality component, however, there are notable differences where the trend is concerned. For example, incident cases (S- Figure 2 ) started with a sharp trend decrease at the beginning of 2014 but then followed with a gradual decrease, while prevalence (S- Figure 3 ) had a gradual trend increase at the beginning of 2014 followed by a decrease. Both low and average temperature (S- Figures 4 and 5) show a trend increase over the study period, while average humidity (S- Figure 6 ) started with a trend decrease but then switched to a trend increase in mid-2016. Determination of long-term trend for weather variables was, however, based on little informative data (S Figures 4-6) . 