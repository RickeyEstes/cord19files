We tested our prediction using an analysis of variance (ANOVA) with the author of the article and notification of the author as the factors. As shown in Fig. 1 , the author of the article by notification of the author interaction was significant (F ¼ 6.301, p < 0.05). The public gave a higher score (M ¼ 3.39) to the algorithm's work when it was notified as the real author, but they gave a lower score (M ¼ 3.21) to the algorithm's work when the author was noted as a journalist. Although the article was written by an algorithm, evaluation was lower when the instructions stated it was a journalist's work. Meanwhile, the public gave a lower score (M ¼ 3.31) to the journalist's article when the author was noted as a journalist, but they gave a higher score (M ¼ 3.41) to the journalist's work when the author was noted as an algorithm. Thus, regardless of the real author, the public is likely to be more favorable to an algorithm's work and less favorable to a human journalist's article. H1 was supported. Based on the first study, we figured out that the public gave higher evaluation to an algorithm's work when it was noted as the real author, but they gave lower scores to an algorithm's work when the author was notified as the reverse. On the other hand, the public gave lower evaluation to the human journalist's article when the author was noted as a journalist, but they gave higher scores to the journalist's work when the author was noted as the reverse. Thus, whether quality evaluation by the public on an algorithm's work is higher than a journalist's work depends on the manipulation of author notification. To test H2, journalists' preferences for a human journalist's work over an algorithm's work, ANOVA was conducted. As shown in Fig. 2 , interaction between the author of the article and the notification of author was significant (F ¼ 8.984, p < 0.01). When the author of the article was noted as the real author, journalists reading an algorithm's article rated higher (M ¼ 3.23), but they gave a lower score (M ¼ 2.85) to an algorithm's work when the author was noted as a journalist. Journalists gave a lower score (M ¼ 3.13) to a journalist's work when the author was noted as a journalist, but they gave a higher score (M ¼ 3.33) to a journalist's work when the author was notified as an algorithm. In Study 2, we figured out that journalists gave a higher evaluation to an algorithm's work when it was noted as the real author, but they gave lower scores to an algorithm's work when the author was noted as a journalist. On the other hand, journalists gave a lower evaluation on a human journalist's article when the author was noted as a journalist, but they gave higher scores to a journalist's work when the author was noted as an algorithm. Thus, whether quality evaluation by journalists on an algorithm's work is higher than on a journalist's work depends on the manipulation of author notification. It should be noted, however, that the direction of interaction was against our hypothetical expectation. That is, regardless of the real author, journalists are more likely to be favorable to an algorithm's work and less favorable to a human journalist's article. Thus, H2 was not supported. Detailed explanation is provided in the next section. 