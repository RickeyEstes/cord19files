As a whole, hospital characteristics were nearly universally reported, with the exception of whether it was located in an urban or rural setting. As a result, researchers curious as to the kinds of patients the facility served or its geographic access would have to use mapping software (e.g., Google Maps) to find an approximate location for the facility. Similarly, indicators of overall hospital size and patient capacity, such as the number of inpatient beds, were infrequently reported; however, could be found occasionally on the hospital webpage, if one existed. The physical layout of the emergency centre itself, including the number of emergency centre beds, was documented more often. The annual patient volume in the emergency centre was the most commonly reported marker for facility size, but the simultaneous reporting of the catchment area for the hospital or the number of outpatient visits per year was rare. Although half of the studies referenced the availability of triage, further details on the processes for stratification of patient acuity were not routinely provided. For example, only 20% described the level of training of the healthcare provider performing the triage assessment and even less frequently the protocol used, if any. The level of training for the physicians staffing the EC was reported in only half of the publications, and less so for nurse staffing. Approximately one-fifth of publications were general facility descriptions, without individual emergency facility patient sampling. When patient-level data for those study subjects presenting for emergency care were utilised, 27% were prospective observational or cross-sectional studies and 73% retrospective studies. Continuous sampling was the most commonly used method to gather data on study subjects. But overall, when employing other sampling methods, there was lack of clarity and detail in the study methods to explain the procedures used to ensure adequate selection of a representative study sample. The emergency patient population was defined as paediatric, adult, or general in 90% of reports, 33% reported median or average age for patients, and 63% the proportion of either sex. Fig. 4 shows the frequency of chosen paediatric to adult age cut-offs used by facilities in our review. While the median age was 15 (IQR 14-18), the range was wide from 5 (4 studies in 3 countries) 21-24 to 20 years of age (1 study in 1 country). 25 Patient outcomes of emergency care, which would serve as a marker for the standard of acute care delivery at each facility, were poorly reported limiting the reader's ability to draw accurate conclusions from the published reports. Perhaps the most objective and useful metrics for emergency care-mortality rates at specific time interval, such as 24-h or 48-h mortality-were only available in 10% of publications. The recording of diagnoses was hallmarked by the same lack of consistency as the data describing emergency care. Only 10% of reports used specific diagnosis coding systems, such as ICD-10 Clinical Classification Software. Frequent misclassification, inconsistent, or double classification of conditions can result in over-or underestimation of key conditions. Table 1 lists examples of inconsistencies in the categorisation of various diagnoses and causes of death. Articles commonly classified localized infections with their respective organ system-but also included a separate infectious disease category, presumably for systemic infections (e.g., meningitis and cerebral malaria categorised with the central nervous system, while malaria, tetanus, septicaemia and enteric fever with ''various infections"). 26 Similarly, traumatic conditions could be cate- gorised with the organ system affected and with a general trauma category. 