The patient APACHE II score were 24.9 ± 8.2, the SOFA score 9.1 ± 3.7, and the survival rate after 28 days 83.4%. The values before IVIg administration were: procalcitonin 36.0 ± 463.3 (median 110) ng/ml, presepsin 4,548 ± 4,250 (median 3,337) pg/ml, CRP 15.6 ± 9.6 (median 14.7) mg/dl, and IL-6 13,860 ± 47,299 (median 630) pg/ml. All values were thus elevated. On the days after the completion of IVIg administration and on day 7, the level of almost all mediators (procalcitonin, presepsin, CRP, IL-6) decreased signifi cantly. In patients with suspected severe sepsis and septic shock, presepsin reveals valuable diagnostic capacity to diff erentiate sepsis severity compared with procalcitonin, IL-6, CRP, and WBC. Additionally, presepsin and IL-6 reveal prognostic value with respect to 30 days and 6 months all-cause mortality throughout the fi rst week of ICU treatment [1] . Methods ICU patients with clinical and laboratory signs of sepsis or septic shock, with documented BSIs and with both serum PCT and CRP measurements on the day of the positive blood sample (±1 day), were included. Illness severity was assessed by SOFA score on both admission and BSI day. Demographic, clinical, and laboratory data including PCT and CRP levels, as well as the white blood cell (WBC) count on the day of the BSI were recorded. PCT was measured by an electrochemiluminescence analyzer and CRP by the tholosimetric method (Roche, Switzerland). Results A total of 64 ICU patients (mean age 58 ± 18 years, 39 males) with BSIs were included. SOFA sore was 9 ± 4 on ICU admission and 8 ± 4 on the day of BSI. In 30 of these patients Candida spp. were isolated in blood culture (candidemia group) whereas the remaining 34 had a bacterial etiology of BSI (bacteremia group). Serum PCT concentrations remained within normal ranges in most patients with candidemia whereas a wide range was observed in patients with bacteremia. Mean values of PCT and CRP levels were higher in the bacterial than in the candidemia BSI group: 18.5 ± 33.2 versus 0.73 ± 1.40 ng/ml, P <0.001 and 17.7 ± 10.3 versus 8.9 ± 8.0 mg/dl, P = 0.001, respectively. There was a signifi cant diff erence in WBC count between the two groups: 19,460 ± 10.174 versus 11,000 ± 5,440, P <0.001 for the bacteremia and candidemia BSI group, respectively. A ROC curve analysis of the predictive ability of PCT showed an AUC of 0.79 (P <0.001). When a cutoff point of 0.40 ng/ml was selected using Youden's J statistic, a low value of PCT had in our sample a negative predictive value of 0.76 and a likelihood ratio (negative) of 0.30. Conclusion A low serum PCT value could be considered as a diagnostic marker in distinguishing between BSIs of candidal or bacterial origin in ICU patients with varying severity of sepsis. following: dialysis, surgery, pancreatitis, and receipt of corticosteroids, other immunosuppressive agents or parenteral nutrition. Diff erent from the original description of the score which considered only the fi rst 7 days of ICU stay, we selected patients who fulfi lled these criteria at any time during the ICU stay. Once a patient fulfi lled these criteria, AFT (anidulafungin 200 mg followed by 100 mg daily) was initiated provided that the patients also presented with any of the following: fever, hypothermia, hypotension, leukocytosis, acidosis or elevated C-reactive protein. Blood cultures (days 1 to 2) and baseline serum BDG (days 1 to 3) were performed. Patients with candidemia were treated for ≥14 days, those without candidemia but ≥1 positive BDG (≥80 pg/ml) received AFT for ≥10 days, and patients with negative blood cultures and negative BDG discontinued anidulafungin. Results A total of 2,148 patients were screened, and 85 (4%) fulfi lled entry criteria. The incidence of candidemia in these 85 patients was 8.2%, compared with 0.5% in the remaining 2,063 patients (relative risk 16.9%, 95% confi dence interval (CI) = 6.63 to 43.55). Baseline BDG was positive in 74 patients (87%), with a median number of positive tests of 3 (range 1 to 3) and a median value of 523 pg/ml (range 83 to 6,860). All seven patients with candidemia had positive baseline BDG (median value 523 pg/ml, range 203 to 3,660). The best cutoff of baseline BDG for the diagnosis of candidemia was 522 pg/ml (area under the ROC curve 0.883, 95% CI = 0.769 to 0.997), with sensitivity and specifi city of 86% and 88%, respectively. The cutoff value of 80 pg/ml had sensitivity and specifi city of 73% and 27%, respectively. Conclusion This dynamic prediction rule was able to diff erentiate a group of ICU patients at high risk to develop candidemia, with a relative risk of 16.9. BDG is frequently positive in ICU patients. A cutoff value of 522 pg/ml was able to discriminate between candidemic and noncandidemic patients. A revision of the cutoff value for BDG in the ICU is needed. Introduction Bloodstream infections in the ICU are a major trigger of morbidity and mortality. Several risk factors for bacteremia have been previously identifi ed, such as presence of a central venous catheter or invasive ventilation [1, 2] . Iron is a key element for bacteria growth, and its metabolism is extensively altered by infl ammation. We aim to determine whether iron defi ciency is a risk or protective factor for bacteremia in the ICU. Methods We performed a retrospective analysis of patients included in the MIMIC-II database, an ICU database that collected data from patients admitted to the medical, surgical, coronary and cardiac surgery ICU of Boston's Beth Israel Deaconess Medical Center during a period of 7 years. We performed logistic regression models to assess the association between iron and bloodstream infection. Results We included 3,980 patients, 2,988 with low serum iron (<60 ng/ ml) and 992 with normal/high serum iron (≥60 ng/ml). During their fi rst stay in the ICU, 351 (8.82%) patients developed bloodstream infections. Low serum iron was associated with increased odds of bloodstream infection (OR: 1.37; 95% CI: 1.04 to 1.80). After adjusting for age, gender, Simplifi ed Acute Physiology Score, presence of central venous catheter, ICU type, transfusions performed before iron measured, neoplastic disease, diabetes mellitus, hepatic disease, congestive heart failure and ferritin levels, low levels of iron were still associated with an increased odds of bacteremia (OR: 1.41; 95% CI: 1.03 to 1.9). In contrast, low serum iron was associated with a decreased risk of death in the hospital (adj OR: 0.73, CI: 0.57 to 0.95). Conclusion Low serum iron increases the risk of bloodstream infection in the ICU, and should be considered as a risk factor to stratify patients' risk of bacteremia during ICU stay. Introduction The aim of this study was to investigate whether clinicians can estimate, at the time of insertion, the length of time a central venous catheter (CVC) will remain in place, and to identify clinical variables which may predict CVC duration. CVC-related bloodstream infection is a known complication among critically ill patients. As infection rates may increase with duration of catheterization, more expensive antimicrobial-coated catheters may be used in patients with anticipated long duration of CVC use. Methods We conducted a single-center, prospective study from January 2012 to November 2012. Clinicians prospectively estimated the anticipated duration of CVC at the time of line placement in an electronic procedure note. We collected demographics, past medical history, type of ICU, vital signs, laboratory values, SOFA score, mechanical ventilation and use of vasopressors at the time of placement. Continuous variables were compared with the Wilcoxon rank-sum test and categorical variables with the Fisher's exact test. Pearson's correlation coeffi cient was used to assess the correlation between estimated CVC time and actual time. Duration of CVC use was dichotomized into long (≥7 days) or short (<7 days), based on previous literature, and sensitivity and specifi city for predicting long duration was calculated. We performed a logistic regression analysis to identify variables associated with long CVC duration and calculated the area under the ROC curve (AUC). Results We enrolled 150 patients; median age was 65 (IQR: 52 to 74), 63 (42%) were female and mortality was 22%. Median time from CVC placement to removal was 5 (IQR: 3 to 8) days. The correlation between estimated CVC time and actual time was low (r = 0.36, P <0.001). Fortyeight (32%) patients had a long CVC duration. Clinician estimate had 46% sensitivity and 76% specifi city for predicting long duration of CVC. Of 30 variables tested, only temperature at the time of insertion was signifi cantly associated with long duration (OR: 1.30, 95% CI: 1.04 to 1.63, P = 0.02). The AUC for this model was 0.59 (95% CI: 0.49 to 0.69). Conclusion Our results suggest a low correlation between clinician prediction at time of insertion and actual duration of CVC. We did not fi nd any good predictors of long duration of CVC. Given our relatively low sample size, we may have been underpowered. It may not be feasible to identify patients at the time of insertion who may benefi t from antimicrobial-coated catheters. Methods After ethics committee approval, patients admitted to the ICU, older than 18 years, who were thought to have a central venous catheter (CVC) for more than 48 hours, and whose fi rst catheter was inserted in the ICU were included in the study. Staff were educated before the study and periodically during the study. Catheter care and insertion were applied according to the guidelines. The study was planned as three sequences. In the fi rst group, catheter care was made with a sterile gauze pad. In the second and third groups, catheter care was made with chlorhexidine gluconate impregnated dressing. Also in the third group, a silver-coated needleless connector was inserted into the tip of venous catheters. Results Totally 105 patients were included in the study and every group included 35 patients. There was no diff erence between groups when evaluating reasons for catheter insertion. There was no statistically signifi cant diff erence according to emergent or elective catheterization, trying times, or catheter insertion side (P >0.05). CRBSI was determined in two patients in group 1, in one patient in group 2, and in no patient in group 3. In group 1 it was observed on the 4th and 11th days. In group 2 it was observed on the 18th day after catheterization. Before the study, a statistically signifi cant decrease was determined in CRBSI ratios before and after education (16.4/1,000, 12.9/1,000 catheter-days (P <0.001)). According to Group 1 a statistically meaningful decrease was assigned in CRBSI ratios in Groups 2 and 3 (4.84/1,000, 2.22/1,000, 0/1,000 catheter-days) (P <0.001, P <0.001, P <0.001). Conclusion Continued education is important in preventing CRBSIs. Maximum precautions must be taken. Usage of antiseptic solutions with clorhexidine and chlorhexidine gluconate impregnated dressing decreased insertion side infections and usage of silver-coated needleless connectors reduced microorganism entry through the catheter lumen and provided a severe decrease in infection ratio. The urinary tract infection rates were 4.8 (year 2010: patients·day -1 (n: 2,511), long-term urinary catheter·day -1 (n: 1,455), device usage rate (958%)), 4.4 (year 2011: patients·day -1 (n: 2,529), longterm urinary catheter·day -1 (n: 1,140), device usage rate (45%)), 0.0 (year 2012: patients·day -1 (n: 2,660), long-term urinary catheter·day -1 (n: 783), device usage rate (29%)), 0.0 (year 2013: patients·day -1 (n: 2,573), longterm urinary catheter·day -1 (n: 960), device usage rate (37%)), and 0.0 (year 2014: patients·day -1 (n: 1,070), long-term urinary catheter·day -1 (n: 444), device usage rate (42%)). Conclusion The use of chlorhexidine in the periprocedural antisepsis of urinary catheterization contributed to the decrease of urinary tract infections associated with long-term urinary catheter in patients admitted to the coronary ICU. References Introduction Whole-body skin decolonization with chlorhexidine in critically ill patients reduces multidrug-resistant bacterial colonization, and catheter-related bloodstream infection (BSI). We performed a meta-analysis of randomized controlled trials to determine whether daily bathing with chlorhexidine decreased hospital-acquired BSIs in critically ill patients. Methods We searched the MEDLINE, EMBASE, and Cochrane Central Register of Controlled Trials databases to identify randomized controlled trials that compared daily bathing with chlorhexidine and a control (daily bathing with soap and water or nonantimicrobial washcloths, or implementation of MRSA screening and isolation) in critically ill patients. The primary outcome was hospital-acquired BSIs. Secondary outcomes were adverse eff ects of chlorhexidine and the incidence of identifi ed pathogens. Results This meta-analysis included four studies. The overall incidence of hospital-acquired BSIs was signifi cantly lower in the chlorhexidine group compared with the control 0.80 (95% CI, 0.71 to 0.90; P <0.001; I 2 = 29.4%). Gram-positive (RR = 0.59, 95% CI, 0.44 to 0.79, P = 0.000; I 2 = 46.0%) and MRSA-induced (pooled RR = 0.64; 95% CI, 0.47 to 0.88, P = 0.006; I 2 = 0.0%) bacteremias were signifi cantly less common in the chlorhexidine group. Chlorhexidine did not aff ect Gram-negative bacteremia or fungemia. The overall incidence of adverse events, such as skin rashes, was similar in both groups. Introduction Good hand hygiene (HH) is critical to infection control in the ICU. Electronic HH surveillance systems are purported to improve HH practices. Such a system was recently trialed in our ICU. The system is based on radiofrequency transponders in three locations: bracelets worn by ICU personnel; on all HH product dispensers; and above each patient's bed. By correlating input from these three sources the system detects whether HH was performed before and after each patient contact. In the event that HH is not performed, the bracelet alerts the user (by vibration) in real time. This study represents a clinical validation of the system. Methods ICU staff (nurses and physicians) were followed by a trained observer over 60-minute periods. Each movement and contact during the period was documented. HH opportunities were determined according to WHO criteria and actual HH performance recorded. Observer and electronic data were compared for number of opportunities, HH performance and compliance. A satisfaction questionnaire was distributed to all users. Paired Student's t test was used for comparison of the observer and electronic data. Results Observations were made over 56 time periods that included 836 HH opportunities and 485 occasions when HH was performed. The observer recorded 10.9 ± 7.6 HH opportunities/hour compared with 6.8 ± 6.9 for the electronic system (P <0.001). HH performance occurred on 8.7 ± 3.9 occasions/hour versus 6.0 ± 3.1 occasions/hour as recorded by the electronic system (P <0.001). Overall HH compliance was 62.5 ± 17.7% versus 57.5 ± 21.0% respectively (P = 0.523). On comparison of specifi c observation periods, there was poor correlation between compliance as recorded by the observer and electronic system (r = 0.03, P = 0.915). Satisfaction questionnaires were completed by 41 personnel. Satisfaction with the system was low or very low for 21/41 (61%). System inaccuracy (either bracelet alerts without cause, or lack of bracelet alerts when HH was required) was the most common reason for dissatisfaction (31/41, 76%), followed by physical discomfort from the bracelet (18/41, 44%). Conclusion The electronic HH system consistently underestimated both HH opportunities and HH performance. The main reason for dissatisfaction with the system was inaccuracy of bracelet alerts. These data suggest that for an electronic system to be accepted by ICU staff , it has to be highly accurate and comfortable for the user. the use of closed system transfer devices (CSTDs). To evaluate the microbial tightness of CSTDs we developed two methods which simulate the bioburden in ambient air of operating rooms and ICUs. Methods The methods simulate airborne and touch contamination. We tested the microbial tightness of the integrated Safefl ow® valve of a Mini-Spike® which is used for drug admixture. The airborne contamination was done in an exposure chamber in which a nebulizer distributed defi ned B. subtilis spore aerosols [1] . A Mini-Spike® was inserted into a vial of 0.9% sodium chloride solution (NaCl). A nebulizer with a suspension of 4.8 × 10 5 CFU spores of B. subtilis per ml was used to generate an aerosol for 1 minute. The volume of B. subtilis suspension nebulized per minute was 0.278 ml. This corresponds to 1.34 × 10 3 aerosolized spores in the exposure chamber, which has a volume of 0.24 m 3 (5.6 × 10 3 CFU per m 3 air). The used concentration was 100 times higher than the microbial burden found in hospitals [2] . After nebulization the valve was disinfected and NaCl was withdrawn into a syringe at certain time intervals. The NaCl was incubated on tryptic soy agar at 37°C for 48 hours. Results were documented as CFU. For touch contamination, a Mini-Spike® was attached to a vial of NaCl. The valve of the Mini-Spike® was contaminated with 10 5 CFU Staphylococcus aureus. The subsequent procedure was done as described above. Results Out of nine tested valves, none showed transmission of B. subtilis spores after airborne contamination. Three out of nine tested valves were contaminated with S. aureus after touch contamination. Conclusion Our study shows that both methods are suitable for evaluating the microbial tightness of CSTDs. The fi rst 50 VAP episodes made up the derivation cohort and the subsequent 50 VAP episodes the validation cohort. Antibiotic coverage rates by applying LEBA and GSBA were identical (96% vs. 96%). GSBA proposed more narrow spectrum therapy as compared with LEBA (P <0.001). GSBA recommended carbapenems in signifi cantly less episodes than LEBA (P <0.001) and the same episodes as actually prescribed initial therapy (P = 1). However, there was signifi cant increase of antibiotic coverage rates in GSBA compared with the actually prescribed initial therapy (96% vs. 78%, P = 0.015). Conclusion Antibiotic coverage rates on GSBA were comparable with LEBA. The use of GSBA would result in a signifi cant reduction of the administration of broad-spectrum antibiotics. Bedside Gram staining may be useful to guide appropriate initial antibiotic therapy for VAP. Introduction Urinary tract infection (UTI) is one of the most common bacterial infections in humans. Gram-negative organisms being the most common causative agent, the rising prevalence of resistance to a number of antibiotics and more importantly the production of extended spectrum beta-lactamase (ESBL) by these organisms is a growing concern worldwide. As the scenario is no better in community isolates, the choice of empirical antimicrobials for such infections becomes a great challenge for the clinicians. Methods In this retrospective observational study we aimed at knowing the prevalence of ESBL production by organisms causing UTI in the community and to study the antibiogram of such isolates. Urine samples from patients with suspected UTI in the community were cultured for uropathogen by routine microbiological methods and susceptibility testing was done on Microscan Autoscan 4 (Siemens). Out of 527 isolates of Enterobactereaceae, 314 (59.58%) were ESBL producers from the community samples compared with 315 (67.30%) from hospital samples, with Escherichia coli being the most commonly isolated pathogen. Enterobacter spp. showed highest prevalence (80%) of ESBL production from the community samples. Among the ESBL producing strains from the community, the sensitivity to ciprofl oxacin, levofl oxacin and nitrofurantoin was 18%, 21% and 44% respectively while in the non-ESBL producers the sensitivity rates were 52%, 51% and 73% respectively. Conclusion Organisms producing the ESBL phenotype present with an added possibility of being resistant to other broad-spectrum antimicrobial agents which are commonly prescribed in the community to empirically treat such infections. This makes the choice of empirical antibiotic much more challenging in the community, drawing errors in judgment. A possibility of frequent overcorrection lies on the other side of the coin. This study also shows the possible need for empirical institution of class I carbapenems as one of the treatment options and outpatient parenteral antimicrobial therapy. The mortality rate of 28 days in the L-group was 32.8%, and was 18.8% in the H-group. Mean arterial pressure increased signifi cantly (P <0.01) in the H-group compared with the L-group. WBC counts in the L-group increased and in the H-group decreased (P <0.01) during PMX-DHP treatment. Platelet counts in both groups decreased signifi cantly (P <0.01).There was no signifi cant diff erence between before and after PMX-DHP in IL-6 levels. On the other hand, IL-1ra decreased signifi cantly before and after PMX-DHP. Also, IL-6 and IL-1ra in the L-group were signifi cantly higher than those in the H-group at the start of PMX-DHP. PCT values in the L-group were increased compared with the H-group at the start of PMX-DHP (P <0.01). PCT in the L-group increased signifi cantly (P <0.01), but no signifi cant changes in the H-group. PAI-1 showed no signifi cant changes before and after PMX-DHP and no changes in both groups at the start of PMX-DHP. Conclusion The mortality rate of the L-group tended to be higher than that of the H-group. Infl ammatory and anti-infl ammatory cytokines in the L-group were higher than those of the H-group. These results indicate that leukopenia (WBC <4,000) in severe sepsis patients leads to more severe outcome and hypercytokinemia than leukocytosis (WBC >12,000) in severe sepsis patients. exchange therapy may improve thrombotic microangiopathy [1] . The purpose of this observational cohort study is to describe whether there is an association between use of plasma exchange therapy and outcome in the Turkish TAMOF network. Methods We performed a retrospective cohort analysis in patients with TAMOF at three diff erent pediatric ICUs comparing those who received plasma exchange (+) plus standard therapies with those who did not receive plasma exchange (-) and only received standard therapies. Introduction Mortality from septic shock in the ICU remains high, ranging from 30 to 50%. In particular, Gram-negative bacilli (GNB) account for 40% of the causative bacteria of severe sepsis, which progresses to multiorgan failure due to signifi cant infl ammation. Hemoperfusion with polymyxin B-immobilized fi ber (PMX) adsorbs endotoxin and can reduce the infl ammatory cascade of sepsis due to GNB. However, the clinical effi cacy of this treatment has not been demonstrated. We aimed to verify the effi cacy of endotoxin adsorption therapy by using PMX. Methods We retrospectively evaluated 387 patients who received a broad-spectrum antimicrobial treatment for septic shock due to GNB between January 2009 and December 2012 in the ICU of 10 Japanese tertiary hospitals. After alignment of the treatment time phase for each patient, we divided the patients into two groups according to whether PMX treatment was performed within 24 hours after ICU admission (PMX group: n = 129 and non-PMX group: n = 258). The primary endpoint was 28-day mortality. Results The mean (SD) age and SOFA scores on ICU admission were 72.5 (12.5) years and 10.0 (3.4), respectively. The infection site was intra-abdominal (47.0%), pulmonary (17.6%), and urinary tract (27.8%). Two-thirds of all patients had bacteremia due to GNB. No diff erence in 28-day mortality was observed between the two groups (PMX: 33.9% vs. non-PMX: 33.1%, P = 0.87). In the Cox regression analysis adjusted for age, sex and facilities, the PMX treatment (hazard ratio = 0.87; 95% confi dence interval, 0.53 to 1.43) did not improve the outcome. Conclusion No diff erence in mortality rate was observed after adjustment for the endotoxin adsorption therapy with PMX in the patients with septic shock due to GNB. evaluate the impact of an evolving regional cardiac catheterisation service on a regional intensive care unit (RICU) serving a population of 1.8 million. Methods A retrospective review was carried out. Patients admitted from the regional cardiac catheterisation laboratory to the regional ICU, between September 2009 and September 2014, were identifi ed using validated RICU admission records. Clinical data were extracted from computerised patient records. [1] . Previous work from our group has shown that incorporating simulation-based teaching elements into a basic TTE course improves candidates' satisfaction [2] . We assessed the impact of introducing the ICE-BLU e-learning programme prior to our simulation-based basic TTE course. Methods Prior to the August 2014 course, all candidates were required to complete the ICE-BLU e-learning module. On the morning of the course, the candidates completed a questionnaire to assess the impact of the e-learning module. The survey included questions on the quality of content, user friendliness, whether the content was pitched at the right level and any problems faced whilst accessing the e-learning module. We also analysed candidates' feedback from our January and August 2014 courses ( Figure 1 ). The response rate of the survey was 100%. Eighty per cent of candidates completed the e-learning module. The e-learning module was rated high by most candidates (80%). However, nearly one-half of the candidates faced problems accessing the module, online. Analysis of candidates' feedback (from the January and August 2014 courses) revealed that candidates' overall impression was better with the introduction of e-learning prior to the course. Comparing group I versus group II, the mortality rate was 45%, and there was a statistically signifi cant diff erence for temperature (P = 0.001), HR (P = 0.001) and WBC count (P = 0.01) on admission. Upon comparing survivors versus nonsurvivors in group I there was a statistical diff erence in HR on day 7 (P = 0.02), successful vasopressor withdrawal (P = 0.02), P/F ratio (P = 0.02) and ScVO 2 on day 7 (P = 0.03). Regarding IL-1α, IL-1β, TNFα and troponin I there was no statistical signifi cant diff erence between groups I and II but IL-6, IL-10 and CRP showed statistically signifi cant diff erence on admission PV and CS. Pro-BNP shows statistically signifi cant diff erence in all CS samples between septic and nonseptic groups. Regarding echo upon comparing the survivors versus nonsurvivors, E'd/t on day 0 shows a statistically signifi cant diff erence between both groups. SAPS II and seventh-day SOFA are good predictive scores for mortality in sepsis. Conclusion Diastolic dysfunction was seen in 90% of patients. Fever, HR, and WBC counts are still good early indicators for diagnosis of sepsis. Vasopressor withdrawal on the seventh day was a good predictor for survival. Admission serum IL-6, IL-10 and CRP from PV were better indicators for sepsis than IL-1, pro-BNP and troponin I. Admission TNFα and seventh-day IL-6 levels were highly prognostic for mortality. CS samples proved that NT pro-BNP is a good indicator for sepsis diagnosis and a good predictor for survival. TNFα from CS samples was also a good predictor of mortality. SAPS II and a slower E'd/t on admission was a good predictor of mortality. No changes in mean arterial pressure were observed. The perfused small vessel density tended to decrease at t1 and normalize at t2 (Figure 1 ) in the hyperoxia group. These variations appeared early after 2 minutes of FiO 2 changes. A signifi cant increase in lactate levels over time (from 1.1 (0.9 to 1.7) at t0 to 1.4 (1.1 to 1.9) mmol/l at t2, P = 0.01) was seen in the hyperoxia group. Conclusion Hyperoxia induces an early decrease in microvascular perfusion, which appears to go back to normality at return to normoxia. Healthy volunteers (n = 27) were studied as controls. The slope of the desaturation curve was assessed separately for the fi rst (StO 2 Down1) and the last part (StO 2 Down2) of the curve and the diff erence between, Down2 -Down1, was calculated. Results StO 2 Down1 was lower in healthy volunteers as compared with septic patients (P <0.05); no diff erence was seen between ICU survivors (n = 7) and nonsurvivors (n = 7). StO 2 Down2 was similar between healthy volunteers and ICU survivors, while it was higher in nonsurvivors (P <0.01 vs. healthy). ICU nonsurvivors showed higher Down2 -Down1 as compared with ICU survivors (P <0.01, Figure 1 ). Conclusion Tissue oxygen extraction was reduced in septic patients. Nonsurvivors showed a fl attening in the last part of the desaturation curve during a VOT, while the fi rst part of the StO 2 downslope did not show any diff erence between survivors and nonsurvivors. This may refl ect a tissue hypometabolic status, which may be better elicited in the fi nal part of the ischemic challenge. We observed a 30-day mortality of 3%. With SI <0.7 as reference, a SI of 0.7 to 1 was associated with an adjusted OR of 2.9 (CI 2.7 to 3.2) for 30-day mortality while the adjusted OR for SI ≥1 was 10.3 (CI 9.2 to 11.5). ORs for SI ≥1 were reduced (but still signifi cant) in patients who were older, hypertensive, or on β-/Ca 2+ channel-blockers, whereas diabetes had no eff ect. The OR for SI ≥1 in patients ≥65 years was 8.2 (CI 7.2 to 9.4) compared with 18.9 (CI 15.6 to 23.0) in younger patients. β-/Ca 2+ channel-blocked patients had an OR of 6.4 (CI 4.9 to 8.3) versus 12.3 (CI 11.0 to 13.8) in nonusers, and the OR for hypertensive patients was 8.0 (CI 6.6 to 9.4) versus 12.9 (CI 11.1 to 14.9) in nonhypertensive patients. The OR for SI ≥1 of 9.3 (CI 6.7 to 12.9) in diabetics did not diff er from the OR of 10.8 (CI 9.6 to 12.0) in nondiabetic patients. A SI of 0.7 to 1 was associated with ORs signifi cantly greater than 1 (range: 2.2 to 3.1) with no evident diff erences within the subgroups. A SI measurement ≥1 was associated with lower positive likelihood ratios in patients ≥65 years, with hypertension, diabetes or using β-/Ca 2+ channel-blockers (range 4.9 to 6.5) compared with patients not exposed to these factors (range 7.6 to 11.6). Introduction Vasodilatory shock is a well-known complication in patients who undergo cardiac surgery with cardiopulmonary bypass (CPB) and its occurrence is associated with higher morbidity and mortality. Despite that, clinical characteristics of vasoplegic shock and its spectrum of severity are poorly described. The aim of this study was to compare patients who developed mild to moderate vasoplegic shock with patients who developed a severe form and to identify predictive factors for the severe form of vasoplegic shock. Methods We performed an observational study in 300 patients who underwent cardiac surgery with CPB and presented within the fi rst 24 hours after surgery with refractory hypotension and used a vasopressor agent. Severe vasoplegic shock was defi ned as a requirement of norepinephrine higher than 1 μg/kg/minute or the use of two or more vasopressors. Baseline characteristics, laboratorial, clinical and intraoperative data, such as amount of fl uids, bleeding, blood transfusion, inotropes and length of CPB were collected at ICU admission. Logistic regression was performed using severe vasodilatory shock as the outcome. Results There were 46 (15%) patients who develop the severe form of vasodilatory shock within 24 hours after cardiac surgery. In a univariate analysis, patients with the severe form were more likely to be older, to receive more blood transfusion and inotropic agents, to have higher levels of serum lactate, lower hemoglobin concentration and lower SvO 2 at the end of the procedure, lower cardiac output index, higher heart rate and higher levels of reactive C protein at ICU admission. These patients also experienced more postoperative organ dysfunction, had a longer length of ICU stay and higher mortality. There were no diff erences between patients regarding amount of fl uids and length of CPB. In a multivariate analysis we identify age (OR = 1.04, 95% CI = 1.01 to 1.08, P = 0.016), intraoperative use of epinephrine (OR = 5.49, 95% CI = 2.42 to 12.43, P <0.001), higher serum lactate at the end of the procedure (OR = 1.04, 95% CI = 1.01 to 1.06, P = 0.001) and intraoperative blood transfusion (OR = 5.06, 95% CI = 2.19 to 11.69, P <0.001). Conclusion This study demonstrated that older patients, intraoperative blood transfusion and utilization of epinephrine were independently associated with a more severe form of vasodilatory shock after cardiac surgery with CPB. Also, we identifi ed that a higher lactate at the end of the procedure was an independent predictive factor for this severe form of shock. Reference We analyzed patients who used levosimendan compared with those that used dobutamine in the fi rst hours after cardiac surgery, discarding patients in which neither of these two drugs were used or surgical cases that arrived at the ICU with both inotropics. We analyzed demographic variables as well as clinical complications in the ICU and overall perioperative mortality of patients. We performed a second analysis using the propensity score, obtaining the probability of patients being treated with either drug, pairing each patient who received levosimendan with its nearest neighbor receiving dobutamine. We collected 875 patients: 331 received one of the two drugs, 50 received both drugs and 494 did not receive any drug. ICU mortality was 7.2% (levosimendan group) and 12.5% (dobutamine group), P = 0.1. After adjustment for severity and type of surgery, the use of levosimendan in the postoperative period was not a protective factor for ICU mortality (P = 0.18, OR = 0.5, 95% CI = 0.18 to 1.3). In the matched sample, mortality was 7.4% (levosimendan group) and 5.9% (dobutamine), P = 0.73. After logistic regression adjusted for severity, measured with EuroSCORE and type of surgery, levosimendan was not a protective factor for ICU mortality (P = 0.8, OR = 1.2, 95% CI = 0.26 to 5.45). Conclusion In our environment, we have observed diff erences in the use of levosimendan compared with dobutamine (higher rate of men undergoing CABG, diabetes and worse EF). After homogenizing the sample of patients by propensity score, an eff ect on mortality is discarded and we observed a signifi cant need for use of norepinephrine and a nonsignifi cant trend for prolonged mechanical ventilation and renal failure requiring renal replacement therapy, both probably related with the greatest need for vasopressors observed. Introduction Levosimendan was originally developed for the treat ment of decompensated heart failure in situations for which conventional therapy is not suffi cient. It is an eff ective calciumsensitising drug with vasodilatory and inotropic eff ects and improves cardiac contractility. Trials have shown positive outcome benefi t with the use of levosimendan [1] . We reviewed the usage levosimendan at our institution and outcome of these patients. Of the 3,835 nontraumatic patients treated in the ED, 3, 196 were adults. In this adult population, 500 ECGs were performed in patients whose symptoms suggest ACS. The median age was 62.3 years and the sex ratio was 1.16. Clinical presentation was chest pain (31%), dyspnea (14%), palpitations (5%), disturbance of consciousness (3%) or others (47%). Fifty-six (11.2%) were diagnosed as ACS, including 20 ST-elevation myocardial infarction (STEMI), 28 non-STEMI and eight unstable angina. Of the 20 STEMI patients, eight (40%) and fi ve (25%) were diagnosed as STEMI complicated by right ventricular and posterior wall ischemia respectively, which means that these complications could have been missed by standard 12-lead ECG. Conclusion Eighteen-lead ECG with synthesized right-sided and posterior precordial leads was an effi cient method to diagnose ACS in a Caucasian population within 10 minutes of ED arrival. It is particularly performant to detect right ventricular ischemia early, which can modify acute therapeutic strategy. Introduction After an acute myocardial infarction with ST-segment elevation (STEMI) treated with percutaneous coronary intervention (PCI), the left ventricle (LV) can undergo negative remodeling (R-). We aimed to investigate whether global longitudinal strain (SGL) of the left ventricle (LV) predicts remodeling. Methods Transthoracic echocardiography with speckle tracking imaging (TTE-STI) was performed 2 to 3 days after primary PCI and 6 months later in patients with diagnosis of STEMI. LV R-criteria were: LVEF increase ≤5% and end-diastolic volume increase ≥15%. Logistic regression and ROC curve analysis was used for the statistical analysis. Results Eighty-three patients (56 ± 11 years) with STEMI at any LV localization and subjected to primary PCI were studied during 2012: LV (Figure 1 ). Conclusion SGL assessment in the fi rst days after primary PCI is useful in the prediction of LV R-independently of the myocardial infarction localization. Vasopressor management (noradrenaline dose) (P = 0.0001), fl uid balance (P <0.001) and E/E' (P = 0.00004) were independent predictors of plasma BNP concentration. Of the 56 ICUs that responded, 16 (28.5%) reported that they had personally seen an accidental injection into the arterial line. Conclusion Despite the arterial line safety recommendations made by the NPSA in 2008, we demonstrate that intra-arterial injection is still a problem and that it remains under-reported. Our incidence is likely to be an underestimate as it relies on the recollections of a single individual in each institution. Medical errors can be mitigated by consideration of human factors and system engineering to improve patient safety. A focus on clinical awareness, colour coding and training may lead to improvements; however, institutions and clinical directors also bear a responsibility to prevent never events and a number of engineered solutions are now available such as needle-free non-injectable arterial sampling devices to protect the healthcare environment and make this error impossible [2, 3] . Introduction Use of ice-cold saline is assumed to provide best accuracy of TPTD to obtain the cardiac index (CI), global end-diastolic volume (GEDVI) and extravascular lung-water (EVLWI). However, roomtemperature injectate might facilitate TPTD outside the ICU. A recent study [1] showed acceptable bias and percentage error (PE) for CI-room derived from TPTD with 15 ml room temperature saline compared with CI-cold using 15 ml iced saline for TPTD. However, GEDVI-room and EVLWI-room had borderline PE values close to 30%, and the bias of GEDVI-room markedly increased with higher values of GEDVI and in case of femoral CVC. Since imprecision of TPTD-room might be reduced by a larger volume of injectate, it was the aim of our study to compare CI, GEDVI and EVLWI derived from TPDT using 20 ml room temperature injectate with standard TPTD with 15 ml iced saline. Introduction There are few methods of cardiac output (CO) estimation validated in children. The aim of this study is to investigate the reliability of an uncalibrated pulse contour method of CO estimation, the pressure recording analytical method (PRAM), in pediatric patients scheduled for diagnostic right and left heart catheterization, compared with the oxygen-direct Fick method. Methods Cardiac index (CI) was simultaneously estimated by Fick, and PRAM applied to pressure signals recorded invasively from a femoral catheter. All measurements were performed in steady-state condition. PRAM CI measurements were obtained for 10 consecutive beats simultaneously during the Fick CI estimation. Agreement between Fick and PRAM was assessed using the Bland-Altman method. Correlation coeffi cient, bias, and percentage of error were calculated. Results Forty-three CI measurements were performed in 43 patients. The data showed good agreement between CIFick and CIPRAM: r 2 = 0.98; bias -0.0074 l/minute/m 2 ; limits of agreement from -0.22 to 0.22 l/minute/m 2 . The percentage error was 8%. Figure 1 shows the Bland-Altman plot. Introduction Although recognized as a questionable indicator of the intravascular volume, central venous pressure (CVP) is integrated in many therapeutic algorithms for hemodynamic resuscitation of critically ill patients [1] . In an attempt to simplify CVP estimation, several clinical and ultrasonographic approaches have been suggested [2] [3] [4] [5] . The VE-induced increase in stroke volume was ≥10% in 14 patients (responders) and <10% in four patients (nonresponders). Before VE, the DELTA Vpeak ao in responders was higher than in nonresponders (19.5% (12 to 29) vs. 11.5% (7 to 13)), whereas FTc was lower in responders than in nonresponders (262.5 milliseconds (180 to 340) vs. 285 milliseconds (205 to 300)). The prediction of fl uid responsiveness was higher with DELTA Vpeak ao (ROC curve area 0.964 (95% CI = 0.756 to 1.000); P = 0.0001) than with FTc (ROC curve area 0.562 (95% CI = 0.314 to 0.790); P = 0.7203). The best cutoff value for DELTA Vpeak ao was 13% with sensitivity and specifi city predictive values of 85.7% and 100%, respectively; and the best cutoff value for FTc was 265 milliseconds with sensitivity and specifi city predictive values of 57.1% and 75%, respectively. Conclusion In our study, DELTA Vpeak was the most appropriate variable to predict fl uid responsiveness by OD in ventilated children with ACF. Results Eighty-four data points on 43 patients were collected. VPW correlated with IVC diameter (r = 0.64, P ≤0.001) and IVC variation (r = -0.55, P ≤0.001). No correlation was observed between VPW and number of lung comets (r = 0.12, P = 0.26) or positive fl uid balance (r = 0.3, P = 0.058). On multivariate linear regression, standardized coeffi cients demonstrated that a 1 mm increase in IVC diameter corresponded to a 0.28 mm (Beta) increase in VPW. ROC curve analysis yielded an AUC of 0.843 (95% CI = 0.75 to 0.93), P ≤0.001 and provided the best accuracy with a cutoff VPW value of 64 mm (sensitivity 81%, specifi city 78%, PPV = 88.5%, NPV = 66%, correct classifi cation rate = 79.6%). See Figure 1 . The objective of this study was to determine the minimum volume of intravenous fl uid required to signifi cantly increase the Pmsf. Methods Patients following cardiac surgery were randomly allocated to receive 1, 2, 3 or 4 ml/kg (body weight) of crystalloid over 5 minutes using a 60 ml syringe. Pmsf was measured using the arterial pressure after stopping blood fl ow in the arm with a pneumatic tourniquet infl ated for 1 minute. Cardiac output (CO) was also recorded at baseline and immediately after the fl uid infusion. CO was measured with LiDCO or pulmonary artery catheter, and a positive response was considered an increase of 10% from baseline. From previous data, the least signifi cant change for Pmsf was 15%. Medians were compared using the independent samples media test, and proportions were compared using a chi-square test. Statistical signifi cance was considered when P <0.05. Results Fifty patients were included, 40.8% of them were responders. The proportion of responders increases with the increase of dose of fl uids ( Table 1 ). The regression equation was: change of Pmsf (%) = 4.4 (dose of fl uids ml/kg, 95% CI 2.3 to 6.5) -1.6 (95% CI 7.4 to 4.3, R 2 = 0.28, F(1.47) = 17.8, P <0.001). The predicted dose of fl uids required to achieve a change in Pmsf of 15% is 3.7 ml/kg crystalloids.  We included a total of 1,267 patients. The median age was 68 (quartiles: 59, 76), 32% were female, 68% underwent coronary artery bypass grafting and 59% underwent valve surgery. Median length of hospital stay was 6 days (quartiles: 5, 9) . Median length of stay in the normal, elevated and high lactate groups were 5 days (quartiles: 4, 7), 6 days (quartiles: 5, 9) and 9 days (quartiles: 6, 17), P <0.001 for comparison. In multivariable analysis, patients with an elevated lactate had a 1.12 times (95% CI: 1.02 to 1.23, P = 0.02) longer length of stay compared with those with normal lactate. Patients with a high lactate had a 1.30 times (95% CI: 1.10 to 1.53, P = 0.002) longer length of stay compared with those with normal lactate. Conclusion Postoperative lactate levels are associated with increased length of hospital stay in patients undergoing major cardiac surgery. Interventions aimed at decreasing postoperative lactate levels may decrease hospital length of stay.  We recorded complications (bleeding, tracheoesophageal fi stula, subglottic stenosis, tracheal rings' fracture, diffi culty of placement, change of procedure) related to PDTs performed with and without applying the algorithm. We considered complications that occurred in our experience and we changed our modality in technique choice ( Figure 1 ). Compared with the complications reported in the nA-group, use of the algorithm as a guide to choose the kind of PDT technique seems to reduce the incidence of complications (37% vs. 19%; P = 0.001 chi-square test). Conclusion In our experience the application of the proposed algorithm may reduce the incidence of complications related to PDT in the ICU. However, a randomized controlled multicenter study would be necessary in order to confi rm the effi ciency and validity of the proposed algorithm. Reference Introduction Percutaneous bedside tracheostomy (PBT) is a frequently done procedure in the ICU. PBT is a clean-contaminated procedure, and the duration of the procedure is 15 to 20 minutes depending on the physician's procedural skills. The rate of infectious complications and effi cacy of perioperative therapy in reducing infections after PBT is currently unknown. Currently there have been no defi nitive recommendations for prophylactic antibiotic therapy before PBT in the ICU. Methods All clinical and microbiological data were retrospectively collected and analyzed during the ICU stay before PBT performance and 72 hours after the PBT procedure from 110 patients in our ICU. Controls were defi ned as patients in whom the PBT procedure was performed in the ICU, with antibiotics administered 72 hours prior to and during the procedure (Group 1, n = 82). Cases were defi ned as patients in whom the PBT procedure was performed in the ICU without antibiotics administered 72 hours prior to and during the procedure (Group 2, n = 28). Secondary bacteremia, line sepsis and VAP during the 72 hours after PBT were considered infectious complications. Twotailed P <0.05 was considered to be signifi cant. Results No diff erences were found in age, gender, admission diagnoses, length of ICU stay and in-hospital mortality rate between the two study groups. Overall Gram-negative, Gram-positive and fungal fl ora were similar in both groups before and after PBT. Patients who received antibiotic therapy had a lower incidence of new ventilator-associated pneumonia (VAP) episodes (15/82 (18.2%) in Group 1 vs. 14/28 (50%) in Group 2, P <0.001 (0.23, 0.87 to 0.13)) ( Table 1 ). There were no diff erences in the incidence of bacteremia or line sepsis (Table 1) . Conclusion Our fi ndings highlight the importance of conducting a prospective randomized control trial to better understand the role of antibiotic prophylaxis in PBT. Introduction Respiratory failure is a well-known complication of aortic aneurysm surgery. We describe the impact of a protocol, using CPAP after elective surgery to reduce the need for unplanned invasive ventilation. The average duration of NIV was 3.5 days (SD = 1.6). We examined two sets of 10 consequent breathing cycles for every patient. The mean Vt was 472 ml (SD = 76 ml) with standard face mask and 460 ml (SD = 86 ml) with the modifi ed one. There was statistically signifi cant correlation between the two datasets (P <0.05). No additional leaks were detected. According to the VAS evaluation, fi ve of the patients (83%) had comfort improvement with the modifi ed mask. Conclusion With this modifi cation of the face mask we achieved adequate drainage of the stomach and/or the enteral nutrition of the patients and improvement in their comfort during NIV, compared with the ventilation with a standard mask, without additional air leaks and at a low cost. Introduction Lung ultrasound (LUS) allows semiquantifi cation of lung aeration in PEEP trials [1] , pneumonia [2] and weaning [3] . LUS score is based on number/coalescence of vertical artifacts (B-lines) in longitudinal scan (LONG) [4] : the pleura is identifi ed between two ribs and its visualization limited by intercostal space (ICS) width. We hypothesized that a transversal scan (TRANSV) aligned with ICS would visualize longer pleura and a higher number of artifacts, with better assessment of loss of aeration (LoA). Methods LONG and TRANSV were performed in six areas per lung (anterior, lateral and posterior, each divided into superior and inferior). Once LONG was performed, TRANSV was obtained by a probe rotation until the ribs disappeared. We considered pleural length, B-line number/coalescence, and subpleural/lobar consolidations. LUS score was assigned: 0 normal lung, 1 moderate LoA (≥3 well-spaced B-lines), 2 severe LoA (coalescent B-lines), 3 complete LoA (tissue-like pattern). Results We enrolled 38 patients (21 males, age 60 ± 16 years, BMI 24.7 ± 4.7 kg/m 2 ) corresponding to 456 ICSs. In 63 ICSs, a tissue-like pattern was visualized in both techniques. In the other 393, LONG versus TRANSV pleural length was 2.0 ± 0.6 cm (range 0.8 to 3.8; variance 0.31) versus 3.9 ± 0.1 cm (range 3.0 to 4.3; variance 0.1) (P <0.0001), B-lines per scan were 1.1 ± 1.6 versus 1.8 ± 2.5 (P <0.0001), coalescent B-lines were detected in 24 versus 30% (P <0.05) and subpleural consolidations in 16 versus 22% (P <0.05), respectively. LUS scores' prevalence signifi cantly diff ered in LONG versus TRANSV (Figure 1 ). Conclusion TRANSV visualizes signifi cantly longer pleura and greater number of artifacts useful for lung disease assessment. We were successfully able to record the diaphragm thickness in all included patients. Median time on the ventilator was 9 days (IQR 4 to 15 days). Mean baseline thickness was 1.9 mm (SD ±0.4 mm), and mean nadir was 1.3 mm (SD ±0.4 mm), corresponding with a mean change in thickness of 32% (SD ±18%). As early as after only 72 hours of MV, we already noted an average drop of diaphragm thickness of 20%, illustrating the rapid progression of the atrophy in VIDD. Conclusion On average, diaphragm thickness decreased 32% in our cohort. The decrease occurred rapidly, with two-thirds of the maximal thinning already present after 72 hours of MV. References Introduction Chest-X-ray is recommended for routine use in patients with suspected pneumonia, but its use in emergency settings is limited. In this study, the diagnostic performance of a new method for quantitative analysis of lung ultrasonography was compared with bedside chest X-ray and visual lung ultrasonography for detection of community-acquired pneumonia, using thoracic computed tomography as a gold standard. Methods Thirty-two spontaneously breathing patients with suspected community-acquired pneumonia undergoing computed tomography examination were consecutively enrolled. Each hemithorax was evaluated for the presence or absence of abnormalities by chest X-ray and quantitative or visual ultrasonography. Results Quantitative ultrasonography showed higher sensitivity (93%), specifi city (95%), and diagnostic accuracy (94%) than chest X-ray (64%, 80%, and 69%, respectively), or visual ultrasonography (68%, 95%, and 77%, respectively), or their combination (77%, 75%, and 77%, respectively). Conclusion Quantitative lung ultrasonography was considerably more accurate than either chest X-ray or visual ultrasonography in the diagnosis of community-acquired pneumonia and it may represent a useful fi rst-line approach for confi rmation of clinical diagnosis in emergency settings. Introduction One of the aims of lung recruitment is to improve oxygenation [1] , but it has not yet been investigated in spontaneously breathing patients. Our objective was to evaluate the eff ects of recruitment maneuvers on oxygenation in patients ventilated in CPAP/ pressure support (CPAP/PS) mode. Methods In a prospective, observational study, 30 patients with a Lung Injury Score ≥2 were recruited. Following baseline measurements (t 0 ) PEEP was increased by 5 cmH 2 O (t 1 ). Recruitment maneuver was applied for 40 seconds with 40 cmH 2 O PS. Measurements were taken immediately after recruitment (t 2 ) then 15 minutes (t 3 ) and 30 minutes later (t 4 ). Results According to the diff erence of PaO 2 /FiO 2 between t 2 and t 0 , three groups were defi ned: nonresponders (NR: diff erence of PaO 2 /FiO 2 ≤0%, n = 8), low responders (LR: diff erence of PaO 2 /FiO 2 = 0 to 50%, n = 11) and high responders (HR: diff erence of PaO 2 /FiO 2 >50%, n = 11). In the NR-group, PaO 2 /FiO 2 decreased signifi cantly: median (interquartile), PaO 2 /FiO 2 = 178 (159 to 240) versus 165 (118 to 210) mmHg; in the LRgroup and in the HR-group there was signifi cant improvement: 119 (98 to 164) versus 161 (123 to 182) mmHg and 141 (130 to 183) versus 239 (224 to 369) mmHg, P <0.05, respectively. Dynamic compliance (C dyn ) signifi cantly dropped at t 2 as compared with t 0 in the NR-group, C dyn = 62 (48 to 87) versus 53 (43 to 78) ml/cmH 2 O, while there was no signifi cant change in the LR-and HR-groups, P <0.05. At the same time points the dead space to tidal volume ratio (Vds/Vte) signifi cantly increased in the NR-group, Vds/Vte = 30 (23 to 37) versus 37 (26 to 42)%, but not in the LR-and HR-groups, P <0.05. Conclusion Recruitment maneuvers improved PaO 2 /FiO 2 in the majority of patients (73%) without aff ecting C dyn or Vds/Vte; therefore it may be a safe approach to improve oxygenation in patients ventilated in CPAP/PS mode. Reference traditional parametric sample size estimations depend upon restrictive assumptions that often do not hold in real data. This study estimates N to detect changes in length of mechanical ventilation (LoMV) using Monte-Carlo simulation (MCS) and mechanical ventilation (MV) data to better simulate the cohort. Methods Data from 2,534 MV patients admitted to Christchurch Hospital ICU from 2011 to 2013 were used. N was estimated using MCS to determine a sample size with power of 80%, and compared with the Altman's nomogram for two patients groups, (1) all patients and (2) targeted patients with 1 <LoMV ≤15 days. MCS allows any range of intervention eff ect to be simulated, where this study tested a 10 and 25% diff erence in LoMV (0.5 to 1.25 days for mean LoMV of 5 days). The simulated LoMV for the intervention group is compared with the LoMV in a control group using the one-sided Wilcoxon rank-sum test, Student t test, and Kolmogorov-Smirnov test to assess central tendency and variation. Results The distribution of LoMV is heavily skewed. Altman's nomogram assumes a normal distribution and found N >1,000 to detect a 25% LoMV change. Figure 1 panels (1) and (2) show N for 80% power if all patients were included, and panels (3) and (4) for the targeted patient group. Panels (1) and (3) show that it is impossible to achieve 80% power for a 10% intervention eff ect. For 25% eff ect, MSC found N = 400/arm (all patients) and N = 150/arm (targeted cohort). Conclusion Traditional parametric sample size estimation may overestimate the required patients. MCS can estimate eff ective N/arm and evaluate specifi c patient groups objectively, capturing local clinical practice and its impact on LoMV. It is important to consider targeting specifi c patient groups by applying patient selection criteria that can be easily translated into trial design. Introduction Benzodiazepines are used in many of settings to induce sedation, but can cause a reduction in respiratory drive. Objective monitoring of the eff ect of benzodiazepines on respiratory status in non-intubated patients has been diffi cult, putting patient safety at risk. A non-invasive respiratory volume monitor (RVM) that provides continuous measurement of minute ventilation (MV), tidal volume (TV) and respiratory rate (RR) was used to quantify the eff ects of midazolam on respiratory status in spontaneously breathing patients. Methods An impedance-based RVM (ExSpiron; Respiratory Motion Inc., Waltham, MA, USA) was used in 30 patients who received 2 mg midazolam prior to induction of anesthesia and were sedated but spontaneously breathing. Eleven of these patients (58 ± 19 years, average BMI 27.7) received midazolam at least 20 minutes prior to induction. Digital RVM data were collected and MV, TV and RR calculated and evaluated from 30-second segments 10 minutes before and after the fi rst dose of midazolam. Ten patients were analyzed as a group and one patient was analyzed separately (due to idiosyncratic reaction). Results Following administration of midazolam, the group MV and TV decreased an average of 19 ± 7% and 16 ± 5%, respectively (mean ± SEM, P <0.01, both) while RR remained essentially unchanged (decrease of 3 ± 8%, P >0.3). In the younger half of the cohort (45 ± 16 years), the decreases in MV and TV were not signifi cant, only 6 ± 3% and 8 ± 5%, respectively. The older half of the cohort (72 ± 8 years) displayed fourfold greater MV and TV decreases (32 ± 11%, P <0.05 and 25 ± 6%, P <0.05), when compared with the younger cohort, P <0.01, Figure 1 ). Conclusion Continuous monitoring with RVM provides a valuable depiction of hypoventilation from benzodiazepines, not demonstrated by other methodologies such as pulse oximetry and RR alone. RVM monitoring can help uncover potentially life-threatening hypoventilation in older patients. Further studies are ongoing to quantify hypoventilation after administration of other anesthetic medications. Introduction Mechanical ventilation has the potential to induce pulmonary coagulopathy. Local treatment by nebulization of heparin could be benefi cial in ventilated patients. The aim of this data metaanalysis is to determine the association between nebulization of heparin and outcome of mechanically ventilated critically ill patients. Methods PubMed, Scopus, EMBASE, and Web of Science were searched for relevant articles. Articles were selected if they compared nebulization of heparin with standard care. The primary endpoint was overall mortality. Secondary endpoints included occurrence of pneumonia and number of ventilator-free days and alive at day 28. Results Six articles were found: fi ve retrospective cohorts with historical controls, one randomized controlled trial, covering 423 patients. Dosages of nebulized heparin varied from 30,000 to 150,000 IU/day. Fifty out of 222 patients (22.5%) receiving nebulized heparin and 48 out of 201 patients (23.9%) receiving standard care died (risk ratio (RR) 0.79 (95% CI 0.47 to 1.35)) (see Figure 1 ). Occurrence of pneumonia (RR 1.36 (95% CI 0.54 to 3.45); I 2 = 59%), and number of ventilator-free days and alive at day 28 (standardized mean diff erence 0.11 (95% CI -0.14 to 35); I 2 = 0%), were not diff erent between the two groups. Conclusion Nebulization of heparin is not associated with improved outcome in mechanically ventilated critically ill patients. This metaanalysis is limited by methodological problems in most included studies. Only one randomized controlled trial could be included. Also, most patients in the meta-analyzed studies suff ered from inhalation trauma, and heparin dosages diff ered widely. The coeffi cient of variation (CV) of identifi ed Ers across all patients was low (<0.005), as expected, as the 30-minute period allows time-dependent alveolar recruitment to fully occur and stabilise. However, even with substantial stabilisation periods, there remains a diff erence between the minimum and maximum estimated Ers within each 1-minute period of analysed data. Introduction Maintaining the appropriate tidal volume (VT) is important for success of lung protective ventilation. However, in neonates, the presence of airway leaks may increase the errors in the delivery of tiny VT, which raises a concern of ventilator-induced lung injury. This study is to investigate the accuracy of VT delivery during non-invasive ventilation (NIV) with modern neonatal ventilators. Methods Using a lung simulator for a patient body weight of 3 kg, we measured the actual delivered VT in the lung and compared it with the value displayed on the ventilator in six ventilators. We tested 18 conditions with various combinations of respiratory mechanics (normal, restrictive, obstructive), leak levels (0, 1.0, 1.5 l/minute), and PEEP settings (5, 10 cmH 2 O). All conditions were tested in NIV mode. The pressure level was set to achieve VT to the lung at 6 to 7 ml/kg. All other settings were: F I O 2 0.21, I time 0.6 seconds, f 25/minute, and default rise time. We calculated the mean errors of the ventilator-displayed VT at various levels of airway leak. The VT mean error values are presented in Table 1 . When no leak existed, the mean error was less than 5% in all ventilators except one (C3) which showed a mean error of 26%. As the leak level increased, three ventilators (C3, G5, and VN500) showed marked diff erences between the delivered and displayed VT. In particular, the VN500 could not operate in the large leak condition. The other three ventilators (PB840, PB980, Servo i) showed acceptable VT accuracy across all conditions tested. Conclusion Tidal volume accuracy during neonatal NIV varies greatly among diff erent ventilators and leak conditions. This must be considered in neonatal ventilation management to avoid overventilation or underventilation. Methods 'Hats and caps' was devised on our ICU [3] and used for the training: this teaches that capnography traces on the left signify the airway is functional, in contrast to the traces on the right which indicate immediate attention is required (Figure 1 ). This was presented to staff working on the ICU in individual bedside teaching sessions with feedback obtained and evaluated. Introduction Weaning from mechanical ventilation is an important concern in ICU clinical practice. Surface electromyography (sEMG) [1] is a non-invasive tool to assess activity of diff erent muscles. We describe sEMG patterns of respiratory muscles during a CPAP trial [2] in patients undergoing pressure support ventilation. Methods Twenty-one adult and clinically stable patients undergoing assisted mechanical ventilation for more than 48 hours were investigated during pressure support (baseline) and during a 2-hour CPAP trial. sEMG of diaphragm (costmar), intercostal and sternocleidal (accessory muscles) was recorded with a dedicated device (Dipha16; Inbiolab, Groningen, the Netherlands) simultaneously with airway waveforms and expressed as the ratio of the signal during baseline. Diaphragmatic electrical activity from a nasogastric tube (EAdi) of 14 of those patients was also measured. The rapid shallow breathing index was lower than 105 in all patients and only one patient failed the trial. We observed that the mean inspiratory value of costmar increased immediately after switch to CPAP but did not signifi cantly vary during the CPAP trial (ANOVA, P = 0.7). On the other hand, the activation of accessory muscles increased signifi cantly during the same period (P = 0.01) and was strongly correlated with respiratory rate (r = 0.41, P <0.001) and inversely with Table 1 . Introduction The aim of this study was to determine the types, incidence, and risk factors for early postoperative pulmonary complications in heart transplantation recipients. Methods We retrospectively collected data from the records of consecutive heart transplantations from January 2003 to December 2013. A total of 83 patients underwent heart transplantation. Those patients younger than 10 years (n = 9) and the patients who died intraoperatively (n = 1) or during the fi rst postoperative day (n = 1) were not included in the analyses. The data collected for each case were demographic features, duration of mechanical ventilation, respiratory problems that developed during the ICU stay, and early postoperative mortality (<30 days). The respiratory complications that we sought were pleural eff usion, pneumonia, pulmonary atelectasis, pulmonary edema, pneumothorax, and acute respiratory failure. Methods We included 10 patients receiving iLA Activve® due to hypercapnic respiratory failure as bridge-to-transplant or obstructive lung disease. Sweep gas fl ow was increased in steps from 1 to 14 l/ minute at constant blood fl ow (phase 1). Similarly, blood fl ow was gradually increased at constant sweep gas fl ow (phase 2). At each step, gas transfer via the membrane as well as arterial blood gas samples were obtained. (VT) reduction from 6 to 4 ml/kg attenuates overdistension but is associated with hypercarbia [2] . We thought to combine extracorporeal CO 2 removal (ECCO 2 R) with continuous renal replacement therapy (CRRT) through the insertion of an oxygenator membrane within the hemofi ltration circuit in patients presenting both ARDS and acute kidney injury (AKI). Methods A fi rst set of measurement was performed at 6 ml/kg before and after ECCO 2 R. Twenty minutes later, VT was reduced to 4 ml/kg for the remainder of the study period (72 hours). Ventilator settings were those of the ARMA trial. The CRRT mode was hemofi ltration with 33% of predilution. Ultrafi ltration was adjusted to achieve a fi ltration fraction of 15%. Sweep gas fl ow was constant at 8 l/minute. The primary endpoint was a 20% reduction of PaCO 2 at 20 minutes after initiation of ECCO 2 R. Results Eight patients were studied. Age was 69 ± 11 years, SAPS II was 68 ± 9 and SOFA score was 13 ± 4 at inclusion. Blood fl ow, at the inlet of the oxygenator membrane, was 400 ± 4 ml/minute. CO 2 removal rate was 84 ± 4 ml/minute. Initiating ECCO 2 R, at 6 ml/kg, induced a mean PaCO 2 reduction of 17% (41 ± 5.5 to 33.9 ± 5.6 mmHg, P <0.001 [2] . In our experience, there were no complications during the transfer of ECMO patients, even for longer trips. A wide and thorough clinical evaluation and multidisciplinary ECMO team allowed the optimization of clinical parameters before transport and a safely transfer. The start of ECMO treatment at peripheral hospitals and the transfer of patients in ECMO may be a viable option compared with conventional ventilation. Our data suggest that ECMO can be set up safely in peripheral hospitals by a multidisciplinary highly specialized ECMO team [3] . Introduction Cerebral microhemorrhages (MH) are diminutive focal bleedings which can be detected best by MRI using susceptibilityweighted imaging sequences (SWI). They can be found in a variety of neurologic diseases. The pattern of distribution can lead to the underlying pathomechanism [1] . Survivors of high-altitude cerebral edema (HACE) showed multiple MH, predominantly in the splenium of the corpus callosum. Mountaineers with a lack of acclimatization to high altitudes tend to suff er from HACE. Hypoxemia in great heights is discussed to be the main trigger of HACE [2] . Acute respiratory distress syndrome (ADRS) is characterized by oxygenation failure in mechanically ventilated patients. The severity is classifi ed by the ratio of arterial oxygen tension to fraction of inspired oxygen [3] . In some patients suff ering from severe ARDS, refractory to conventional therapy, venovenous extracorporeal membrane oxygenation therapy is the therapeutic option to ensure oxygenation. Methods Retrospectively, we examined 20 patients with cerebral MRI (including SWI) who had suff ered from severe ARDS and received ECMO therapy. The MRI slides were anonymized and analyzed by two experienced neuroradiologists. Based on the distribution pattern and characteristic, a modifi ed HACE score (mHCS) was surveyed [2] . Results Six of 20 patients (30%) showed multiple MH with emphasis in the splenium of the corpus callosum. Eight patients had sporadic MH in the parenchyma of the brain but not in the corpus callosum. The remaining six patients had no intracerebral alterations. The distribution of MH with involvement of the splenium resembled that seen in HACE survivors. Conclusion Based on these results, we postulate that hypoxemia is one of the main players in the development of splenium-associated MH, not only in HACE but also in severe ARDS and other diseases accompanied with severe hypoxemia. Further investigations have to examine potential triggers and special circumstances concerning ARDS treatment which lead to MH in this distinctive pattern. The acute response to sepsis was characterized by early activation of AMPK which increased from 6 to 18 hours, peaked at 24 hours, and decreased by 48 hours ( Figure 1A ). This activation was associated with a consistent decrease in B-ENaC expression. In AICAR pretreated animals, AMPK was only activated in WT mice, which was associated with a decrease in the expression of B-ENaC as compared with AMPK KO mice ( Figure 1B) . Conclusion AMPK was activated early after induction of sepsis, and was associated with a consistent decrease in Beta-ENaC expression in the apical membrane of tubular epithelial cells. In addition, absence of AMPK activation in KO animals was associated with increased expression of Beta-ENaC at 24 hours after CLP. These data support the hypothesis that early activation of AMPK decreases energy consumption through ion channel downregulation. Figure 1 . The total baseline plasma concentration of all standard amino acids was similar between IHD versus SLEDf groups (1,812 ± 517 vs. 2,675 ± 527 μmol/l, respectively) but were higher in the CVVH group (3, 194 ± 564 μmol/l). RRT reduced the plasma concentration of amino acids in the SLEDf group (to 1,732 ± 529 μmol/l; P = 0.02), but had no eff ect in the IHD or CVVH groups (IHD; 1,853 ± 523, CVVH; 2,845 ± 512 μmol/l). Introduction Venovenous extracorporeal membrane oxygenation (VV-ECMO) is a novel therapy for severe respiratory failure (SRF). Its introduction has reduced mortality; however, patients require substantial blood product support and between 10 and 20% of cases develop a life-threatening haemorrhage. Methods We contacted 336 practitioners at 135 centres, examining their haematological management. Results In total 25% of practitioners contacted responded; 85% were attending physicians, predominantly based in North America and Europe, 41 and 32% respectively. Ninety-six per cent of units used a polymethylpentene membrane oxygenator and all used a centrifugal pump. Thirty-four per cent of responders managed <10 cases a year and 60% worked in units handling <20 annually, 6% saw >50 patients. One centre did not use unfractionated heparin. Monitoring of anticoagulation varied; 52% used the APTT, 43% the ACT and 5% the APTTr. Sixty per cent did not routinely measure antithrombin. Scenario 1 was based on a patient with H1N1. Practitioners targeted a haemoglobin (Hb) of 80 to 100 g/l; however, 20% targeted a Hb outside this range; 38% favouring a transfusion threshold of <80 g/l when the patient was improving compared with 32% when the patient had just started on ECMO. Seventeen per cent of practitioners transfused platelets when the count was <30 × 10 9 /l whilst 21% maintained the platelet count >100 × 10 9 /l. Scenario 2 described a patient with SRF secondary to a hospital-acquired pneumonia. The patient developed a haemothorax, with persistent blood loss of 200 ml/hour. Practitioners targeted a higher haemoglobin concentration of 100 g/l and targeted a higher platelet count of >100 × 10 9 /l when compared with the patient in scenario 1, neither of these diff erences was statistically signifi cant. Seventy-one per cent stated they would manage the patient off anticoagulation. There was no agreement as to the length of time off anticoagulation; 26% restarted anticoagulation in <12 hours, compared with 22% who advised no anticoagulation for >5 days. Scenario 3 examined the management of an incidental intracranial haemorrhage. There was a lack of consensus regarding the duration off anticoagulation; 14% of responders held anticoagulation for less than 12 hours whilst 37% held anticoagulation for >5 days and tranexamic was considered useful by 25%. Conclusion There was wide variation in the use of blood products and the intensity of anticoagulation. This is not surprising given the current lack of evidence. Further work is required to provide a standardised approach. . Five patients were discharged from the ICU but did not survive until H-discharge. At discharge from the ICU, these patients were similar to H-survivors in SOFA score, heart rate, mean arterial pressure and lactate, but showed lower StO 2 downslope (-13 (-16.5, -11.7)%/minute vs. -8.6 (-11.7, -6.5)%/minute, P = 0.01). The average ISS is 21.5 (SD 10.9). Cars are the most involved in serious urban VRU crashes. Car-to-pedestrian crashes are the most frequent (50%). The impact speed is always over 40 km/hour ( Table 1) . The head and face are the most frequently injured part (48% of the 571 injuries collected), followed by lower extremities (15%). In terms of maximum AIS (MAIS), the head is the most severely injured region with 42% of MAIS 3+ (Figure 1 ).  Introduction The outcome of multiple trauma patients is related to a number of diagnostic and therapeutic interventions during hospitalization. ICU patients with severe trauma are susceptible to sepsis leading to poor outcome. Factors associated with the occurrence of sepsis and the outcome of these patients were investigated. Methods We studied retrospectively all trauma patients admitted to the A' ICU of KAT General Hospital in Athens during the last 3 years and were treated for more than 5 days. Age, gender, the type of injury, the severity of injury (Injury Severity Score), the length of ICU stay, severe sepsis, coexisting diseases, the outcome and the cause of death were recorded. Logistic regression and chi-square tests were used for statistical analysis.  There was no signifi cant diff erence in age, %total burn surface area or Belgian Outcome Burns Injury score between the groups. For all operation data, use of colloids was found to signifi cantly contribute towards poor graft viability (P = 0.035, 95% CI). When analysis was performed on only SSG and debridement operations, colloids remained signifi cant (P = 0.034, 95% CI) and metarminol use was found to signifi cantly contribute (P = 0.028, 95% CI) to poor graft viability. Overall use of inotropes was not signifi cant between the two groups. Other variables including minimum and maximum temperature, preoperative haemoglobin and blood transfusion were not found to be signifi cant. Conclusion Our results suggest that the use of colloids is a contributor to poor graft viability in burns. This was found to be independent of temperature and overall inotrope use; however, the use of metarminol may be a contributing factor. Introduction For a long time, many investigators have tried to demonstrate increased mortality associated with acid-base distur bances. In this study, we sought to determine the association of hyperchloremia measured at ICU admission and whether this electrolyte disturbance is associated with an increase in morbidity and mortality. Methods Data were retrospectively collected for consecutive adult patients admitted to Agustin O'Horan Hospital ICU, between January 2011 and July 2014, who underwent inpatient medical treatment using electronic fi les. Results The dataset consisted of 936 medical fi les and serum chloride concentration values on admission, 853 being eligible. Hyperchloremia (serum chloride >110 mmol/l) is quite common, with an incidence of 47.71%. Patients were propensity matched based on their association with death and hyperchloremia. Of the 853 patients collected, patients with hyperchloremia after admission (n = 446, 52.3%), patients were matched to patients who had normal serum chloride levels after admission. These two groups were well balanced with respect to all variables collected. The hyperchloremic group was at increased risk of mortality at ICU discharge, relative risk ratio = 1.81; 95% confi dence interval, 1.41 to 2.51 risk increase of 25.31%. Admission hyperchloremia was associated with increased morbidity, mortality and higher scores in severity scales; this association was statistically important. See Figure 1 . Conclusion This retrospective cohort trial demonstrates an association between hyperchloremia and poor ICU admission outcome (death). Additional studies are required to demonstrate a causal relationship between these variables. Our results show that adult ICU patients are continuously exposed to phthalates (that is, DEHP) as well as to BPA, albeit to a lesser extent, resulting in detectable serum and urinary levels in almost every patient and at every studied time point. Moreover, these levels were signifi cantly higher than in controls or compared with referenced literature. The chronology of exposure was demonstrated: the preoperative urine and serum levels of the DEHP metabolites were often below the detection limit. Medical devices are the source of these chemicals: patients on hemofi ltration, extracorporeal membrane oxygenation or both showed serum levels 100-fold or 1,000-fold higher than the general population or workers in plastic industry. The serum and some of the urinary levels of the DEHP metabolites are the highest ever reported in humans; some at biologically highly relevant concentrations of even ≥10 to 50 μM. Conclusion Adult ICU patients are exposed to plastic softeners, in particular PMs. Despite the continuously tightening regulations, BPA and DEHP are still present in medical devices. Because patient safety is a concern in the ICU, further research into the (possibly toxic and clinical) eff ects of chemicals released from medical devices should be undertaken. Introduction Vitamin D defi ciency may frequently occur in critically ill patients and may be associated with sepsis and increased mortality. We therefore evaluated the prevalence of 25-hydroxyvitamin D defi ciency in a Dutch ICU, and its relationship with sepsis, morbidity and mortality. Methods We conducted a prospective observational study in a 10-bed mixed ICU. A total of 1,372 patients were admitted between July 2011 and June 2013 including 198 readmissions, of which 940 patients were studied. 25-Hydroxyvitamin D levels were determined within 24 hours after admission. 25-Hydroxyvitamin D levels were judged as suffi ciency (>50 nmol/l), insuffi ciency (30 to 50 nmol/l) and defi ciency (<30 nmol/l). Results The prevalence of defi ciency and insuffi ciency was 36% and 38%, respectively. Only 26% of the patients had suffi cient vitamin D levels. Vitamin D defi ciency is associated with sepsis (P <0.001) at ICU admission. Patients with defi cient levels had higher mean APACHE IV scores, 64 versus 52 (P <0.001), and longer length of hospital stay, 12 versus 9 days (P <0.001), respectively, as compared with patients with suffi cient levels. Patients with defi cient vitamin D levels had an odds ratio for in-hospital mortality of 1.4 (95% confi dence interval of 0.84 to 2.29, P = 0.2) relative to patients with suffi cient vitamin D levels. Conclusion 25-Hydroxyvitamin D defi ciency frequently occurs in Dutch critically ill patients. Although relating to sepsis, disease severity and morbidity, vitamin D defi ciency is not an independent predictor of mortality in these patients, which was otherwise relatively low. Introduction Stress hyperglycaemia (SH) is commonly observed during hospitalisation in the ICU and adversely infl uences outcome [1] . When SH occurs in previously nondiabetic patients, this might refl ect a latent disturbance of glucose metabolism and predict future risk of diabetes. We wanted to assess the incidence of disturbed glucose metabolism (DGM) and identify predictors for future diabetes risk. This could support timely diagnosis, prevention, and early treatment of impending diabetes mellitus (DM). Methods In this prospective observational study, we enrolled 338 patients without known DM, who were admitted for at least 36 hours to the ICU of the Antwerp University Hospital between September 2011 and March 2013. A 75 g oral glucose tolerance test was performed 6 to 9 months post ICU admission to screen for disturbed glucose metabolism. Furthermore, we examined whether post-discharge glucose disturbances could be predicted by the FINDRISC questionnaire [2] , patient demographics, comorbidities, HbA1c at ICU admission, and by parameters related to ICU stay (glucose parameters, insulin need, caloric intake, disease severity). Results In total, 246 patients (73%) experienced SH during their ICU stay. Eight months post ICU admission, glucose metabolism was disturbed in 119 (35%) subjects. Of these, 27 (8%) had impaired fasting glucose, 43 (13%) had impaired glucose tolerance, 25 (7%) had impaired fasting glucose and impaired glucose tolerance, and 24 (7%) were diagnosed with DM. A disturbed glucose metabolism tended to be more prevalent in subjects who experienced SH during ICU stay as compared with those without SH (38% vs. 28%, P = 0.065). HbA1c on admission correlated with the degree of SH (r = 0.308, P <0.001). The FINDRISC score (9.5 vs. 11, P = 0.001), SAPS 3 score (median of 42 in both groups, P = 0.003) and daily caloric intake during ICU stay (222 vs. 197, P = 0.011) were associated with a DGM. Conclusion Stress hyperglycaemia is frequent in nondiabetic patients and has a tendency towards future disturbances in glucose metabolism and DM. Glucose metabolism was disturbed in 35% of subjects 8 months post ICU admission, of whom 7% was diagnosed with diabetes mellitus. Predictors of elevated risk included a high FINDRISC score, high SAPS 3 score, and a lower daily caloric intake during ICU stay. References Introduction It is conjectured that transition of hypoglycemia to hyperglycemia may be more harmful than hypoglycemia itself. We investigated the association between the degree of correction of hypoglycemia and ICU mortality in patients under moderately strict to strict glycemic control. Methods This is a retrospective analysis from a pooled cohort from seven ICUs in the Netherlands over 6 years. ICU patients who developed hypoglycemia (<70 mg/dl) were included. We excluded patients who were readmitted, and patients with hypoglycemia in whom no followup blood glucose measurement was performed within 8 hours. We determined the association between three measures of correction of hypoglycemia within 8 hours after hypoglycemia and ICU mortality: predefi ned ranges of the 'highest blood glucose level' (<80 mg/dl; 80 to 110 mg/dl; 110 to 150 mg/dl (reference category); 150 to 180 mg/ dl; and >180 mg/dl); quartiles of the 'delta glucose' , defi ned as the diff erence between minimum and maximum blood glucose level with the third quartile as reference category; and quartiles of the 'standard deviation' of the blood glucose level with the third quartile as reference category. Results In total, 4,516 ICU patients developed at least one episode of hypoglycemia. In three separate multivariate analyses for each of the three measures we adjusted for the respective confounders. The category 80 to 110 mg/dl of the 'highest blood glucose level' was associated with increased mortality compared with the reference category (odds ratio (OR) = 1.31, 95% confi dence interval (CI) = 1.06 to 1.61). The lowest quartile of the 'delta glucose' (OR = 1.32, 95% CI = 1.03 to 1.69) and the lowest quartile of the 'standard deviation' (OR = 1.55, 95% CI = 1.23 to 1.96) were associated with higher ICU mortality than their reference categories. We used the criteria of Nanashima and colleagues for the diagnosis of IPGF (ALT and/or AST level above 1,500 IU/l within 72 hours after OLT). The study group included 33 men (55%) and 27 women. Mean (±SD) age was 50.56 (±13.26) years. WIT longer than 60 minutes correlated signifi cantly with ALT and AST levels in POD 1 to 3 (P <0.0001 for ALT in POD 1 to 3, P = 0.001 for AST in POD 1, P = 0.007 and 0.013 for AST in POD 2 and 3) and with prothrombin time (P = 0.008 in POD 1, P = 0.03 in POD 2 and P = 0.015 in POD 3). We could not fi nd a correlation between PRS and WIT (P = 0.566), CIT (P = 0.439) or transaminase levels on POD 1 to 3. The correlation between WIT >60 minutes and IPGF was confi rmed using the Pearson chi-square test (P <0.0001). The same test was used to correlate IPGF with PRS with nonsignifi cant results (P = 0.876). Conclusion Our study showed that PRS is not a risk factor for IPGF after liver transplantation. WIT over 60 minutes does not infl uence the development of PRS, but is associated with IPGF after liver transplantation. Close monitoring of liver tests in the early postoperative period is very important especially in recipients of grafts with WIT over 60 minutes. Further eff orts to decrease WIT may prove useful for the reduction of IPGF in liver transplant patients. The results of 36 patients could not be reached, so 426 patients were evaluated in the study. Among 426 patients, 169 (39.7%) were female and 257 (60.3%) were male. The mean age was 63.7 ± 18.7. HBsAg was positive in nine (2.1%) patients; all of these nine were male. Anti-HCV was positive in four (0.9%) patients; among these, three were male and one was female. Only one patient was positive for anti-HIV. We included 88 patients after elective surgery (76 cardiac and 12 general surgery) and 90 patients after acute admission (27 sepsis, 17 acute surgery, two trauma and 44 medical). Baseline characteristics are presented in Table 1 . Plasma glutamine levels at admission were signifi cantly lower in acute patients compared with elective surgery, 0.25 mmol/l (IQR 0.09 to 0.37) versus 0.43 mol/l (IQR 0.33 to 0.55) Figure 1 (abstract P399) . Indirect calorimetry measured signifi cantly higher resting energy expenditures. (P <0.001). There appeared to be a signifi cant correlation between the APACHE IV score and glutamine levels (R = 0.52, P <0.001). Moreover, in a backward linear regression analysis this correlation was independently associated with APACHE IV scores and the presence of infection, but not with the type of admission. Conclusion Plasma glutamine levels were signifi cantly lower after acute admission compared with elective surgery. In both groups a considerable amount of patients had decreased glutamine levels, but this was not independently associated with the type of admission. In contrast to previous studies we found that glutamine levels were determined by severity of illness and the presence of an infection. Introduction Intravenous fi sh oil (FO) lipid emulsions (LEs) are rich in ω-3 polyunsaturated fatty acids, which exhibit anti-infl ammatory and immunomodulatory eff ects. We previously demonstrated that FOcontaining emulsions may be able to decrease mortality and ventilation days in the critically ill. Over the last year, several additional randomized controlled trials (RCTs) of FO-based LEs have been published. Therefore, the purpose of this meta-analysis was to update our systematic review aimed to elucidate the effi cacy of FO-based LEs on clinical outcomes in the critically ill. Methods We searched computerized databases from 1980 to 2014. Overall mortality was the primary outcome and secondary outcomes were infections, ICU and hospital length of stay (LOS), and mechanical ventilation (MV) days. We included RCTs conducted in critically ill adult patients that evaluated FO-based LEs in parenteral nutrition (PN) or enterally fed patients. We analyzed data using RevMan 5. Introduction This study aimed to describe the patient characteristics and prehospital factors associated with an ICU admission from the ED. There is a paucity of information about the early recognition of critical illness by paramedics; especially in the Australian prehospital setting. Methods A retrospective cohort study, July 2012 to June 2014, conducted in the Perth metropolitan area, which is served by a single ambulance service. Adult patients were included if transported to a public hospital ED that used the ED information system (EDIS) (seven of eight EDs) and were admitted to the ICU from the ED (ED-ICU group). Patients aged <16 years, those from rural areas or transfers were excluded. We used existing ambulance clinical data linked to EDIS data. Prehospital cohort characteristics are described using univariate statistical techniques. Logistic regression was conducted with admission to the ICU from the ED (critical illness surrogate) as the outcome variable. Variables included in regression models were age, sex, paramedic-identifi ed urgency, that is the time patients should be seen by a doctor based on the Australasian Triage Scale, paramedicidentifi ed patient problem and the time taken from the ambulance service receiving the call to hospital arrival. Physiological variables: systolic blood pressure (SBP), heart rate (HR), respiratory rate (RR), temperature, oxygen saturation, and GCS were included in the logistic models. Introduction We aimed to identify the adequacy of assistance provided and to assess correct anaesthetic equipment and drug availability at emergency calls made in the ICU and in remote areas of the hospital. Emergency calls often involve managing critically ill patients with the highest mortality results. The importance of a clinical team with the necessary competencies and the right level of resources are paramount. Methods We undertook a prospective survey of all adult patients with emergency calls put out to the anaesthetic team in a London district general hospital over a 6-week period. We performed a snapshot audit of equipment in resuscitation trolleys across each ward and in the radiology department. We compared the data collected on available equipment with the standard set by the Resuscitation Council (UK) Recommended Minimum Equipment Checklist [1] . The survey addressed the availability, clinical competency and appropriate duration of stay of the anaesthetic assistant at the emergency calls. Further qualitative data were collected on the availability of required emergency drugs. Results During the study period 44 emergency calls were attended. Twenty-three (52%) of these calls were in the accident and emergency department, and four (9%) in the ICU. Survey results demonstrated two cases where no anaesthetic assistant arrived at the emergency call put out to them. In cases where timely assistance was available, the assistant did not have the adequate clinical and anaesthetic skills required by the attending physician. In 6% of cases where skilled assistance was required (n = 2), it was felt that the assistant did not stay for the clinically required length of time. Emergency drugs required were found to not be available in 11% of cases (n = 5) and in 17% of cases (n = 6) the necessary emergency equipment was not available. Data were collected on equipment from 17 resuscitation trolleys. The inadequacies identifi ed were the oxygen cylinders were fi lled less than 75% full in 41% cases (n = 7) and end-tidal capnography was identifi ed to be absent. Conclusion Emergency calls require standards to be met involving the competency of responding team members and adequate resources. This leads us to question whether guidelines should exist regarding the clinical competency and timeliness of the assistant available to the physician at emergency calls. Reference Introduction There is widespread concern regarding excess mortality for patients admitted to hospital out of hours. We introduced an electronic track and trigger system (Patientrack) with automated alerts in a large university teaching hospital between 2010 and 2012. The system computes the patient's early warning score and alerts medical staff via a pager. It is operational 24 hours a day, 7 days a week and could be an eff ective tool to reduce variations in mortality throughout the working week. Based on analysis of responses, a focused three-pronged intervention was formulated and implemented hospital wide. The arms of the intervention were: identifi cation of the name and role of each staff member using highly visible labels; role allocation according to policy written through a multidisciplinary working group; and a time out during the response allowing a structured synopsis of the patient's current status to be communicated to the team. The intervention was preceded by extensive staff education, and 175 staff (50%) completed the survey 6 months later to assess its success. The intervention signifi cantly increased satisfaction amongst staff regarding: identifi cation of the team leader and other key staff members at the response; and time out eff ectiveness in reducing repetition and improving staff understanding of the patient's status and medical issues. We found no signifi cant change in staff perceptions regarding the clarity of the ongoing treatment plan at the end of the MET call response. Conclusion Utilising a low-cost intervention in a regional setting, we were successful in improving staff perceptions of role allocation and communication within our MET call responses. The intervention also led to signifi cantly increased overall satisfaction with the MET call system. Through our surveys we have identifi ed other facets of the MET call response that also require attention. Given our encouraging results we are designing a follow-up intervention incorporating structured multidisciplinary training in MET call scenarios. Introduction A medical emergency team (MET) was introduced in our institution in January 2012 to provide timely response to the needs of acutely ill inpatients and cardiac arrest calls. The MET assesses the patient and prescribes a management plan for the responsible team to follow; promptly stabilising and transferring patients to a place of safety where required. We aimed at evaluating the eff ects of introducing the MET on clinically relevant processes and outcomes. Methods Prospective data were analysed using STATA 10.1. The primary outcome measure was immediate mortality (defi ned as mortality at Cardiovascular illness was the predominant baseline morbidity but none of the baseline illness showed increased risk of mortality in this group. Among true cardiac arrest events, 92.6% was due to pulseless electrical activity/asystole and 7.7% was due to ventricular fi brillation (VF)/pulseless ventricular tachycardia (VT); both of these did not have any diff erence on the initial outcome. But having an initial rhythm of VF/pulseless VT had 90% more chance for discharge from the hospital, with P = 0.04. Although arrival time of the CBT did not have any infl uence on the fi nal outcome, duration of resuscitation ≤20 minutes had an odds ratio of 10.6 with P <0.001 favoring return of spontaneous circulation over death after controlling for age. Of the 203 patients who had true cardiac arrest events, 43 (21.2%) were discharged from the hospital. Good neurological outcome at discharge was seen among 22 (10.8%) of the patients based on Cerebral Performance Category Score. Conclusion Our experience shows that out of every 1,000 patients admitted to our hospital, about fi ve sustained cardiac arrest, of whom only 11.3% survived to hospital discharge with good neurological recovery. Variation in the eff ectiveness of the cardiopulmonary resuscitation quality in comparison with world data could be due to the inherent diff erence in the severity of the primary illness in the patients and diversity in the reported data. References practices relating to CPR and AED training in London secondary schools. The fi rst patient, a 59-year-old male (73 kg), was admitted after successful resuscitation from a protracted out-of hospital cardiac arrest. His initial temperature was 35°C, which is within our current institutional protocol of 34 to 36°C. Several hours after arrival, his temperature slowly increased to 35.8°C despite application of a cooling blanket and ice packs to the groin and axilla. The ECD was inserted and a reduction of temperature to 34.8°C was achieved within 3 hours. The patient expired on day 3. The second patient, a 54-year-old female (95 kg), was admitted after resuscitation from an out-of-hospital PEA arrest. Despite initiating our cooling protocol with surface-cooling blankets and cold intravenous saline, she mounted a fever peaking at 38.3°C shortly after admission. After ECD insertion and confi rming the external heat exchanger connection, her temperature gradually dropped to 35.7°C over a period of 4 hours. She subsequently made a favorable neurological recovery and was discharged home at day 23. The third patient, a 47-year-old male patient (86 kg) presented with an ongoing fever secondary to necrotizing pneumonia in the postoperative period after coronary artery bypass grafting. His fever was unresponsive to empiric antibiotic therapy, antipyretics, cooling blankets, and ice packs. ECD insertion resulted in a decrease in temperature from 39.5°C to 36.5°C in less than 5 hours. The patient eventually made a full recovery and was discharged home after 59 days. In all three patients, placement of the device occurred in less than 3 minutes and ease of use was reported as excellent by nursing staff and physicians. Conclusion The ECD is a novel technology that can be used for temperature management post cardiac arrest and for fever control in critically ill patients. Despite patients mounting a febrile response, temperature control was achieved and maintained successfully. The device was reported as being easy to use, by both physicians and nurses. Introduction Clinical outcomes vary depending on the method used to induce therapeutic hypothermia following stroke or cardiac arrest. In swine, we tested the hypothesis that selective nasopharyngeal brain cooling (SNBC), in contrast to systemic hypothermia, adversely impacts cerebral perfusion. Methods In two groups of animals (34 to 35 kg), blood fl ow in the right middle cerebral artery (MCA) was measured using transcranial Doppler (TCD). In group 1, SNBC was initiated using perfl uorohexane aerosol (1 ml/kg/minute) and oxygen (1 l/kg/minute) through a nasopharyngeal catheter atomizer. In group 2, the animals were body surface cooled using water-circulating blankets (4°C). In both groups, brain temperature, intracranial pressure (ICP), core temperatures and vital signs were continuously recorded. Cooling was terminated once the brain reached 32°C and the animals were allowed to passively rewarm. In the SNBC group, the brain target temperature was reached in 54 ± 11 minutes. The mean ICP dropped precipitously to a nadir of -15 mmHg. TCD showed signifi cant vasospasm in the MCA, compared with the internal carotid artery (ICA), during the entire cooling phase (Table 1 ). Upon termination of cooling, the brain temperature spontaneously rewarmed to core temperature in 13 ± 4 minutes. Rewarming was associated with hyperemia and elevation of ICP. In group 2, there was no cerebral vasospasm or hyperemia during cooling and rewarming respectively. Conclusion SNBC is associated with signifi cant vasospasm of the MCA. In addition, spontaneous and rapid rewarming of the brain, vasodilation, rapid reperfusion, and rebound elevation of ICP, all occurring minutes after termination of SNBC, are likely to be detrimental to an already ischemic brain. Introduction Uncontrolled shivering may have negative consequences by increasing metabolic demand and subsequently neutralize the benefi ts of therapeutic normothermia [1] . Previous anti-shivering protocols that utilize the least sedation have been described in therapeutic temperature modulation (TTM) [2] . Our aim is to describe and evaluate an anti-shivering protocol that emphasizes the least sedating regimen with the least number of pharmacologic agents for patients undergoing therapeutic normothermia. Twenty-seven patients of the nonsurvivors had ROSC >20 minutes and one patient had CPC 3 at hospital discharge. We observed no signifi cant diff erence between both groups in age (P = 0.161), time between emergency call and start of ALS (P = 0.788) and duration of basic life support performed by bystanders, general practitioners or paramedics (P = 0.649). The initial rhythm was asystole in one (12.5%) survivor and in 50 (62.5%) nonsurvivors (P = 0.009), ventricular fi brillation in six (75%) survivors and 13 (16%) nonsurvivors (P = 0.001), and pulseless electrical activity in one (12.5%) survivor and 17 (21%) nonsurvivors (P = 1.00). The cardiac arrest was witnessed in all survivors (100%) and in 49 (61%) nonsurvivors (P = 0.046). First measured rSO 2 was 38% (27 to 67) in the survivor group compared with 22% (8 to 32) in the nonsurvivor group (P = 0.004). Also a signifi cant diff erence was found in mean rSO 2 until 1 minute before ROSC between survivors and nonsurvivors, respectively 46% (40 to 74) and 34% (22 to 42). We observed no signifi cant diff erence in increase of rSO 2 until 1 minute before ROSC between survivors 12.5% (5 to 21) and nonsurvivors 11% (5 to 18) (P = 0.719). Conclusion We observed a signifi cant diff erence in fi rst measured rSO 2 and mean rSO 2 until 1 minute before ROSC between patients with good neurological outcome (CPC 1 or 2) at hospital discharge and patients with worse neurological outcome or nonsurvivors (CPC 3 or 4 or 5). However, no signifi cant diff erence was observed in the increase between both groups. Larger studies are necessary to confi rm these results. of this study were to investigate the association between hemoglobin, cerebral oxygenation (SctO 2 ) and outcome in post-CA patients. Methods A prospective observational study in 82 post-CA patients during hypothermia in the fi rst 24 hours of ICU stay. Hemoglobin was determined hourly together with a corresponding SctO 2 by NIRS and SVO 2 in patients with a pulmonary artery catheter (n = 62). Results Based on 2,099 paired data, we found a strong linear relationship between hemoglobin and average SctO 2 (SctO 2 = 0.70 × hemoglobin + 56 (R 2 = 20.84, P = 10 -6 )). Given the previously suggested SctO 2 target between 66 and 68%, hemoglobin levels below 10 g/dl generally resulted in suboptimal brain oxygenation. Forty-three patients (52%) had a good neurological outcome (CPC 1 to 3) at 180 days post CA. There was a signifi cant association between average hemoglobin above 12. Introduction The purpose of this study was to determine the rate and magnitude of response to hypoxia for three diff erent regional oxygen saturation (rSO 2 ) devices. rSO 2 technologies are focused on absolute accuracy without consideration of response characteristics. Current rSO 2 technologies assume that the oxygen saturation is a fi xed ratio of arterial and venous blood. Cerebral arteries have an oxygenationrelated vasoactivity that may change the arterial/venous ratio during hypoxia. Thus, absolute rSO 2 accuracy may be less important compared with sensitivity to changes in cerebral rSO 2 . Methods Ten subjects completed the study and are included in the analysis. One INVOS sensor (SAFB-SM) was placed on the left side and one Equanox (8000CA) or Foresight (1 July 2007 or 1 July 2005) sensor (alternated between subjects) was placed on the right side of the forehead for bilateral monitoring. Desaturation was induced by adjusting the inspiratory gas mixture of O 2 /N 2 . Desaturation was titrated from room air to achieve a plateau of 70% arterial oxygen saturation (SpO 2 ). Resaturation was induced by rapid change in FiO 2 to 1.0. After 5 minutes of SpO 2 100%, the process was repeated by desaturation to SpO 2 70% and rapid return to SpO 2 100%. Cerebral and pulse oximetry data were recorded during the study and the time of each FiO 2 change and plateau was recorded. rSO 2 levels at 10, 20, 40, 60 and 80% of the total SpO 2 response were calculated for each device to assess the rate of rSO 2 change. The rate of rSO 2 change in seconds and total rSO 2 change were compared. An NSE serum concentration threshold of 90 μg/l predicted poor outcome with a positive predictive value of 0.98 and a sensitivity of 0.51. Three patients survived with good outcome despite an NSE serum concentration >90 μg/l. In two of these patients NSE elevations had been documented prior to cardiac arrest. One patient had a neuroendocrine tumor of the pancreas, the other patient suff ered from encephalitis of unknown etiology and an osteomyelofi brosis. Potential confounders in the third patient were an ovarian carcinoma, the use of an intra-aortic balloon pump and blood transfusions shortly after cardiac arrest. Only 16 of 205 patients with NSE <17 μg/l had poor outcome, the majority of these patients died from causes other than hypoxic encephalopathy. Conclusion In patients with cardiac arrest and targeted temperature management at 33°C, an NSE serum concentration of >90 μg/l strongly indicates poor outcome. NSE producing tumors, acute brain diseases, severe hematologic diseases, use of an intra-aortic balloon pump and blood transfusions need to be considered as potential confounders. An NSE serum concentration of <17 μg/l largely excludes hypoxic encephalopathy incompatible with re-awakening. frequently suff ered cardiogenic shock, had more organ dysfunctions and died more frequently, respectively, with hospital mortality of 79.5% versus 29.1%, P <0.001; see also Figure 1 . Conclusion In patients hospitalized for acute heart failure, both prehospital and postadmission resuscitated cardiac arrest is a severe complication associated with signifi cantly morbidity and mortality. Conclusion Ten percent of patients resuscitated after CA and admitted to the ICU become OD, consisting of up to 31% of the total number of OD in our center. Patients resuscitated after CA who suff er severe irreversible brain damage or are brain dead can thus substantially expand the donor pool. This justifi es extensive resuscitation eff orts, if not to save lives, then to save organs. This might be reassuring for families, staff and the community. Methods This is a retrospective study of 43 polytraumatized patients with head injury who were intubated and treated by the prehospital unit and transported to the trauma center. Patients were grouped according to their BAL into BAL+ (>0.5 mg/l) and BAL-(≤0.5 mg/l). Inclusion criteria were age ≥18, Injury Severity Score ≥16 and head Abbreviated Injury Scale (AIS) ≥3. Physiological parameters and outcome with respect to survival to hospital discharge (STHD) and functional outcomes were analyzed. Severity of injuries was measured using the Trauma-Injury Severity Score (TRISS) and head injury using AIS. Functional outcome was measured using the Glasgow Outcome Scale (GOS), Cerebral Performance Category (CPC) and Glasgow Coma 3.9; 95% confi dence level; P = 0.027), and GCS at discharge was on the border of statistical signifi cance (15 vs. 14; 95% confi dence level; P = 0.05). Other variables (TRISS, AIS, STHD, CPC) did not show statistically signifi cant diff erences among groups. Conclusion Presence of alcohol in the blood had a positive eff ect on neurological outcome but there was no signifi cant diff erence in survival. However, the positive results in neurologic outcome in the BAL+ group may also be due to the fact that this group was younger. The small number of patients in the study is another limiting factor of the interpretation. Therefore, the neuroprotective role of alcohol needs further clarifi cation. In patients with ABI, RHI at admission was signifi cantly reduced compared with healthy subjects (P = 0.003), coinciding with a decrease in circulating endothelial progenitor cells (EPC) (P = 0.002) ( Table 1 ). The RHI recovered in eight patients without development of CeI ( Figure 1 , black), but failed to fully recover by day 12 in three out of four patients that developed CeI (Figure 1 , red). Despite recovery of the RHI within 12 days in these patients (P = 0.003), the EPC count remained signifi cantly lower after 12 days in patients with ABI (P = 0.022) ( Introduction Since most patients with acute brain injury are treated head-up at 30 to 45°, there can be a height diff erence of up to 15 cm between the heart and the ear canal. This causes a diff erence between mathematical CPP and true CPP of up to 11 mmHg depending on the zero reference level used and the body length of the patient (Figure 1 ). We conducted a survey to analyze the current practice on CPP targets and zero reference levels in diff erent ICUs. Methods Neuro-ICU physicians were invited to participate in a survey on ICP and CPP targets and the level of measurement. The results of 30 centers are summarized in Table 1 . Most centers (83.3%) use head-up elevation of 30 to 45° and consider an ICP of 20 mmHg as the threshold to start treating ICP (80%). More variation is noted in minimal and maximal CPP threshold. All centers measure ICP at the ear canal. Twenty-seven centers (90%) measure MAP at the heart, three centers measure MAP at the ear canal. These three centers use >50, 60 and 65 mmHg as minimal CPP and raise the bed to 30 to 45°. The two centers using minimal CPP >60 mmHg do not apply an upper limit. Conclusion Considering the infl uence of position on CPP, the variations among centers and the narrow range of CPP thresholds, future studies and guidelines should describe where MAP is measured. Alternatively, we propose a new formula for CPP: true CPP = MAP(heart) -ICP(ear)height diff erence (heart to ear canal (cm)) × 0.73. Introduction The purpose of this study is to assess the rate of confi rmed infections, antibiotic exposure, and monitoring practices with normothermia protocol utilization for traumatic brain injury patients. Treatment and prevention of fever is a focus of therapy for patients with severe neurological injury as fever has been identifi ed as an independent risk factor for morbidity and mortality [1] . Introduction Osmotherapy with mannitol (Man) or hypertonic saline (HTS) is currently used to treat elevated intracranial pressure after severe acute brain injury (sABI); however, their eff ect on cerebral oxygenation and metabolism has not been extensively evaluated. Methods A retrospective analysis of a cohort of patients with sABI after traumatic brain injury (TBI) and subarachnoid hemorrhage (SAH) monitored with cerebral microdialysis (CMD), brain oxygen (PbtO 2 ) and ICP, who were treated with Man (20%, 0.5 g/kg) or HTS (7.5%, 100 ml) for ICP >25 mmHg. Osmotherapy was administered over 20 minutes and each patient's individual response to intervention was analyzed up to 120 minutes following infusion. Only episodes where no other hypertonic solute was administered within 2 hours before or after treatment were selected. Variables analyzed included CMD lactate, pyruvate, glucose, glutamate, lactate/pyruvate ratio, and main brain physiologic variables ICP, PbtO 2 , CPP. Analysis was conducted using mixed-eff ects multilevel regression.  biomarkers, of long-term outcomes. Among these, ubiquitin carboxyterminal hydrolase L1 (UCH-L1) is currently being investigated to defi ne its potential prognostic value. The objective of this systematic review is to determine the ability of UCH-L1 to predict prognosis following a moderate or severe TBI. Methods The MEDLINE, Embase, The Cochrane Library and BIOSIS electronic databases, conference abstracts and existing narrative reviews were searched from their inception to July 2013. Cohort studies including patients with moderate or severe TBI having evaluated the prognostic value of UCHL-1 according to mortality or the Glasgow Outcome Scale (GOS) were considered. Data concerning patients, outcomes, study methods, and laboratory methods were abstracted. Pooled results were planned to be presented using mean diff erences and analyzed using random eff ect models, as well as sensitivity analyses to explain potential heterogeneity. Results Our search strategy yielded 2,257 articles, of which fi ve studies corresponded to our inclusion criteria (n = 730). All studies were performed by the same group of researchers. Five studies reported mortality (n = 515), two studies reported GOS (n = 58). Results from all included studies observed that UCHL-1 was a signifi cant predictor of mortality. However, only two studies represented a unique study population, thus precluding a meta-analysis. Conclusion In this systematic review, we observed that all published studies on UCHL-1 were conducted by the same group of investigators and presented results from an intersecting cohort of patients. Due to the paucity of data, we could not perform a pooled analysis and conclude on the association of this biomarker with long-term prognosis. Assays using UCHL-1 were only recently developed and further studies done by diff erent research teams will be needed to determine the reproducibility and validity of UCH-L1 as a potential prognostic tool. Introduction ICU patients may remain comatose after resolution of critical illness. Frequently this is due to delayed sedative clearance but may also result from increases in intracranial pressure (ICP) and cerebral edema. We proposed that measurement of the optic nerve sheath diameter (ONSD) is a rapid, bedside screening test that can be used to quickly identify patients with cerebral edema and increased ICP. Methods This was a prospective, observational study carried on consecutive patients admitted to a multidisciplinary medical and surgical ICU. Stable patients with unexplained coma and scheduled for brain imaging were included. Patients with obvious ocular trauma or on sedative, narcotic infusions were excluded. ONSD was measured using a 7.5 to 10 MHz linear array ultrasound transducer probe placed on the closed eye in the transverse axis. The ONSD was measured at a predefi ned point 3 mm posterior to the globe. Both eyes were measured and the mean value used. Introduction Increased intracranial pressure (ICP) adversely aff ects anesthesia due to a disturbed cerebral blood fl ow. In older patients this disturbance may increase the incidence of postoperative delirium (POD) and may lead to a poor outcome [1] . The standard hemodynamic protocol involves maintaining the mean arterial blood pressure (MAP), but in patients with intracranial hypertension it may not be enough to maintain adequate cerebral perfusion. The purpose of this study was to evaluate the protocol of maintaining cerebral perfusion pressure (CPP) in the prevention of postoperative delirium in older patients in abdominal surgery. Methods A total of 132 ASA 3 patients, undergoing major abdominal surgery (duration 5.2 (4.3 to 6.5) hours) with ICP >12 mmHg evaluated by a venous ophthalmodynamometry [2] , were included in our research. Patients were randomized into two groups: MAP group, in which MAP was maintained above 70 mmHg or within 20% from baseline (n = 78); or CPP group, in which CPP was maintained above 60 mmHg or within 20% from baseline (n = 54). ICP, MAP and CPP were assessed every hour of anesthesia. Time of recovery of consciousness, incidence of POD and length of stay in the ICU and in the hospital were also evaluated. Results Initial ICP was 14 ± 3 mmHg in the MAP group and 15 ± 2 mmHg in the CPP group. During the anesthesia it was stable without any signifi cant change. Decreasing of MAP after induction of anesthesia was similar in two groups and it was stable during the anesthesia. The frequency of use of vasopressors and infusion rate was higher in the CPP group. Time of recovery of consciousness in the MAP group was higher (28 ± 7 minutes vs. 18 ± 5 minutes (P <0.05)). The incidence of postoperative delirium was higher in the MAP group (18% vs. 11% in the CPP group (P <0.05)). There were no signifi cant diff erences between two groups in other complications. Total length of stay in the ICU and in the hospital was higher in the MAP group (6 ± 2 days vs. 4 ± 2 (P <0.05) and 15 ± 3 days vs. 12 ± 2 in the N group (P <0.05)). Introduction In critically ill patients, blood lactate on admission is associated with outcome, but in patients with aneurysmal subarachnoid hemorrhage (SAH) this has not been investigated. We studied the association of early circulating lactate and glucose with unfavorable disease course. The prognostic role of both lactate and glucose was studied, hypothesizing that both may be increased due to sympathetic activation after SAH [1] . The results of studies attempting to assess the risks of ischemic stroke in patients with burn injury have been confl icting. We investigated the risks of ischemic stroke in hospitalized burn injury patients in Taiwan to evaluate whether the risk is higher compared with the general population. Methods The data from 1 million National Health Insurance bene fi ciaries were utilized. All adult benefi ciaries were followed from 1 January 2005 until 31 December 2012 to identify those who developed ischemic stroke. Meanwhile, each identifi ed patient with burn injury was matched with 100 unexposed patients based on the high-dimensional propensity score. Cox regression models were applied to compare the hazards of ischemic stroke in the matched cohorts. Introduction Muscle wasting is a common consequence of longterm stay in the critical care environment, which may slow down the rehabilitation of survivors. Previous ultrasound studies have demonstrated a loss of cross-sectional area of lower limb muscles during a 10-day intensive care stay. In this study, we have looked at how markers of muscle architecture (muscle thickness, pennation angle and fascicle length) change in the lower limb, as well as looking at changes in muscle thickness in the upper limb. Methods Following ethical approval, patients who were intubated and ventilated in one of two critical care departments were assented to take part in the study by their next of kin. B-mode ultrasound scans of the right biceps, vastus lateralis and the medial head of gastrocnemius were performed on days 1, 5 and 10. Scans were not performed in patients once they were free of sedation. Muscle thickness (MT) was measured in all three muscles, with pennation angle (PA) being measured in the lower limb muscles. Fascicle length (FL) was derived from PA and MT. Results Twenty patients were recruited, of which 15 were scanned on day 5, and eight were scanned on day 10. In the biceps, there were no alterations in MT over 5 or 10 days. MT of the vastus lateralis signifi cantly decreased on day 5 (1.77 ± 0.06 mm muscle loss, P = 0.03) and day 10 (5.58 ± 0.09 mm muscle loss, P = 0.01). There was also a signifi cant loss in PA over 5 days (1.48 ± 0.63°, P = 0.01) and 10 days ( [1]. The presence of delirium in critical care is an independent risk factor for mortality; for every day of delirium, there is an additional 10% relative risk of death at 1 year [2] . A delirium prediction tool PRE-DELIRIC has been recently developed and calibrated in a multinational project [3] . This study aimed to determine the utility of PRE-DELIRIC on our ICU. Methods This study prospectively investigated 41 patients. Medical and surgical general ICU patients were included after 24 hours of sedation and mechanical ventilation. The researchers calculated PRE-DELIRIC scores for each patient. PRE-DELIRIC involves recording 10 variables, submitted into an online algorithm that estimates the percentage risk of delirium. We diagnosed delirium with the CAM-ICU which was performed 12 hourly [4] . The PRE-DELIRIC scores predicted a mean rate of delirium of 39%. PRE-DELIRIC risk scores ranged from 4 to 93% (Figure 1 ). Six (15%) patients developed delirium in the fi rst 24 hours following extubation. Fifteen (37%) of patients were predicted 20% or less probability of delirium. Twelve (29%) patients developed delirium at any point during their ICU stay. This resulted in 36 total delirium bed-days. Conclusion Our observation that <30% of patients experienced delirium is less than the reported prevalence in similar settings and our own audits. This study demonstrates that there is some agreement between recorded rates of delirium and predicted rates using PRE-DELIRIC. We suggest that PRE-DELIRIC can be used in quality/audit work on UK ICUs in order to assess attempts to improve the management of delirium. Further work is required to assess the utility of PRE-DELIRIC as a risk assessment tool in individual patients. The application of xenon increases erythropoietin levels with a maximum 24 hours after exposure (1.32 (0.99 to 1.66) P = 0.033) compared with the baseline values and compared with control values (0.87 (0.68 to 1.05) P = 0.012, Figure 1 ). Xenon was gas chromatographically traceable in blood and exhalation probes up to 24 hours after exposure. (Figure 1 ). Conclusion Etomidate use is associated with lower postoperative SVRI which is increased in the presence of G homozygosity for TNFβ polymorphism. The planned analysis for determining the discriminatory and predictive ability of the decision tree HEWS will be conducted with area under the receiver operating characteristic curves. We will test whether the current HEWS has the appropriate sensitivity and specifi city when compared with that of the decision tree score. The AUROC will be calculated for both the training set of data as well as the separate population of additional medical and surgical patients. The two scores will also be plotted along an effi ciency curve, comparing the percentage of vitals that precede a critical event with the percentage of vitals that produce a EWS value greater than or equal to a given EWS value. Conclusion Decision tree analysis methodology with real-life vital signs can produce an EWS superior to previous observational studies. Using a decision tree, especially one that composites all vitals, may show that certain vitals are more predictive of critical events than others. Data will be used to further improve our current HEWS score. The median delay to admission was 22 hours (range 41 to 167 hours). The median geodesic distance was 18 km (range 1 to 141 km), and road distance was 24 km (range 2 to 180 km). Correlations between time delay and geodesic/road distances were weak ( Figure 2 , R 2 = 0.015 and 0.011, respectively). Transfer delays in the daytime and overnight were similar (Wilcoxon rank sum, P = 0.6). Conclusion Interhospital transfers are subject to clinically signifi cant delays, and substantial travel distances. Delays are only weakly correlated to distances travelled and may refl ect delays resulting from organisational ineffi ciencies. We infer that eff orts to improve the effi ciency of transfer should focus on local organisational issues. There was no diff erence in the duration taken for overnight versus daytime transfers. The WHO functional status was the most signifi cant variable aff ecting admission (P <0.001). The APACHE score of patients admitted to ITU was signifi cantly lower than refused patients (P = 0.039). Patient age did not aff ect admission status (P = 0.15). See Table 1 . Introduction This Six Sigma project was initiated to evaluate and improve the transfer of care of patients from the OR to the ICU. Medical errors are responsible for billions of dollars in increased healthcare spending. Miscommunication among healthcare providers is a major contributor to these errors, with handoff s a particularly vulnerable period in the care process. At our institution, surgical patients with scheduled admissions to the ICU are fi rst recovered in the postanesthesia care unit (PACU). With this process, multiple, unstructured, and individual handoff s occur in parallel between providers, which may lead to communication errors, diff erential information sharing, content variability, care delays, and ineffi ciency. Methods A multidisciplinary QI project was initiated with input from the ICU, anesthesia and surgical services. A series of PDSA cycles were conducted, which began by defi ning the current process via direct observation and value stream mapping of orthopedic and neurosurgical patients. A new process was then introduced, including direct transfer of the patient to the ICU and a single, structured, bedside report between all care providers. A standardized handoff tool was implemented. We used process times, wait times and information content as process measures and handoff errors as outcome measures. A 10-point satisfaction score was also measured. Results Following implementation of the new transfer process, the average wait time decreased by 58 minutes, process time decreased by 9 minutes, and lead time decreased by 66.5 minutes. The handoff error rate decreased by 1.3 errors/patient and fi rst-time quality rate increased by 67%. Staff satisfaction improved from 48% to 73%. By elimination of the PACU stay, the costs involved in admission to the PACU were deferred. Conclusion A single, multidisciplinary bedside handoff process between the OR and ICU leads to cost and time savings. By elimination of redundant, nonvalue-added processes, less opportunity for medical errors occurred, with substantial improvements in fi rst-time quality. Such a process can be successfully attained while aff ecting staff satisfaction positively. Introduction Prolonged hospital stay prior to admission to the ICU was previously shown to be independently associated with poorer outcome [1, 2] . This is probably due to slow deterioration of physiological function in hospital and infl uenced by processes leading to critical care admission [2] . We investigated whether commonly measured severity scoring systems (Acute Physiology and Chronic Health Evaluation (APACHE) II, Intensive Care National Audit and Research Centre (ICNARC) and Sequential Organ Failure Assessment (SOFA) scores) are signifi cantly diff erent in patients admitted with prolonged pre-ICU hospital length of stay, and describe mortality and hospital length of stay. Methods A retrospective analysis of prospectively collected data of all emergency admissions in the ICNARC database of a 44-bed adult critical care unit within a major trauma centre over a 2-year period. Demographic data, APACHE II score, SOFA score, ICNARC model score, mortality, and length of hospital stay prior to and after ICU admission were collected. Five groups of patients were defi ned as follows: those admitted to ICU within 1 week of hospitalization (group 1), within 8 to 14 days (group 2), within 15 to 21 days (group 3), within 22 to 28 days (group 4), and more than 28 days (group 5). Chi-squared and ANOVA tests were performed using the SOFA statistics package. Results A total of 2,248 emergency admissions were analysed. The majority of patients were admitted within 1 week of hospital admission (n = 1,897). They were younger and had lower APACHE II scores (15 vs. 19; P <0.001). APACHE II scores were the same in all other groups (groups 2 to 5). Patients admitted to the ICU 3 weeks following hospital admission had signifi cantly higher hospital mortality (up to 50%; P <0.001) and ICU length of stay (12 ± 15 vs. 8 ± 10 days; P <0.001). ICU mortality remained the same in all groups (20 to 28%). ICNARC and SOFA scores were equal between the groups. The post-ICU lengths of stay were signifi cantly longer in groups 3 to 5. In-hospital CPR prior to admission to ICU was lower in patients from groups 4 and 5, probably signifying appropriate DNAR decisions made on the ward. Conclusion Prolonged pre-ICU hospital admission is associated with higher hospital but not ICU mortality. Commonly measured scores do not refl ect this higher mortality in patients admitted after prolonged stay in hospital. Further research into parameters that may refl ect changes in physiological reserves may strengthen these scores for such patients. Introduction Hospital costs are a constant concern within health, especially in the ICU. Hospital admissions and average life expectancy have been growing gradually mainly in older and critical patients. This study is aimed to observe the direct costs of patients admitted to an ICU and their relation to the SAPS 3, length of stay in the ICU and fi nal outcome. Methods A retrospective observational study in which the direct costs were studied (materials, medicines, oxygen therapy and hospital fees) for 1,790 ICU patients from November 2013 to November 2014. The readmissions within 48 hours were excluded and also 10% of patients who had the highest and lowest costs. The remaining 1,401 patients were divided by age groups. Of the patients studied, 54.6% were male. Average age was 57.8 years (18 to 105 years). The biggest ICU average cost was in the group of patients 81 to 90 years old (US$793.00), as well as longest ICU stay (9.25 days), highest SAPS 3 (53.96) and higher ICU and in-hospital mortality (14.29% and 19.25% respectively). This study shows that the direct cost of the ICU stay for older patients was higher than for younger patients. The diff erence was explained by the higher severity measured by SAPS 3 in the older age groups (Figure 1) , and the required greater length of stay in the ICU ( Figure 2 ). As might be expected, the mortality in the group of older patients was also signifi cantly higher. Conclusion This study showed that greater age is associated with higher severity measured by SAPS 3, higher direct costs, and higher mortality both in the ICU and in-hospital environment. Introduction Pregnancy and labour usually progress uneventfully; however, serious complications can occur and develop rapidly, necessitating critical care admission and support. Successive confi dential enquires have highlighted defi ciencies in this area and suboptimal care leading to increased morbidity and mortality [1] . The National Maternity Hospital is the largest maternity hospital in the Republic of Ireland where a total of 8,954 babies were delivered in 2013. It is a stand-alone institution and onsite facilities include a twobed dedicated anaesthesia lead high-dependency unit. Methods A retrospective observational study was carried out from January 2011 to January 2014 especially looking at the following parameters: admitting diagnosis, demographics, length of stay and the number of admissions requiring transfer for tertiary-level care. In total, 29,344 deliveries occurred. A total of 376 HDU admissions were recorded in this period, representing 1.28% of all admissions. The average age of patients admitted to the HDU was 34 years. The predominant reasons for admission were hypertensive disease of pregnancy (49.7%), haemorrhage (antepartum/postpartum) (36.4%), sepsis (4.2%) and other reasons (11.1%) including cardiac rhythm disturbances, neurological complications and pre-existing medical disease. In 2013 the average length of stay was 2 days. A total 6.1% of those admitted to HDU required transfer for tertiary-level ICU care in other centres during the study period, this represented 0.07% of all deliveries. Conclusion There is signifi cant demand within our institution for HDU care for our patients, with the number of admissions increasing in 2013. The main admitting diagnoses are hypertensive disease of pregnancy and haemorrhage with an increase in the number of patients being admitted for management of sepsis in 2013. This highlights the increasing awareness, recognition and management of this condition in pregnancy. The increased number of HDU admissions in 2013 could also be explained by the recent introduction of an early warning score for the deteriorating patient in our hospital but this would require further evaluation. The low number of transfers of patients to other tertiary centres underpins the importance of an anaesthesia lead service. A total of 389 patients with a mean age of 68.7 years were identifi ed. Frail patients were signifi cantly more likely to need vasopressors postoperatively (P = 0.012). Each increase in frailty score was associated with 0.16 increase in length of stay on the HDU (P = 0.025). Analysis of patient location at 30 days shows that frail patients stay in hospital longer (P = 0.00). Frail patients also bleed more intraoperatively (P = 0.00 with a coeffi cient value of 239; that is, for every point increase in frailty, average blood loss increases by 239 ml). For each increase by unit of blood transfused, the length of stay increased by 5.3 days (P = 0.000). The use of epidural is not associated with increased need for postoperative vasopressors (P = 0.598). See Figure 1 . Conclusion Frailty is associated with increased intraoperative resource use and postoperative care requirements independent of choice of anaesthetic technique. This type of surgery should be subject to health economic analysis as demand amongst the frailer surgical population increases. References demographics, physiological measurements and coexisting conditions and can be used to evaluate ICU performance, to stratify patients in clinical trials and to assist in-hospital and healthcare decisions such as resource allocation. The aim of the project was to determine whether a general score derived from routine laboratory parameters could be used to predict mortality rates in patients admitted to the ICU in the UK. Methods P values were calculated using the t test, Mann-Whitney U test and chi-squared test, depending on distribution of data, in order to determine which variables were signifi cantly diff erent in the survivors and nonsurvivors of critical illness. Signifi cant variables were categorised into subgroups according to medically relevant landmarks and univariately analysed by assessing the correlation with mortality. Forward logistic regression models were used to choose the parameters to include in our score. ROC curves illustrated the sensitivity and specifi city of selected variables via their AUC. Results Age, platelets, ALT and APACHE II were selected to be included in the new laboratory-based score. The AUC for the score was 0.714, which was higher than each of the individual laboratory parameters. The AUC was increased further to 0.781 by including all 14 variables (age, lactate, FiO 2 , urea, creatinine, ALT, APACHE II, platelet, bicarbonate, haemoglobin, pH, ionised Ca, carboxyhaemoglobin and albumin), although this improvement was not considered signifi cant as the confi dence intervals of the two scores (4 and 14 variables) overlapped. Conclusion A laboratory-based score was successfully established in ICU patients, revealing an AUC of 0.714 which is comparable with established scores in a similar population. The compilation of the variables to produce a laboratory-based score showed greater prognostic power than individual variables. Model developers require an AUC of >0.7 to be termed useful; however, in order to be used in a clinical setting the AUC must be at least 0.75. Further research including internal and external validation studies must be performed to optimise the model before clinical implementation. Among ICU patients a high level of trait anxiety is relatively common and associated with intrusions, a symptom of PTSD. Independently, childhood trauma and stress exposure throughout life have been associated with depression. In cardiac surgery patients admitted to the ICU postoperatively, the eff ect of trait anxiety on the relationship between cumulative life stress and stress-related psychopathology remains unknown. Therefore we aimed to assess the mediating or moderating role of trait anxiety in this at-risk patient population. Methods In this multicenter follow-up study of the Dexamethasone for Cardiac Surgery (DECS) trial, validated self-report questionnaires were sent 1.5 to 4 years after cardiac surgery and ICU treatment to assess symptoms of PTSD and depression, in relation to cumulative life stress (that is, childhood trauma, major stressful life events) and trait anxiety as determinants of psychopathology. Data were available for 1,125 out of 1,244 (90.4%) eligible participants. Mediating and moderating analyses were performed with multivariable linear regression to assess the eff ect of trait anxiety. Subgroup analyses were performed for both sexes. Results Trait anxiety partially mediates the relationship between cumulative life stress and PTSD (β-value reduction from 0.325 to 0.068; P = 0.000 to P = 0.003) and fully mediates the association between cumulative life stress and depression (β-value reduction from 0.282 to 0.015; P = 0.000 to P = 0.507). Trait anxiety was not a moderating factor between cumulative life stress and psychopathology. Full mediation of trait anxiety was found in female patients (n = 247), whereas only partial mediation was seen in male patients (n = 878) with regard to PTSD symptoms. As for depression, full mediation was present in both female and male patients. Conclusion In cardiac ICU patients, trait anxiety mediates the infl uence of cumulative life stress on the occurrence of PTSD and depression symptoms. Further prospective research is necessary to establish these factors as reliable measures for the early identifi cation of ICU patients at risk for stress-related psychopathology. Introduction Although the ICU survival rate has increased in the last decade, the negative eff ects on mental health and related quality of life become more clear. In the literature the prevalence of anxiety and depressive symptoms post ICU ranges from 10 to 43% [1] . Early recognition and treatment of anxiety and depressive symptoms is important because depression caries a risk for suicide, limited quality of life, and delayed return to work. We studied hospital anxiety and depression (HAD) symptoms after ICU discharge. correction for natural decline in HRQOL, the mean scores of four dimensions -physical functioning (P <0.001), physical role (P <0.001), general health (P <0.001) and social functioning (P = 0.003) -were still signifi cantly lower 5 years after ICU discharge compared with their preadmission levels, although eff ect sizes were small (<0.5). Conclusion Five years after ICU discharge, survivors still perceived a signifi cantly lower HRQOL than their preadmission HRQOL (by proxies), and that of an age-matched general population. Importantly however, after correction for natural decline, the eff ect sizes were small suggesting that patients regain their age-specifi c HRQOL 5 years after their ICU stay. Introduction ECMO support in ARDS is an emerging strategy when conventional treatment modalities fail. ECMO has advantages on oxygenation and circulation but also it has some unfavorable eff ects. The most serious complication is brain death due to cerebrovascular hemorrhage. An apnea test is the most important component in confi rming brain death. For patients supported by ECMO, apnea testing remains challenging. Brain-death diagnosis is often made without an apnea test. The ability to return to the hospital and talk to medical assistants was considered by parents as a positive and enlightening opportunity. Parents who participated in the study understood this moment as an opportunity to be heard and demonstrated the intention to contribute with their experiences in order to improve care in the hospitals studied. Conclusion We conclude that there is a need to implement measures to provide palliative care to parents after the death of their children. It is necessary to consider the possibility of providing families with follow-up meetings with the multidisciplinary team after the death of children. priorities for improvement: provide families with a guide/navigator; educate providers about the fragility of family trust; improve provider communication skills; inform patients about the long-term eff ects of critical illness; and develop strategies to facilitate continuity of care between providers. Conclusion Patients and family members are an untapped resource and engaging them as researchers is a viable strategy to identify opportunities for quality improvement that are patient and family centred. Introduction The purpose of this study was to assess the visiting restrictions placed on families visiting adult patients on critical care units within trauma hospitals in England. Whilst it is well recognised that high-quality care for patients is of paramount importance, we should also be aware that supporting patients' families off ers longterm benefi ts for patient, family and hospital. In our own unit we are reviewing whether we could adopt a more fl exible attitude to visiting times and assessing how to provide a more welcoming environment to relatives. To inform our own review and in order to develop a best practise approach, we surveyed all of the major trauma centres in England. 