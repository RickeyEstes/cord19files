Consider comparing an experimental treatment (E) with standard therapy (S) for Middle East Respiratory Syndrome Coronavirus (MERS-CoV) motivated by a sudden increase in the number and geographical spread of incident cases. Randomisation is 1:1. We choose D = 28 days and outcome categories C 1 : alive and not receiving ventilation; C 2 : alive and receiving only non-invasive ventilation; C 3 : alive and receiving invasive mechanical ventilation and C 4 : dead. Data from an observational study [8] of 70 patients yield estimates of the probabilities of these four outcomes occurring for patients on S of 0.286, 0.043, 0.214 and 0.457 respectively. In Table 1 , these four outcome probabilities form Column 2. In the first of 12 sets of simulations, one million replicate runs of GOST were conducted in which these outcome probabilities governed the responses both for patients receiving S and for those receiving E. The results are shown in the second column of Table 2 . The proportion of trials in which E won was 0.025; equal to the intended one-sided type I error rate, confirming the accuracy of the procedure. In the second set of simulations, outcome probabilities for patients receiving S were unchanged, but a common odds ratio of R = 1.5 was imposed and the respective probabilities 0.375, 0.048, 0.217 and 0.359 (shown in Column 3 of Table 1 , and reflecting a shift to better outcomes) were used to generate patient outcomes on E. For the third set of simulations, the outcome distribution on S was again unchanged, but R was increased to 2. The results are shown in Column 4 of Table 2 , showing that the intended power of 0.90 was achieved. Nine more simulation runs were conducted. The outcome distributions for patients on S were changed to those shown in bold in Table 1 under Scenario 2, and then as shown for Scenarios 3 and 4. For each scenario, three outcome distributions on E were explored, corresponding to R = 1 (no treatment effect), 1.5 and 2. Scenario 2 uses a rounded version of the estimated distribution on S to demonstrate that precise values are unnecessary at the design stage. Scenario 3 represents a more extreme situation in which all patients either leave intensive care or die by Day 28, while in Scenario 4, most patients leave intensive care by Day 28, with the other three categories being unusual. Values reported in Table 2 for Scenarios 1 and 2 are virtually indistinguishable, but more patients are needed in the case of Scenario 3 or 4. When interpreting the simulation results shown in Table 2 , it is important to distinguish between what the trial designer anticipated as the truth before starting the trial and what was actually true. All simulations represent trials in which the investigators anticipated that Scenario 1 was true, even if they were wrong. As explained in the Supplementary Information (S1 Text), if Scenario 1 is true, then a maximum sample size of 440 will be sufficient to ensure that V eventually reaches the value where the stopping boundaries in Fig 1 meet, Table 2 . Having set the design and forecast its properties assuming Scenario 1, the simulations are then conducted under the twelve different models displayed in Table 1 . For Scenario 1, with R = 1, 1.5 or 2, the investigators' predictions are confirmed as being very accurate: average Table 3 presents data from a single simulated run of GOST and Fig 6 shows the resulting plot. This fictitious trial stopped at the 11 th interim analysis with 242 patients, and E won. Using the approach described in [1] , the one-sided p-value is found to be 0.016. The median unbiased estimate of the log-odds ratio Î¸ is 0.568 with 95% confidence interval (0.059, 1.062). For the odds-ratio R, the median unbiased estimate is 1.76 with 95% confidence interval (1.06, 2.89). The simulation did not generate patient data that would be received by the investigators after this analysis, but in practice results would come in from study patients who were still being followed to 28 days at the time the data for the 11 th interim analysis were extracted, and those who were recruited while that analysis was being undertaken. Provided that no change was made to the treatment of these patients, they could be included in a subsequent overrunning analysis [7] , and this would become the definitive interpretation of the trial results. We conclude this section with a brief account of the changes that would follow if the investigators chose to dichotomise patient responses into alive at 28 days (C 1 , C 2 or C 3 ), or dead (C 4 ). Taking the rounded outcome probabilities of Scenario 2, and then combining those relating to the first three categories, leads to Scenario 3. GOST can be applied to such binary data, and equations E4 in S1 Text provide simplified versions of the test statistics. However, binary data are less informative than the ordinal version of the data, and it will now take 520 patient responses to ensure that V eventually reaches the value where the stopping boundaries in The inflation in sample size due to dichotomising the ordinal scale is a factor of 1.18: an 18% increase in sample size. Additional simulations conducted using 26 new binary responses per interim analysis confirmed that the intended type I error rate 0.025 and the power of 0.90 were achieved, but the increase in average final sample sizes relative to those for the ordinal approach reported for Scenarios 1 and 2 in Table 2 ranged from 17% to 26%.  