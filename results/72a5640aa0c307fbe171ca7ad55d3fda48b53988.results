The initially applied PEEP and the determined optimal PEEP did not differ significantly. Compared with baseline (T0) the PaO 2 was significantly higher following alveolar recruitment (T ep ) and also after 60 min. The EVLW did not change significantly during the study period (Table 1) . Regression analysis could not reveal any significant relationship between PaO 2 and EVLW at different PEEP. The average difference between the groups is 8 days less seal time (P < 0.001), 11 days less weaning time (P < 0.001), and 9 days less, on average, time spent in ICU (P < 0.001). Conclusions The use of PAB in comparison with the exclusive use of a thoracic drain with a water seal for the treatment of PAL in ARDS is an effective, inexpensive and simple method that decreases the ventilator weaning time and makes for a shorter stay in the ICU. Table 1 The increase between day 1 and day 7 of respiratory values of studies Introduction Open lung biopsy (OLB) is regarded as the gold standard for the diagnosis of pulmonary infiltrates. This procedure is associated with significant risk of morbidity and mortality in the intensive care unit (ICU) setting. We wished to study the efficacy of open lung biopsies in ICU patients requiring advanced respiratory support associated with bilateral pulmonary infiltrates. Methods We reviewed medical case records of all patients who underwent open lung biopsy on the ICU between August 1996 and June 2003. We included patients requiring advanced ventilatory support, with persistent bilateral infiltrates on chest X-ray failing to respond to first-line treatment. The biopsies were performed in the ICU at the University Hospital of Wales under general anaesthesia. Access to the lung was via anterior mini thoracotomy. All operative lung samples were sent for bacteriology Gram staining and culture, virology and histology assessment. We performed 13 OLBs in the study period. The patient demographics (survivors versus nonsurvivors) are presented in Table 1 . Open lung biopsy provided a diagnosis in 12 out of 13 patients (92%). In all 12 of these patients specific treatment changes were implemented. Overall mortality was 53.8% Conclusion OLB in critically ill patients is an accurate diagnostic tool. Background Acute respiratory distress syndrome (ARDS) is characterised by the development of noncardiogenic pulmonary oedema leading to refractory hypoxaemia. The early clearance of alveolar oedema is an important determinant of outcome in ARDS. β-agonists have been shown to upregulate alveolar fluid clearance (AFC). The primary aim of this study was to determine the concentration of salbutamol achieved in plasma after treatment with intravenous (IV) salbutamol. A second aim was to determine the concentration of airspace salbutamol required to stimulate AFC in the normal rat lung. Methods Patients with acute lung injury/ARDS were randomised to an infusion of IV salbutamol (15 µg/kg/hour) or placebo. Plasma salbutamol levels were measured by a commercially available ELISA before and 24 hours after starting the infusion. In a second series of experiments AFC was measured in rats in response to 10 -4 M to 10 -8 M salbutamol as previously described [1] . Results Twelve patients were recruited (six received placebo). Median plasma salbutamol levels were 408 ng/ml in the salbutamol-treated group (equivalent to 10 -6 M) compared with undetectable in the placebo group (P = 0.001). Basal AFC in rats was 7.6 ± 2.2% hour. Salbutamol (10 -6 to 10 -5 M) increased AFC by 100% and 400%, respectively, above baseline (P < 0.05). Introduction SARS is caused by a newly described coronavirus [1] . About 20% of SARS patients require oxygen supplementation and mechanical ventilation in an ICU for respiratory failure and ARDS [2] . We aim to describe the CT findings of patients in the late stage of ARDS caused by SARS, and report changes on longterm follow-up. Methods A retrospective review of CT findings in eight patients who met CDC criteria for SARS. All patients met criteria for ARDS [3] . CT was performed in late-stage ARDS (more than 2 weeks after onset of ARDS) [4] , and after discharge from hospital in survivors. Relevant respiratory and ventilatory parameters, total steroid dose and outcome were recorded. All mechanically ventilated patients received low pressure (peak pressure < 30-35 mmHg), low volume (tidal volume < 8 ml/kg estimated lean body mass) ventilation [5] . Five patients received prolonged mechanical ventilation (over 14 days), one was only ventilated for 72 hours, and two patients were not ventilated at all. All patients received high-dose pulse methylprednisolone (2.5-7 g total dose). Three patients died and five survived to hospital discharge. ARDS chronic stage CT findings Consolidation was present in five patients. Ground glass opacification and interstitial thickening were present in all patients. Three had evidence of fibrosis. Small pulmonary cysts were present in five patients and extrapulmonary gas (pneumothorax) in two. Findings in patients after long-term mechanical ventilation (more than 14 days) and short-term or no ventilation were similar. At follow-up CT (mean 3 months, n = 4), consolidation and extrapulmonary gas had resolved, ground glass opacification improved, but signs of fibrosis had generally progressed. The cause of ALF was paracetamol overdose in 19 patients, NANB hepatitis in eight patients, and acute Budd-Chiari syndrome in five patients. The remaining eight patients suffered from acute hepatitis B virus infection, Wilsons disease, drug-induced liver failure and autoimmune hepatitis. Twenty-eight patients (70%) were transplanted and 24 survived to hospital discharge. Of the 12 nontransplant patients only one survived. A diagnosis compatible with ALI was found in 23%, with no difference between transplant and nontransplant patients. The median PaO 2 /FiO 2 ratio (P/F) was 167 in ALI patients against 283 in nonlung injury patients (Mann-Whitney U test, not significant). Only two patients (5%) were taken off the transplant list due to a combination of refractory hypoxia and multiple organ failure. Transplant and nontransplant patients did not differ in terms of P/F, positive end expiratory pressure (PEEP), EVLWI or permeability index. Poor outcome was not associated with low P/F, CXR signs of ALI, high EVLWI or permeability index. Bilateral infiltrates on CXR correlated with PEEP (P = 0.004), EVLWI (P = 0.001) and permeability index (P < 0.001) but not with P/F. Focal lung infiltrates did not correlate with the above parameters. Twelve patients without CXR findings of ALI had significant impaired gas exchange P/F < 200, suggesting an extrapulmonary reason for hypoxia. Conclusion One-quarter of the patients with ALF in our series showed signs of ALI. Severe lung injury in the peri-transplant period was not associated with a high mortality. Hypoxia is nonspecific for the diagnosis of ALI and should not be used as a sole determinant to remove patients from the transplant list. The EVLWI and the permeability index are readily available bedside parameters for the diagnosis of ALI; however, they did not correlate with patient outcome. Objectives To determine the incidence of pulmonary dysfunction in comatose patients with severe traumatic brain injury and to evaluate the effect of respiratory failure on neurological outcome. Methods A retrospective study of 68 trauma patients, 18 females (26.47%) and 50 males (73.53%), admitted to the ICU from July 1998 to July 2003 with isolated brain injury and a Glasgow Coma Score (GCS) of 9 or less, all under sedation and mechanical ventilation on admission. Patients enrolled in the study were aged from 16 to 83 years, with a mean age of 40.28 ± 20.73 years. Pulmonary function was evaluated at the latest by the fourth day of hospitalization, using the Lung Injury Score (LIS) with the following components: chest radiographic findings, PaO 2 /FiO 2 and positive end expiratory pressure. A LIS of zero was defined as normal pulmonary function, a LIS of 0.1-2.5 as mild to moderate dysfunction, while a LIS of more than 2.5 as severe pulmonary dysfunction. The maximum LIS was taken in consideration for statistical analysis. The patients' brain computerised tomography (CT) scan on admission was graded using the Marshall CT scoring system. The Glasgow Outcome Scale (GOS) was used after a 30-day follow-up of the population, as good recovery (1), moderate disability (2), severe disability (3), vegetative state (4), death (5)considering good outcome as (1) and (2) and bad outcome as (3), (4) and (5) . The mean value ± SD was calculated for all data. The correlation of all variables was assessed and the outcome was evaluated. The GCS on admission was 6.47 ± 1.89. The maximum LIS was recorded before the fourth day of hospitalization (3 ± 1) with a mean value of 3.34 ± 0.86. Six patients (8.8%) had normal pulmonary function, while 59 (89.7%) had mild to moderate dysfunction and one patient (1.47%) had severe pulmonary dysfunction. Based on the GOS 47.1% (32/68) had good outcome and mortality reached 25% (17/68). Moderate statistical correlation was found between the LIS and GCS (correlation coefficient r = -0.51), and also between the LIS and GOS (r = 0.52), while the GCS and GOS were inversely related (r = -0.78). Sixty-one patients (89.7%) presented a relation between LIS and CT score (r = 0.64). The remaining nine patients (13.23%) did not show a relation between LIS and CT score, as aspiration prior to intubation, atelectasies and mechanical ventilation with overdistension of the lung aggravated pulmonary function directly and independently from the neurological status. Conclusions Although in clinical practice we experience a strong relation between LIS and CT scan findings for patients with severe traumatic brain injury, this was evident in 89.7% of the population studied. Pulmonary dysfunction was not an isolated complication in patients with brain injury showing poor prognosis, but rather represented the first manifestation of a systemic disease. A broader study should be performed in order to assert these findings. Background Smoke inhalation injury is a frequent health threat contributing to significant pulmonary derangements. The objective of this study was to determine potential interdependencies between pulmonary shunt fraction (Qs/Qt), tissue oxygenation and cardiac performance in the acute phase of combined burn and smoke inhalation injury. Methods Following a 20%, third-degree burn, sheep (n = 10) were subjected to cotton smoke according to an established protocol (4 × 12 breaths, < 40°C). Before (BL) and after each set of cotton smoke inhalation, the Qs/Qt, mean pulmonary arterial pressure, cardiac index (CI), left ventricular stroke work index (LVSWI), O 2 delivery index (DO 2 I), O 2 consumption index (VO 2 I) and O 2 -extraction rate (O 2 -ER) were assessed. At the same time points, the arterio-venous SO 2 difference and veno-arterial pCO 2 gradient were determined. Statistics One-way ANOVA with Student-Newman-Keuls posthoc test, or linear regression when appropriate. Data are expressed as mean ± SEM, or Pearson correlation coefficient, respectively. The burn injury led to an immediate and sustained decrease in CI (6.1 ± 0.2 vs 3.8 ± 0.6 l/min/m 2 ), accompanied by a depression in LVSWI (75 ± 2 vs 28 ± 1 g/m/m 2 ; P < 0.001 each). Smoke inhalation did not further impair these hemodynamic changes but led to a progressive increase in the Qs/Qt, up to a maximum of 85 ± 2% (P < 0.001 vs BL). Interestingly, the degree in Qs/Qt was inversely correlated with both the arterio-venous SO 2 difference (r = -0.90) and the veno-arterial pCO 2 gradient (r = -0.57). While the O 2 -ER remained unchanged, a more than 50% reduction in both DO 2 I (724 ± 41 vs 345 ± 43 ml/min 2 /m 2 ) and VO 2 I (295 ± 16 vs 123 ± 9 ml/min 2 /m 2 ) occurred (each P < 0.001 vs BL). Conclusion This study demonstrated that in the acute phase of combined burn and smoke inhalation injury (1) the deterioration in tissue oxygenation is linked with depressions in myocardial contractility and global oxygen transport as well as an increase in the Qs/Qt, and (2) the arterio-venous SO 2 difference is more appropriate to mirror ventilation/perfusion mismatch compared with the veno-arterial pCO 2 gradient. We examined expired air condensates (EAC) of patients with various stages of ARDS using spectrophotometry to study NO metabolites and fluorescence to study H 2 O 2 . Identification of CD95 (FAS) in blood cells was detected using monoclonal antibodies. Conclusion Filling pressures and static volumes are unreliable preload indices. The EF corrected target volumes better predict fluid responsiveness. We suggest using RVEDVi-C and GEDVi-C as target resuscitation or restoration of organ perfusion endpoints. Unneccessary over-resuscitation past these values will not benefit the patient. Table 1 Ejection fraction 10% 20% 30% 40% 50% RVEDVi Background The pressure recording analytical method (PRAM) is a recently developed method for beat-to-beat quantification of cardiac output (CO) based on the analysis of the arterial waveform. Since PRAM can be implemented in various conditions of flow, we assessed its accuracy in cardiac surgery during extra-corporeal circulation (ECC), using the roller pump device (RP) as the reference gold standard. The estimates of blood flow measured by the PRAM closely agreed with TD (r 2 = 0.75; P < 0.0001; bias = 0.07 ± 0.40; coefficient of variation < 2%) and simultaneous RP readings (r 2 = 0.71; P < 0.0001; bias = 0.11 ± 0.33; coefficient of variation 2.5%). During weaning from ECC, two patterns of hemodynamic adaptation were documented by PRAM following resumption of cardiac contraction. Background The N-terminal prohormones of the natriuretic peptides ANP and BNP (NTproANP and NTproBNP) are accepted markers of myocardial dysfunction [1] and are increasingly used in critically ill patients. While it is well recognized that plasma levels of ANP are altered by variations in thoracic blood volume and during intravenous sodium loading [2] , only incomplete data are available on the course of BNP during these interventions [3] . We studied eight patients (four males and four females). The mean age was 56 years. The mean admission APACHE II and SAPS scores were 19.5 and 31.3, respectively. The mean hospital stay was 31 days. ICU survival was 75%. Two patients were ventilated using a high-frequency oscillator. A total of 64 comparisons were made. We detected a significant difference between blood-gas PaCO 2 and TOSCA tcCO 2 of 0.43 kPa (paired t test P = 0.0012). Figure 1 shows the bias and limits of agreements. A regression line was fitted and the slope and intercept were highly significant. It is possible to predict PaCO 2 from tcCO 2 using the following regression equation: PaCO 2 = 2.7 + 0.5 × tcCO 2 . Conclusion Although there is a difference between PaCO 2 and tcCO 2 , it is possible to accurately predict the PaCO 2 level using tcCO 2 with moderate precision. tcCO 2 may be an adequate alternative to arterial blood gas sampling.  The plasma NT-ProBNP concentrations of patients were significantly higher than those of normal controls. They also increased according to the severity of heart failure classified by NYHA functional classifications (P < 0.001). The plasma NT-ProBNP concentrations and left ventricular end diastolic Introduction Recently, less invasive cardiovascular monitoring with transpulmonary thermodilution with the PiCCO system using a central venous line and an arterial thermodilution catheter got increasingly popular. In the last issue of the Yearbook of Intensive Care and Emergency Medicine, the opinion was stated that a single cold saline injection is sufficient to adequately measure cardiac output and derived thermodilution parameters [1] . Since there are no reported investigations in the literature on the subject, we wanted to examine this hypothesis. Linear regression between ITBVI/SVI was r 2 = 0.30 (P < 0.0001) while the PAOP failed to correlate (r 2 = 0.03) (Fig. 1) . The EVLWI showed a significant correlation with PaO 2 /FiO 2 (r 2 = -0.23, P < 0.0001) (Fig. 2 ). The median APACHE II score of the included patients was 13, ranging from 7 to 33. All patients were mechanically ventilated in a pressure control mode with positive end expiratory pressure ranging from 5 to 15 and an inspiration pressure ranging from 15 to 40 cmH 2 O. We divided patients into two groups: one included patients with EVLW < 10 and one included patients with EVLW of 10 or more. In the group with EVLW ≥ 10, we saw a higher mortality rate compared with the group with EVLW < 10 (35.5% vs 23.8%). In both groups we found no correlation in length of ICU admission, length of mechanical ventilation or the APACHE II score with EVLW. The patients' age was 53.1 ± 13.9 years and the APACHE II score was 26.0 ± 7.4. ∆PCO 2 was not correlated with any of the other three variables. The Pearson correlation coefficient was -0.173 (P = 0.29), 0.291 (P = 0.07) and 0.08 (P = 0.66) for cardiac output, BE and LAC, respectively. Background and goal of study Monitoring of organ function is often crucial for guiding therapy in critically ill patients. Most recently, the indocyanine green plasma disappearance rate (ICG-PDR) has been suggested for assessment of liver function and a transcutaneous system has been clinically introduced and validated [1] . In this study, we analyzed the agreement between ICG-PDR measured with the recommended dosage (0.5 mg/kg) and a reduced dosage (0.25 mg/kg). The values for IAP were 10 ± 4 mmHg (normal value 0-5 mmHg), PDR was 13.6 ± 8.4%, and R15 was 22.3 ± 19.8%. The correlation between IAP and PDR/R15 was poor although significant (R = 0.4), as was the correlation between PDR/R15 and the classic liver test (with R < 0.1): aspartate aminotransferase, alanine aminotransferase, lactate dehydrogenase, gammaglutamyl transferase, alkaline phosphatase, or venous NH 3 . From the socalled liver synthesis function tests, albumin, bilirubin, plasma cholinesterase levels and prothrombin time, only the latter had a good correlation. Neither platelets nor general hemodynamic parameters or lactate were well correlated. A significant and reasonable correlation was observed between PDR/R15 and SOFA score and the number of organ failures. Finally, the correlation between PDR and R15 was good (R = 0.8). Mortality was 57%, PDR was significantly lower (10.4 ± 5.7 vs 16.3 ± 6.6) in patients who died, while IAP (10.6 ± 3.9 vs 8.6 ± 3.6), SOFA score (13 ± 3.3 vs 7.7 ± 3.4) and number of organ failures (2.5 ± 1.1 vs 1.2 ± 0.9) were significantly higher. The number of measurement failures was 14% before and 3% after the software upgrade. Conclusions LiMON ® measurements are feasible at the bedside. There is no correlation between LiMON ® -derived parameters and the classic liver function tests except coagulation. Correlation with IAP was significant but poor. LiMON ® -derived parameters correlated with SOFA score and number of organ failures and give additional information. The PDR was lower in patients who died while IAP, SOFA and organ failures were higher. Introduction Ultrasound-guided catheterization of the internal jugular vein has proved to be of benefit especially for patients with specific problems such as those hospitalized in ICUs. Our purpose was to evaluate the usefulness of such a method compared with the landmarks method, when the former is performed by a senior intensivist trained in ultrasound for 1 year and recently taught the Doppler guidance method and the latter by experienced staff. Patients and methods A prospective randomized study was performed during a 3-year period, in the 12-bed multidisciplinary ICU of 'G. Gennimatas' General Hospital (1 November 2000-1 November 2003). One group was assigned to internal jugular vein cannulation by the landmarks method (control group) and the other with ultrasound guidance (ultrasound group). Our mortality was 60%. We had 15 patients in the nonsurvivor group and 10 patients as survivors. The two groups had similar APACHE II scores (nonsurvivors 26; survivors 24 ± 5; NS). CPK, CK-MB, ecocardiography analysis, cardiac output, and vascular resistance did not show any significant difference at any moment during the study period. However, troponin showed a significant difference from the first day of study, followed by the stroke work analysis as a significant difference between survivors and nonsurvivors. The difference in stroke work data become higher from day 3 onwards. The HRV showed a significant difference in maximal and minimal low frequency (LF) and in maximal high frequency. There was correlation as an independent variable only for maximal LF as a predictor of patient outcome. Conclusions In our study, HRV showed the capability to prognose patient outcome. Heart dysfunction was detected only by serum troponin levels and the hemodynamic data: stroke work. Introduction Whether the day and time of ICU admission or discharge impacts patient care and outcome has been the focus of recent inquiry. There may also be a relationship between timing and outcome for events occurring within the ICU. As a first step to explore this issue, we aimed to describe the timing of new acute hemodynamic events in a large ICU population. Hypothesis Acute hemodynamic events are equally distributed throughout the day and throughout the week. Although there was a trend to less events in the early morning and evening, event frequency generally varied little by hour of the day (Fig. 1) . The majority of patients (n = 255) did prove to have an ischemic heart pain (group A), 59 of them developed MI and 196 had angina and were treated accordingly. The rest of the patients could be divided into two groups: patients with no heart condition (group B, n = 62) discharged as musculoskeletal pain (n = 54), cholecystitis (n = 3), gastritis (n = 2), depression (n = 1), sepsis (n = 1) or meningitis (n = 1); and patients with cardiovascular disease but no actual ischemia (group C, n = 46) discharged as heart failure (n = 18), hypertension (n = 16), tachycardia (n = 5), bradycardia (n = 3), dissection of aorta (n = 2) and pulmonary embolism (n = 2). There were no statistically significant differences in gender between the groups. Patients in groups B and C were older than those in group A (P < 0.05), the significance is even greater when comparing only groups A and B (P < 0.005). Duration of examination in the ER did not influence the accuracy of diagnosis, patients in groups B and C were even longer examined (P < 0.05). We have found that the proportion of patients with history of angina or MI was greater in group A than group B or C (55.1%, 31.1% and 31.3%, respectively) and this was statistically significant (P < 0.005). Smoking, high cholesterol, hypertension, and diabetes did not significantly differ between the groups. Interestingly, we have found that proportion of patients admitted during the afternoons, nights or weekends was higher in groups B and C than in group A (P < 0.05), although characteristics of these patients did not differ from those admitted during the 'ICU staff shift'. Following clinical evaluation including 12-lead ECG, all patients were subjected to routine laboratory testing (including liver and kidney functions, lipid profile, CBC, and random blood sugar). Specific laboratory tests included serum fibrinogen and plasma NO expressed as its metabolites, nitrites and nitrates (NOx), as measured by the Griess reaction. Conclusion Elevated markers of cardiac myocyte damage are common in critically ill patients and are associated with an increased mortality rate. This effect is seen irrespective of renal function. Methods Thirty-six hours after intravenous endotoxin (LPS) administration, 26 rabbits were anaesthetised and ventilated. Systolic arterial pressure (sAP), diastolic arterial pressure (dAP), and mean arterial pressure (mAP) (mmHg), systolic aortic blood flow velocities (sAoV) and mean aortic blood flow velocities (mAoV) (20 MHz pulsed Doppler; cm/s), and systolic renal artery blood flow (sRen) and diastolic renal artery blood flow (dRen) (transonic Doppler, ml/min) were measured in anaesthetised and ventilated rabbits. Heart inotropic quality was estimated by maximal acceleration (Gmax, cm/s 2 ) and sAoV. After 30 min stabilisation, rabbits received levosimendan (200 µg/kg/hour, LS+) or saline (LS-) for 30 min. They were then separated into four groups: (1) LS+ with NE (1 µg/kg/min, 90 min); (2) LS+ with AVP (14 ng/kg/min, 90 min); (3) NE alone; (4) AVP alone. All parameters were gaussian. Statistical analysis was performed using one-way and two-way ANOVA. Results LS consistently improved sAoV and Gmax within 30 min (P < 0.05 for both), while sAP, dAP, and mAP decreased (P < 0.05). Addition of AVP or NE similarly restored mean arterial pressure. However, their effects on myocardial function diverged. While NE did not alter sAoV and Gmax, AVP dramatically deteriorated both contractile parameters (-25% and -45%, respectively, after 60 min; both P < 0.01). This effect of AVP was observed when used in combination with LS or alone. No significant effect of treatments was observed on sRen and dRen. The LVEF showed a significantly but relatively small improvement in response to levosimendan infusion (pre, 25.7 ± 11.0% vs post, 29.8 ± 8.6%), representing an absolute change of 4.1 ± 8.4% (P = 0.039). The plasma B-type natriuretic peptide concentrations demonstrated a significant decrease, from 993 ± 389 to 644 ± 408 pg/ml, before and after levosimendan infusion (P = 0.001). Continuous infusion of levosimendan increased the cardiac index in both groups significantly. The pulmonary capillary wedge pressure and systolic blood pressure did not change. Crystalloids and vasopressors, most commonly noradrenaline and adrenaline, were administered as needed. Weaning from CPB was successful in all the patients. Two of the infusions were discontinued due to hypotension. One high-risk patient in the preoperative group died during the operation. In the postoperative group, two patients with multiorgan failure died postoperatively. Introduction The aim of the study was to determine the hemodynamics and clinical effects of levosimendan (LS) in cardiosurgical patients. LS enhances the contractile function of stunned myocardium without increasing concetrations of intracellular calcium and myocardial oxygen consumption. Methods Ten patients (age 71 ± 6 years) mechanically ventilated and sedated were included in this study (n = 10). Diagnosis was coronary artery bypass operation (n = 7), valve replacement (n = 1) and pulmonary edema (n = 2). Patients were prospectively selected to receive LS, if hemodynamic data measured by a pulmonary artery catheter and estimation of cardiac function by echocardiography indicated a need for positive inotropic support. The infusion rate of LS was 0.1-0.2 µg/kg/min. A pre-existing infusion with epinephrine or norepinephrine was titrated to maintain a mean arterial pressure of 65-100 mmHg. Crystalloids and colloids were administered to maintain pulmonary capillary wedge pressure (PCWP) > 14 mmHg. Measurements were obtained at baseline, 3 hours and 24 hours after starting LS infusion. Statistical analysis was performed with a paired t test. P < 0.005 was considered statistically significant. Results LS caused a significant increase in cardiac index (CI) from 2.2 ± 0.4 l/min/m 2 at baseline to 3.3 ± 0.5 l/min/m 2 after 24 hour infusion. The increase in CI was due mainly to increase in stroke volume, as the heart rate remained nearly unchanged during the study period. The stroke volume index increased from 22.9 ± 4 ml/m 2 to 33.9 ± 9 ml/m 2 (P < 0.005). The left ventricular ejection fraction, as estimated by echocardiography, increased from 29.5 ± 5.5% to 33.9 ± 9% (P = 0.001). The systemic vascular resistance index significantly decreased from 2539.5 ± 551.4 dyn/s/cm -5 /m 2 to 1791.5 ± 276 dyn/s/cm -5 /m 2 (P < 0.005). LS did not cause significant changes in pulmonary vascular resistance (PVRI at baseline 318.5 ± 104 dyn/s/cm -5 /m 2 , after 24 hours 293 ± 136 dyn/s/cm -5 /m 2 ). There was a fall in PCWP, although this was not significant. At baseline, 34 out of 51 (67%) patients in the LS group, and 25 out of 49 (51%) patients in the PBO group were treated in the ICU/CCU. One levosimendan and three placebo-treated patients were subsequently admitted to the ICU/CCU after randomisation. The mean treatment time at the ICU/CCU was 4.4 days in the LS group and 5.1 days in the PBO group (median 4 days vs 5 days). The mean duration of index hospitalization after randomization was 5.7 days for the LS group and 6.8 days for the PBO group (median 5 days in both groups). After the initial discharge, one patient in the LS group and seven patients in the PBO group were admitted to the ICU/CCU during a subsequent rehospitalization up to day 31. The mean treatment time at the ICU/CCU for these patients was 2.0 days in the LS group and 4.4 in the PBO group (median 2 days vs 5 days). The patients were 10 males and three females with mean age 66 ± 14 years. The mean TRmax was 38.0 ± 9.2 mmHg prior to levosimendan infusion. After 24 hours of levosimendan infusion TRmax decreased to 30.9 ± 6.7 mmHg (P = 0.0015). In patients with markedly elevated baseline TRmax (> 35 mmHg), the median drop in TRmax was more pronounced then in patients with mild elevation of baseline TRmax (7.8 mmHg vs 2.4 mmHg). Although LVEF increased in all patients (from 18 ± 6% to 25 ± 7%) and RV contractility assessed by M-mode was better (from 1.48 ± 0.2 cm to 1.61 ± 0.2 cm), the blinded observer was not able to confirm improvement in RV contractility. Conclusion Levosimendan reduced te TRmax of peak TR flow velocity in cardiac failure and critically ill patients, implying a reduction in PVR. The degree of PVR reduction is greater in patients with baseline pulmonary hypertension. Vasodilators might cause a deterioration in gas exchange. There have been isolated case reports where oral Sildenafil, a selective phosphodiestrase inhibitor (PDEI), has been used as an alternative to prostacyclin in primary PH with early success. Our aim was to assess acute and short-term effect of Sildenafil in patients with PH with different etiologies. Seven patients have been studied (four female, three male; mean age 49 ± 12 years). They included two patients with primary PH, two patients with Eisinmenger syndrome, two patients with thromboembolic PH and one patient with Bilharzial PH. Following clinical evaluation, all patients were subjected to Swan-Ganz catheterization and the mean pulmonary artery pressure (mPAP), pulmonary vascular resistance (PVR), and mixed venous oxygen saturation (mVO 2 ) were invasively measured. Patients were also subjected to echocardiographic evaluation of the right ventricular diameter (RVD) in the short axis, of the left ventricular stroke volume (SV) and of the cardiac output (COP). Readings were recorded before, 3 days and 3 months after the start of Sildenafil. We used oral Sildenafil (25 mg) every 6 hours for all patients. Out of the seven patients, five showed significant clinical (New York Heart Association [NYHA] class IV to NYHA class III), hemodynamic and echocardiographic improvement 3 days after therapy. The five patients included two patients with primary PH, one patient with Eisenmenger syndrome, one with Bilharzial PH and one thromboembolic patirnt. The latter patients showed significant reduction of mPAP (107 to 73 mmHg, -32%, P < 0.01), mPVR (1988 to 1177 dynes/s/cm 5 , -41%; P < 0.01) with insignificant rise in mVO 2 (48 to 53 Torr). All hemodynamic changes occurred without significant reduction of arterial blood pressure and SVR. Echocardiography showed insignificant mild reduction in RVD (6.6 to 6.4 cm) with a significant rise in SV (35 to 42 ml), and COP (3.7 to 4.2 l/min). Follow-up 3 months later showed improvement in four out of the latter five patients. The fifth patient is the Bilharzial PH one who died suddenly 5 days after discharge. The other four patients showed further subjective improvement (NYHA class III to II), reduction of mPAP (73 to 57 mmHg, -22%; P < 0.05), mean PVR (1177 to 759 dynes/s/cm 5 , -36%; P < 0.05) with a further rise in mVO 2 (53 to 60 Torr). Echocardiography also showed a significant reduction of the RVD (6.4 to 5.6 cm) with a further rise in SV (42 to 48 ml) and COP (4.2 to 4.7 l/min, P < 0.01). Conclusions (1) Sildenafil proved to be effective in the acute and short-term condition, subjectively and objectively, especially in patients with primary PH. Yet, the long-term effect and 5-year mortality are to be evaluated. (2) The effect of Sildenafil on Bilharzial PH is guarded. A larger group of Bilharzial PH patients should be studied, especially the milder forms. Interventions None. Inhospital mortality was 54%. Inhospital major adverse events (death, CABG, myocardial infarction) occurred in 62%. Survival at 1 year and 5 years was 41 ± 4% and 40 ± 4% (NS), respectively. Survival at 5 years after a successful procedure was 44 ± 5% versus 17 ± 8% after incomplete success/failure (P < 0.001). Multivariate analysis showed four independent variables for the long-term outcome: age, left ventricular dysfunction, extent of coronary artery disease and procedural result. Aim To assess the safety, feasibility and efficacy of the Impella device in patients with cardiogenic shock or patients undergoing high-risk surgery or PCI. The results of the first 20 patients are presented in Tables 1 and 2 . Conclusions These preliminary data indicate the feasibility of the Impella pump for patients in cardiogenic shock, high-risk CABG and PCI. More data will be available in March 2004. Results and discussion Sixty (92.3%) patients were succesfully treated. Fifty-six (86.1%) had a total recovery, four (6.1%) had a partial response and treatment failed in five patients (7.6%). Embolic migration occurred in five (7.6%) patients and two patients (3%) died because of it. Three patients (4.6%) had some hemorrhagic disorders. Conclusions Thrombolytic therapy is feasible and safe. Surgical treatment is not contraindicated even if thrombolitic therapy partially failed allowing better hemodynamic status after all. Introduction Deep vein thrombosis (DVT) is a serious complication that may develop in critically ill ICU patients as a consequence of immobilization, femoral central venous catheter (CVC) placement and activation of the thrombotic cascade. We hereby report our experience with emergency PA in clinically suspected cases of PE to highlight its merits and the limitations of clinical examination. We studied 18 patients with clinically suspected PE (six male, 12 female; mean age 49.5 years). Predisposing factors included heart disease in two patients, diabetes mellitus in five patients, polytrauma in three patients and autoimmune disease (i.e. Behcet disease) in one patient. Four patients were dehydrated and bedridden. Following clinical evaluation, elctrocardiogram and chest X-ray, all patients. were subjected to routine laboratory evaluation, arterial blood gas measurement and specific coagulation profile (fibrin, fibrin degradation products, D-dimer). All patients were then subjected to first-pass radionuclide angiography. PA was done in all patients within a mean period of 2 days (day 0-day 4). Following acute imaging, PA revealed the presence of PE in only eight patients in the form of distal cutoff and/or filling defects, while 10 patients had negative PA for PE. Compared with patients with negative PA, those with positive findings were more frequently hypotensive (50% vs 20%), more hypoxic (100% vs 90%), more congested (100% vs 80%) with more positive echocardiographic data (85% vs 60%). They also exhibited significant scintigraphic evidence of impaired RV ejection fraction than patients with negativeve PA (80% vs 20%). Conclusion Emergency PA is a feasible, safe, highly sensitive diagnostic tool in acute PE before starting intrapulmonary or systemic thrombolytic therapy with its potential hazards. In view of the ready availability of the catheter laboratory as well as its safety and ease of performance, emergency diagnostic PA is recommended in suspected clinical settings of PE. Objective The primary objective of this study was to estimate the prevalence and incidence of diagnostically confirmed DVT and PE in medical-surgical ICU patients. The secondary objective was to examine VTE prophylaxis longitudinally, estimating the proportion of VTE events associated with prophylaxis failure versus failure to implement prophylaxis. The tertiary objective was to estimate the morbidity and mortality outcomes of patients with VTE. Intrasample variation as to expected fibrinogen results were estimated by the coefficient of variation for each subject. A random effect analysis of variation (ANOVA) was performed and the coefficient of variation (r) was estimated by measuring the ratio of hypercoagulate to fibrinogen and factor 8. A level of confidence > 0.05 was considered statistically significant. Coefficient of variation was 0.96 for the fibrinogen level and 0.62 for factor 8. We investigated 55 patients (16 female; median age 60 years, range 12-92 years) having an illness severity score APACHE II of 20.28 ± 6.8. Eleven patients were treated with FUFH, 38 with FUFH and LMWH, three with LMWH and one with UFH. Positive HPF4-Abs were detected in 17 (30.9%) patients on day 7 and 21 (39.5%) patients on day 15 ( Table 1) . None of the patients developed HIT-II. Higher levels of TATc and lower levels of PAA were found in infected lungs compared with noninfected lungs and lungs from controls (P < 0.05). Protein C and APC concentrations were significantly decreased at the infected site (P < 0.01). See Fig. 1 . The platelet count decreased to be less than 10 × 10 4 /µl in 41 out of 454 patients during their hospital stay. Among these 41 patients, 28 (70%) developed DIC. There was no significant difference in age, sex, APACHE II score, SOFA score, or frequency of systemic inflammatory response syndrome between DIC and non-DIC patients. When the platelet count, the International Normalised Ratio, the fibrinogen level, the fibrin/fibrinogen degradation product (FDP) value, and the most abnormal white blood cell count in non-DIC patients were compared with those observed at the time of DIC onset in DIC patients, only the FDP value was significantly higher in DIC patients (non-DIC:DIC, 8.49 ± 3.40 µg/ml:59.6 ± 86.2 µg/ml; P < 0.05). ∆PLT was significantly higher in DIC patients (6.55 ± 8.41/µl/day) than in non-DIC patients ([2.24 ± 1.87] × 10 4 /µl/day). The mean SAPS II scores from septic patients on day 1 treated with and without Drotrecogin alfa (activated) were comparable (SAPS II score mean = 32). Significantly lower concentrations of NT-proBNP (P = 0.0075) and NT-proANP (P = 0.0366) were measured in the patients treated with Drotrecogin alfa (activated) as compared with the patients not receiving Drotrecogin alfa (activated). TNI values were significantly lower (P < 0.05) in septic patients treated with Drotrecogin alfa (activated) (mean ± SD = 3.3 ± 7.2 ng/ml) as compared with untreated patients (mean ± SD = 0.3 ± 0.97 ng/ml). There was a correlation between NT-proBNP and NT-proANP values (r = 0.6381, P < 0.001). Septic patients with NT-proBNP levels > 1600 fmol/ml have a 3.7-fold higher risk of death than patients with NT-proBNP levels < 1600 fmol/ml (P = 0.05). Conclusion Nt-proANP and Nt-proBNP levels are significantly lower in septic patients treated with Drotrecogin alfa (activated). Nt-proBNP can serve as a predictor for survival in septic patients. Drotrecogin alfa (activated) may influence cardiac depression in septic patients by controlling the pathways of NT-proANP and Nt-proBNP production. The beneficial effect of Drotrecogin alfa (activated) on cardiac function is also reflected by lower TNI values in this patient group. Methods Inclusion/exclusion criteria were similar to PROWESS. Patients eligible for participation had a known or suspected infection, met three or four criteria defining systemic inflammatory response syndrome and one or more acute sepsis-induced (< 48 hour duration) organ dysfunctions. Patients were classified by the time interval from the first documented organ dysfunction to administration of DrotAA (time-to-treatment), for patients that had received DrotAA within 24 hours (n = 1128) versus > 24 hours (n = 1246) after the first documented organ dysfunction. Serious bleeding rates and fatal event rates for PROWESS and ENHANCE are presented in Table 1 . Overall 28-day mortality: PROWESS placebo = 30.8%, PROWESS DrotAA = 24.7%, ENHANCE DrotAA = 25.3%. As in PROWESS, bleeding was the most common drug-related complication associated with DrotAA. A total 48.9% of SAE bleeding events were adjudicated as procedure-related. In ENHANCE, the ICH rate during infusion was 0.6% (n = 15), of which five (0.2%) were fatal. ICH rates for placebo vs DrotAA in PROWESS were 0% and 0.2% (n = 2, both fatal), respectively. A higher postinfusion rate of serious bleeding was observed in ENHANCE, suggesting a higher overall background bleeding rate, relative to PROWESS. Conclusions Twenty-eight-day survival was similar in PROWESS and ENHANCE. Serious bleeding events during infusion of DrotAA were slightly more frequent in ENHANCE than in PROWESS; the proportion of fatal bleeding events was the same. However, the background bleeding rate in ENHANCE may have been higher. The ENHANCE safety and efficacy data are highly consistent with PROWESS, and reinforce the favorable benefit-risk profile of DrotAA in patients with severe sepsis. Acknowledgement This research was supported by Eli Lilly and Company, Indianapolis, IN, USA. Available online http://ccforum.com/supplements/8/S1 Methods Inclusion and exclusion criteria were similar to PROWESS. Patients eligible for participation had a known or suspected infection, met three or four criteria defining systemic inflammatory response syndrome and one or more acute sepsisinduced (< 48 hour duration) organ dysfunctions. Days in the ICU, days in the hospital, and days of ventilator use were monitored, starting from time of DrotAA infusion. Patients were classified with respect to the time interval from the first documented organ dysfunction to administration of DrotAA in the intent-to-treat population with two or more organ dysfunctions at baseline that had received DrotAA within 24 hours after the first organ dysfunction (time 0-24 hours, n = 894) vs more than 24 hours after first organ dysfunction (time 24-48 hours, n = 1110). Results Table 1 describes patients with two or more organ dysfunctions at baseline. Administration of DrotAA within 24 hours of the first organ dysfunction was associated with reductions in days in the ICU, hospital length of stay, and mechanical ventilator use, relative to patients receiving DrotAA from 24-48 hours after first organ dysfunction. Conclusion Earlier treatment with DrotAA was associated with reduced hospital resource use and decreased length of stay in patients with two or more organ dysfunctions at baseline. These data suggest that the timely administration of DrotAA may have important clinical and economic value. Acknowledgement This research was supported by Eli Lilly and Company, Indianapolis, IN, USA. Methods Inclusion and exclusion criteria were similar to PROWESS. Patients eligible for participation had a known or suspected infection, three or four of the criteria defining the systemic inflammatory response syndrome, and one or more acute sepsis-induced (< 48 hour duration) organ dysfunctions. Days in the ICU, days in the hospital, days of ventilator use, and days of vasopressor use were monitored, starting from the time of DrotAA infusion. Patients were subclassified with respect to the time interval from the first documented organ dysfunction to administration of DrotAA (time-to-treatment). Time-to-treatment was considered in the intent-to-treat population with an APACHE II score of 25 or more at baseline that had received DrotAA within 24 hours of the first organ dysfunction (n = 430) vs those that received the drug more than 24 hours after first organ dysfunction (n = 432). Results Data presented are from severe sepsis patients with an APACHE II score of 25 or more at baseline. The administration of DrotAA within 24 hours of the first observed organ dysfunction was associated with significant reductions in days in the ICU (median ICU days = 10 for time: 0-24 hours, 14 for time: 24-48 hours; P = 0.006), mechanical ventilator use (median ventilator days = 7 for time: 0-24 hours, 10 for time: 24-48 hours; P < 0.001), and vasopressor use (median vasopressor days = 2 for time: 0-24 hours, 3 for time: 24-48 hours; P = 0.003), relative to patients receiving DrotAA after more than 24 hours from first organ dysfunction. Median days in the hospital were lower in patients receiving DrotAA within 24 hours of first organ dysfunction, but the difference was not statistically significant (median hospital days = 18.5 for time: 0-24 hours, 22 for time: 24-48 hours; P = 0.103). Conclusion Earlier treatment with DrotAA was associated with reduced hospital resource use in patients with an APACHE II score of 25 or more at baseline. These data suggest that the timely administration of DrotAA may have important clinical and economic value. Introduction It has been shown that age and number of organ dysfunctions (OD) correlate with outcome of patients suffering from severe sepsis (SS). Recently, the PROWESS study (phase III, double-blind, placebo-controlled trial) had demonstrated that recombinant human activated protein C (rhAPC) reduces the absolute risk of 28-day all-cause mortality by 6.1% in patients suffering from SS. As a result in Mexico, from August 2002 until October 2003, 206 patients have been treated with rhAPC. The present study is to identify the main variables that contribute to early mortality (first 8 days) in patients treated with rhAPC. Methods Data from 206 patients treated with rhAPC from 58 public and private medical institutions all over Mexico were analyzed retrospectively. Age, origin of SS, number of OD, timing of rhAPC administration, andcomplications during rhAPC were used as independent variables. Cross-tabulation and chi-square analysis were performed to identify those variables that contribute to mortality at 8 days of SS. Results Intra-abdominal sepsis was the most common origin of SS (46.6%), followed by postoperative sepsis, pneumonia and others (28.6%, 19.4% and 5.3%, respectively). There were no differences in mortality about patients treated in public hospitals compared with patients treated in private hospitals. The mean age of patients treated was 58.80 years (19-89 years). The mean of OD was 2.78 (1-6), the mean of timing administration of rhAPC was 50.94 hours (4-504 hours), and global mortality at 1 week was 31.6%. Age was associated with mortality; patients younger than 41 years had 14.7% mortality, in contrast with patients older than 65 years with 48.3% mortality (P = 0.000). The number of OD was associated with mortality; patients with one OD had 21.4% mortality in contrast with 37.7% mortality in patients with three or more OD (P = 0.040). Patients younger than 41 years with one OD had 0% mortality, two OD 11.8% and three or more OD 21.4%; patients between 40 and 65 years with one OD had 25% of mortality, two OD 20.0% and three OD 33.3%. Patients older than 65 years with one OD had 25% of mortality, two OD 50% and three or more OD 50% (P = 0.003). Bleeding was observed in 4.7% of patients, and one dead by cerebral haemorrhage associated with rhAPC (0.48%) was reported. Conclusions Age and the number of OD are highly associated with mortality at 1 week of SS on patients that were treated with rhAPC. Patients suffering from SS have to be treated at an early stage of sepsis. Introduction Neuroaxial anaesthesia reduces the risk of postoperative complications, but in high-risk patients undergoing major abdominal surgery the benefits of neuroaxial anaesthesia are less clear [1, 2] . A significant proportion of patients develop sepsis following laparotomy. Recently Drotrecogin alfa (activated) has been shown to reduce the risk of death from sepsis [3] . Due to the increased risk of bleeding the presence of a neuroaxial catheter is an absolute contraindication to its use. We hypothesized that the presence of a neuroaxial catheter excludes a significant number of septic patients from receiving this potentially beneficial therapy. Method Fifteen patients who received Drotrecogin alfa were each matched for ICNARC diagnostic category and APACHE II score with two historical controls. These were selected from patients admitted prior to the availability of Drotrecogin alfa. Following successful matching, the mortality was unblinded. The two groups (control and Drotrecogin alfa) had comparable APACHE II scores (25.5 vs 25.7) and risk of death at admission (0.52 vs 0.54), respectively [2] . The mortality was 60% for historical controls and 27% for those receiving Drotrecogin alfa. The standardised mortality ratios were 1.14 and 0.49, respectively (chi-squared P < 0.05). Conclusion Protocol-driven Drotrecogin alfa treatment in septic patients appears to confer a survival benefit in a UK district general intensive care unit. The absolute mortality reduction of 33% was considerably higher than that in PROWESS [1] . Objectives To assess the epidemiology and prognosis of thrombocytopenia (TP) in ICU patients. The mean age was 47.7 years (14-74 years) with a male/female ratio of 1.7. The internal jugular vein was the insertion site in 80.3% of patients. The APACHE II score was 16.5 ± 7.8 (2-40). Three operators performed 91.6% of the procedures. There were no mortality or major complications associated with CVC placement, with 10 patients showing local hematomas. Results for PT (%) were 50 ± 24.8 (1-114), for aPTT (s) 53.6 ± 29.9 (16-180) and for PC (/mm 3 ) 115,571 ± 89,516 (5000-475,000) (mean ± SD). The average PC in patients with thrombocytopenia was 56,133/mm 3 . FFP and PTL units saved, and local and US saved charges according to published payment rates are depicted in Table 1 . The mean cost per patient using the rhEPO strategy was $1030 vs $1323 for no rhEPO. Fewer units of PRBCs were administered in the rhEPO arm, resulting in a lower infection rate. rhEPO use was therefore both less expensive and more effective (i.e. it was the dominant strategy). One-way sensitivity analyses revealed that administration of rhEPO remained the preferred strategy provided that the PRBC cost was greater than $186/U or that the rhEPO cost was less than $1455/40,000 U. These results can be generalized: provided that the cost of rhEPO < 2.4 × cost 1 U PRBC, the rhEPO strategy will be preferable. Further, the advantage of treatment with rhEPO was maintained down to an expected transfusion rate of 1.1 U PRBC per patient per admission. Decreasing the probability of infection or increasing the long-term cost of infection did not significantly affect the model. Expressed as mean (SD). Both colloid osmotic pressure (COP) and albumin changed significantly, with significant immediate elevation at t5 that declined by t240, although elevation above baseline remained significant. Plasma albumin was 13(3.8) g/dl at t0, 17.4 (6.1) g/dl at t5, and 16.7 (4.7) g/dl at t240. COP was 16.1 (2) mmHg at t0, 19 (2.5) mmHg at t5 and 17.3 (2.4) mmHg at t240. Significant changes also occurred in both PO 2 /FiO 2 and central venous pressure (CVP) but significant increases at t5 were not sustained at t240. PO 2 /FiO 2 was 19.9 (4.1) kPa at t0, 22.3 (5.8) kPa at t5, and 20.6 (6) kPa at t240. CVP was 17 (6) mmHg at t0, 20 (5) mmHg at t5, and 18 (5) mmHg at t240. The heart rate and cardiac output were not significantly affected by albumin administration, although an increase in cardiac output correlated nonsignificantly with improvement in the PO 2 /FiO 2 ratio at t5 (correlation 0.43) and at t240 (correlation 0.40). Discussion Cardiovascular stability was unaffected by albumin and furosemide administration. An immediate improvement in oxygenation was not sustained at 4 hours. Introduction Recombinant factor VIIa (rFVIIa) is a prohaemostatic agent that has successfully been used for the treatment of patients with haematological malignancies and coagulopathy. It also has been used in postsurgical patients where the coagulopathy in combination with hypothermia and metabolic acidosis causes an increase of mortality early post operation. Recently reported has been the use of rFVIIa in patients with a normal coagulation system, undergoing major surgery in order to reduce the intraoperative bleeding and the need for transfusions. Here we present our experience on rFVIIa use in ICU patients. The single MARS treatment contributed to significant decreases in levels of serum total bilirubin (from 547 ± 187 mmol/l to 312 ± 118 mmol/l, P < 0.05) and nonconjugated bilirubin (379 ± 134 mmol/l to 185 ± 68 mmol/l, P < 0.05), respectively, and MAP was increased from 72 ± 8 mmHg to 81 ± 7 mmHg (P < 0.05) during the MARS therapy. There were statistical differences in prognosis and survival between the two groups: in the SMT group, six of 12 patients in the middle stage survived (50%), while in the MARS group the survival for comparable middle-stage patients was 10/12 (83.3); for the end-stage subgroup comparison, all four patients died in the SMT group but the MARS therapy improved the survival to 25% (1/4) in its four patients. The overall survivals of these two groups with middlestage and end-stage SCH-B patients were 37.5% for SMT and 68.5% for MARS (P < 0.05). Conclusions MARS therapy effectively removed serum bilirubin and other albumin-bound toxins, increased the MAP, and inhibited the hepatocellular necrosis, thus contributing to organ protection. Results MARS treatments were associated with a significant reduction of albumin-bound toxins and various cytokines, as well as the water-soluble toxins. Most patients showed a positive response to the therapy, proven by an increase in prothrombin time activity and mean arterial pressure, and a decrease in hepatoencephalopathy grade and Child-Turcotte-Pugh index significantly. Eighty-four patients survived in hospital including those alive from the liver transplantation (56.4%). Survival of the acute liver failure, subacute liver failure and acute on chronic liver failure patients were 62.5%, 66.7% and 54.5%, and acute on chronic liver failure patients formed the majority (121/149-81.2%). Patients in end stage presented the largest among the subgroups of acute on chronic liver failure (65/121, 53.7%), and patients in the early and middle stages gained more favorable outcomes than those in C grade (91.7% and 75% vs 30.8%) ( Table 1) . Randomized controlled studies in China are ongoing to verify the optimal therapeutic results of MARS. Materials Nineteen patients (nine male/10 female) 15-73 years of age with sepsis who received continuous hemodiafiltration (CHDF) treatment were examined. The APACHE II score was 28.3 ± 0.4. Fifteen patients underwent mechanical lung ventilation, and 13 had inotropic support. The mortality rate was 43.9%. Hemoprocessor 'Prisma' kits with membrane AN69 and solutions from 'Hospal' Company (France) were used for CHDF. The mean duration of CHDF was 73.8 ± 7.0 hours with the filtration volume of 80.4 ± 1.6 l/day. Concentration of TNF-α during CHDF were 386.3 ± 111.6-429.3 ± 80.7 pg/ml. A significant amount of this cytokine was measured in all effluent samples (90.9-132.5 pg/ml). Daily TNF-α elimination was 8.92 ± 0.94 µg. Clearance was 80.2 ± 6.3 l/day, which was one-third of the blood volume that has been perfused through the hemodiafilter. We found a correlation between the volume of effluent and TNF-α elimination (r = +0.49 ± 0.04; n = 30; P < 0.05). The difference between TNF-α content in the plasma volume before and after hemodiafilter, at a mean blood speed of 150 ml/min, hematocrit of 26.7% and plasma flow of 110 ml/min, was 17,160 pg/min. At the CHDF speed of 55.6 ml/min, 6183 pg/min TNF-α was eliminated. The difference between TNF-α content in plasma and effluent volume was 10,977 pg/min, which acknowledges the receipt of significant absorption of this cytokine on the hemodiafilter membrane during the first 6 hours of the CHDF procedure. Conclusion Significant amounts of TNF-α can be eliminated using CHDF filtration and absorption, which is important in the absence of natural hepatorenal clearance during multiple organ failure. The hemodynamic pattern of sepsis characterized by a high cardiac index associated with low systemic vascular resistances and alterations on tissue oxygenation is caused by the release of mediators during the host-infecting microorganism interaction. We thought that removing those endotoxins and inflammatory mediators by plasmapheresis would improve hemodynamic changes and tissue oxygenation. The APACHE-II score was 22.9 ± 6.3 and 30.7 ± 8.9, and the SOFA score was 9.7 ± 3.6 and 12.6 ± 3.4 in the S and N-S groups, respectively, showing significantly higher scores in the N-S group. The number of days that had lapsed from the onset of shock to PMX-DHP initiation was 0.8 ± 0.8 days in the S group while it was longer (1.8 ± 1.2 days) in the N-S group. After PMX-DHP for 2 hours, the endotoxin level decreased from 26.1 ± 20.3 to 20.3 ± 24.5 pg/ml with statistical significance (P < 0.05) in the S group. In the N-S group, it tended to decrease from 23.6 ± 20.3 to 10.9 ± 17.2 pg/ml. The MARS therapy was associated with a significant removal of NO and certain cytokines such as TNF-α, IL-2, IL-6, IL-8, and lipopolysaccharide binding protein (LBP) (see Table 2 ), together with a marked reduction of other nonwater-soluble albumin-bound toxins and water-soluble toxins. These were associated with a, improvement of the patients' clinical conditions including hepatic encephalopathy, deranged hemodynamic situation and renal and respiratory function, thus resulting in a marked decrease of teh Sequential Organ Failure Assessment (SOFA) score and improved outcome: 16 patients were able to be discharged from the hospital or bridged to successful liver transplantation. The overall survival of 39 patients was 41%. Significant independent predictors of a normal first creatinine are presented in Table 1 . The most powerful independent predictor of a normal post-hydration creatinine was a normal admission creatinine (odds ratio [OR] = 31, confidence interval [CI] = 6.6-145, P = 0.0001). An elevated BUN and a CK greater than 10,000 were negative predictors of a normal second creatinine (OR = 0.20, CI = 0.06-0.65, P = 0.008, and OR = 0.21, CI = 0.07-0.61, P = 0.004). Conclusion A normal admission creatinine was associated with WBC < 11.0, the absence of cocaine or amphetamine, less than 18% volume depletion, a normal BUN and a normal calcium. A normal first creatinine was a very strong predictor of a normal second creatinine after hydration. This suggests that otherwise healthy patients with uncomplicated rhabdomyolysis and a normal first creatinine who can hydrate themselves orally may be safely discharged from acute emergency care after correction of volume deficits. Results Plasma M peaked on average 0.6 ± 0.4 days before CK. In the 76% of the patients M and CK increased in parallel and both decreased exponentially T½ (M) 22 ± 10 hours and T½ (CK) 26 ± 7 hours ( Fig. 1.) In 17% of the patients an isolated increase in M was observed. In the majority of these patients abdominal complications was found. In 7% of the patients an isolated increase in CK was observed, typically in relation to mobilisation of the patients. ARF was treated with continuous venovenous haemofiltration. Ten patients with ESRD were in the control group and eight in the treatment group. Baseline hemodynamic (heart rate [HR], MAP, CVP, ScvO 2 ) and severity of illness scores (APACHE, MODS, SAPS) were not different between groups. Seven out of 10 patients in the control group died compared with 1/8 in the EGDT group (P < 0.05). At 6 hours, the HR and CVP remained equal between groups, but a statistically significant rise in ScvO 2 and MAP was found between groups (P < 0.05). Additionally, the treatment group displayed a significant fall in lactate, APACHE, MODS, and SAPS scores (P < 0.05). The difference in ScvO2, lactate, and severity of illness remained significant at 72 hours (P < 0.05). Conclusion EGDT is both safe and efficacious for patients with ESRD, resulting in reduction of both morbidity and mortality. This improvement in outcome can be explained by eradication of global tissue hypoxia by aggressive resuscitation guided by goal-directed care. Although EGDT was performed for only 6 hours in the ED, the physiologic benefits persisted between groups at 72 hours. Objective Although the simple closure/omental patch (SC) has been standard procedure for perforated duodenal ulcer (PDU) in most institutes in Japan, this procedure was originally performed for poor-risk patients. Basic evaluation concerning the SC has been insufficient and the SC has been performed based on only experience. Gastrointestinal endoscopic examination (GF) makes it possible to evaluate such fine structures. However, it is not known whether the early endoscopic examination after SC is safe or not. The aim of this study is to clarify the macroscopic findings of the healing process after the SC for PDU. In three of 11 patients, GF findings showed an active stage and a healing stage. In two of them, the surgical technique was thought to be insufficient (the distance between the stitch and the edge of the ulcer was insufficient), and in the other patient postoperative GF was performed on the 4th postoperative day because of transfer to another minor hospital. The other eight patients showed a scar phase with good granulation and without exposure of stitches. Iatrogenic perforation, bleeding, and severe abdominal pain during or after postoperative GF was not seen in all cases. Conclusion Postoperative GF in the early phase after SC is useful and safe for evaluating the healing process of the SC for PDU. We can start oral intake 1 week after this surgical procedure.  Serum GLI and IRG in groups S and M were significantly higher than those of group C (P < 0.01), while those in group S were also significantly higher than those in group M (P < 0.05). In all patients in groups S and M, except for only three in group S, a peculiar glicentin-like peptide (GLLP) (molecular weight about 8000) other than pancreatic glucagon was observed in IRG gel filtration chromatography, which was clearly absent from group C. All 22 patients developed MODS and all laboratory parameters as indicators of SIRS were increased. Serum concentrations of IL-1, IL-6 and TNF-α were elevated in all patients, but with high significance difference (P < 0.03) in 14 patients who developed pulmonary failure (three from group I and all 11 patients from group II). The peak serum concentrations of cytokines were found in patients from group II with the most increased value for IL-6. Lung injury treated with mechanical ventilation (14 patients), pulmonary drainage (six patients) and even decorticating (three patients) correlated with increased serum value of IL-6. Changes in chest radiographs depended on the increased values of all cytokines and the more severe was lung injury, the higher were the values. Comparison between the patients from group I and those from group II showed significant differences in the values of cytokines, with the values being higher in group II. Serum concentration of cytokines were significantly higher (P < 0.05) in five patients who died (all of them with pulmonary failure) compared with those who survived. All assessed parameters were significantly higher in abdominal fluid than in the other two compartments (up to 100-fold in cell counts and 1000-fold in IL-8 concentrations compared with blood; P < 0.0001). Leukocyte count, neutrophil count/percentage and IL-8 concentrations were also significantly higher in the lung compared with blood or plasma values (P < 0.05). The absolute number, percentages and activity (MPO concentration) of neutrophils in the lung were higher at all time points in peritonitis patients (even day 0) compared with short ventilated controls (P < 0.05). Alveolar membrane permeability, as measured by the relative coefficient of excretion (a ratio between albumin excretion and alpha-2-macroglobulin excretion ratio) was increased in peritonitis patients at all time points. Discussion Neutrophil accumulation and activation in the abdominal cavity and the pulmonary compartment in patients with peritonitis is likely to be compartmentalized. In various compartments of the body, the host defense systems vary in extent and nature. An impressive pulmonary response develops early in secondary peritonitis: Neutrophils are activated and lung permeability is increased above normal values.  The values for IAP (mmHg) were 9.7 ± 3.2 (IGP) vs 9.8 ± 3.1 (IBP), and 72.1 ± 16.5 for APP. There was a good correlation: IBP = 0.85 × IGP + 1.6 (R 2 = 0.79, P < 0.0001). Bland and Altman analysis showed good agreement: IGP was almost identical to IBP with a mean bias of -0. Conclusion Estimation of IAP via IGP or IBP is feasible. The novel IGP method is less time consuming, fully automated (autocalibration), and allows a continuous trend. The FoleyManometer offers a cost-effective alternative. Both are accurate and reproducible. The COVA for the obtained parameters in sedated patients is around 15-20% in a 24 hour period and thus varies substantially. These variations may even be more pronounced in nonsedated patients. Therefore IAP and APP are continuous variables like any other pressure and should be monitored as often as possible during the day to adapt treatment accordingly. Background and goal of study Air tonometry is a common method to examine splanchnic hypoxia, which often is a predictor of severe clinical complications such as sepsis or renal failure. Urodilatine is one of the indicators of renal function. A retroperspective case-control study was conducted considering whether there is an inter-relation between splanchnic ischaemia and renal function. In the control group, no changes were observed with time or between modes. For results of the EAP group see Table 1 . During the second EAP phase lung mechanics deteriorated further, and returned to baseline value after pressure relief only with BIPAP. In both modes, oxygenation after the last pressure relief was worse than baseline. Conclusion An EAP applied twice for 9 hours each worsened the chest wall and lung mechanics and impaired gas exchange regardless of the ventilation mode. These changes were not completely reversed after pressure relief. If spontaneous breathing was present during BIPAP, there was less impairment of lung compliance and oxygen delivery, but this did not lead to differences in gas exchange. Background Organ dysfunction attributable to intraabdominal hypertension, known as abdominal compartment syndrome (ACS), has been recognised as a source of morbidity and mortality in the ICU. Decompressive laparatomy is considered as the sole definite therapy of ACS. However, no randomised trial has been performed to assess the role of surgery. We studied the characteristics and outcome of critically ill patients with ACS treated nonoperatively, and focused on the natural course of organ dysfunction. We found 24 episodes of ACS in 23 patients that were managed nonoperatively. Mortality was 26% (6/23), patients that died had a higher APACHE II score on admission (28.5 ± 8.3 vs 20.8 ± 7.4 in the survival group [P = 0.04]), but the incidence of organ failure and the highest recorded IAP were not significantly different. At discharge, organ function returned to basic levels in all survivors (medium length of stay 13). Conclusion In a group of critically ill patients with ACS treated nonoperatively, the mortality was 26%. Patients that survived were discharged from the ICU without organ dysfunction. We conclude that selected patients with ACS may not require decompressive laparatomy, but will respond to nonoperative observation and supportive therapy. Introduction Splanchnic ischemia due to sepsis or hemorrhage is believed to be involved in the pathogenesis of multiple organ dysfunction syndrome. In previous studies performed in our laboratory we have studied microcirculatory blood flow of the small intestinal mucosa in a porcine model of septic shock [1] . We have demonstrated that microcirculatory blood flow (MBF) was redistributed from the jejunal muscularis towards the mucosa. The aim of this study was to measure changes in MBF in the jejunum during stepwise occlusion of the superior mesenteric artery (SMA). Methods Data from the sepsis group have been extracted from a previously published study [1] . Swiss landrace pigs (30 kg) were anesthetized and mechanically ventilated. Cardiac output (CO) was measured using thermodilution and SMA flow with ultrasonic transit time flowmetry. MBF was measured in the jejunal mucosa and muscularis using laser Doppler flowmetry. In the septic shock group (group S, n = 11), sepsis was induced by fecal peritonitis. In the SMA occlusion group (group O, n = 8), SMA flow was reduced in steps of 15% using an occluder. Results are presented as percent of baseline (mean ± SD, *P < 0.05 compared with baseline, † P < 0.05 mucosa vs muscularis). During septic shock, the CO, SMA flow and MBF of jejunal muscularis decreased to 56 ± 13%*, 47 ± 13%* and 36 ± 17%* † , respectively, while the MBF in jejunal muscularis remained virtually unchanged (86 ± 20% † ). In nonseptic animals, stepwise occlusion of the SMA to 42 ± 4%* of baseline produced a decrease of muscularis blood flow to 43 ± 12%* † while mucosal blood flow decreased less, to 65 ± 24%* † . Conclusion During reduced regional blood flow, microcirculatory flow decreased less in the intestinal mucosa than in the muscularis, suggesting redistribution of flow away from the muscularis towards the mucosa, both in septic and in nonseptic subjects. Blood flow redistribution appeared to be more pronounced in septic than in nonseptic animals. Objective Vasopressors are recommended for circulatory support during acute sepsis. They maintain blood pressure, but have differing effects on cardiac output (CO) and renal blood flow (RBF). In particular, they may impair RBF and increase the risk of renal insufficiency. The aim of the study was to compare the effects on RBF of five vasopressors, noradrenaline (NA), adrenaline (ADR), dopamine (DOP), phenylephrine (PE) and vasopressin (VP), in acute sepsis. All five vasopressors increased MAP (P < 0.01), but their effects on CO varied, with ADR and DOP producing the greatest increases (P < 0.01). SVR was increased by NA, PE and VP (P < 0.01), and was decreased by ADR (P < 0.01). Whereas NA and DOP increased RBF (P < 0.05), RFB was decreased by ADR and PE (P < 0.05; Table 1 ). Conclusion Despite similar effects on MAP, vasopressors have different effects on CO, SVR and RBF. NA and DOP were the most effective vasopressors in preserving RBF during sepsis, while ADR and PE had negative effects. Four out of 50 patients (8%) had one sonographic abnormality while they were in the ICU, 7/50 (14%) had two abnormalities, 11/50 (22%) had three abnormalities, 22/50 had four or more abnormalities and only 6/50 (12%) had no sonographic abnormality. In 2/50 (4%) hypervascularisation was detected in CD and CE study. Only these two patients had surgically proved AAC. Conclusion GB abnormalities are frequently seen on US in ICU patients even if these patients are not suffering AAC. The sonographic critiria are not specific. CD imaging, especially after CE imaging, is useful for the detection hyperemia in the acute stage of GB inflammation and may improve the accuracy of the method in early diagnosis of AAC. Available online http://ccforum.com/supplements/8/S1 Objective To investigate factors that may predict outcome in patients with severe abdominal sepsis that required treatment in an intensive care unit (ICU). Design A retrospective record review of survivors and nonsurvivors, comparing clinical, laboratory, microbiological, and therapeutic data, to identify specific poor prognostic factors. Setting A tertiary referral centre. Over 24 hours, WT developed severe intrarenal ARF with a more than threefold increase in Crea. DARC -/on the other hand displayed a significant protection from ARF, exhibiting only a small, clinically irrelevant increase in Crea over 24 hours (Fig. 1) . MPO was not different between WT and DARC -/-; both groups showed significantly elevated renal MPO after LPS injection, peaking at 4 hours (Fig. 2) and declining thereafter. Even after LPS injection, RT-PCR failed to detect DARC mRNA expression in the kidney of WT, whereas it could demonstrate cerebral expression of DARC mRNA at 12 and 24 hours after LPS administration. The aim of this study was to investigate the early cellular events in I-R injury using elective aortic surgery as a model. There were no histological features of acute inflammation in the preoperative or postoperative biopsies in either group. H&E and TUNEL staining showed a 3.5-fold rise in apoptotic bodies following conventional surgery. There was no significant change following EVAR. IL-6 expression occurred in the colonic epithelium localized to the base of the crypts. Splanchnic blood showed a fourfold increase in nitrosothiols and a 22-fold increase in IL-6 within 15 min of reperfusion. Peripheral blood showed a five-fold increase in IL-6 (Student's t test P < 0.05). In addition, plasma DNA concentrations were found to be significantly different between patients who developed a sepsis state and those who did not (septic patients, median = 192.1 ng/ml, IQR = 298; nonseptic patients, median = 73.8 ng/ml, IQR = 110.6, P = 0.03). Receiver operator characteristic (ROC) curves were calculated for the use of plasma DNA as a predictor of death and of sepsis (see Table 1 ). The specifications with the highest significance were taken as relevant. PMN migration below a cutoff of 6% at least 2 days in sequence occurred before infection in eight of the nine infected patients, but only in three of the 17 noninfected patients (i.e. a sensitivity of 88% and a specificity of 82%, P = 0.0008). Fever ≥ 38°C for 3 days in sequence showed a specificity of 94%, but a sensitivity of only 55% (P = 0.009). The other parameters had no significant discriminative power. Conclusions Among a variety of related parameters, PMN migration proved to be a sensitive predictive marker for infections. Impaired PMN migration indicates impending infections. Early recognition of an infection risk may help to initiate aggressive antimicrobial therapy before clinical manifestation of infection, thus improving therapeutic success.  The new assay detected the small molecular weight of CD14 specifically, but not the 49 kDa and 55 kDa soluble CD14 in serum. The concentration of normal controls (71 specimens) was 27.4 ± 14.4 (mean ± SD) ng/ml and the cutoff level was established at 57 ng/ml (mean ± 2SD). The ELISA detected 94.5% (52/55) of sepsis and 16.3% (13/80) of SIRS. The mean concentration of sepsis and SIRS was 248.2 ng/ml and 41.4 ng/ml, respectively. Sequential study of sCD14-ST was a significant association with the SOFA score and serum endotoxin level. Serum sCD14-ST increased in the very early phase of infection, and was detected much faster and easier than the blood culture test. The new assay was not correlated to soluble CD14 (IBL-Hamburg) and PCT (BRAHMS). Conclusion This ELISA can detect specificallyu for sepsis during the early phase of infection and is useful for monitoring the severity of sepsis. The small molecular sCD14-ST is a new marker for diagnosing sepsis. Available online http://ccforum.com/supplements/8/S1 Methods Subjects in the present study were 39 patients with SIRS admitted to the emergency unit. Plasma levels of SE were determined by ELISA at admission and 1, 3, 5, and 7 days after the admission. The normal range of SE was 3.17-32.09 ng/ml. The presence of various organ failures was diagnosed when patients had the SOFA score higher than 3 points in each organ dysfunction scoring system. A two-sided Fisher's exact test was used to analyze the difference in the incidence of organ failure and the mortality. P < 0.05 indicated the statistical significance. Our mortality rate was 60%. We had 10 patients in the nonsurvivor group and eight patients as survivors. The two groups had similar APACHE II scores (nonsurvivors 26 ± 6; survivors 24 ± 5; NS). At day 1 there were no statistical differences for any of the substances analyzed. From day 3 onwards, we achieved significant statistical differences between survivors and nonsurvivors for total cholestherol, HDL fraction, trigycerides, glycemia and C-reactive protein. The correlations of C-reactive protein with the HDL fraction, total cholesterol, triglycerides and glycemia were not good. As independent variables, we found only glycemia and trigycerides. Conclusions In our patients, hypocholesterolemia, low levels of HDL fraction, hypertriglyceridemia and hyperglicemia were statistically significant related to a poor prognosis. C-reactive protein did not show a good correlation with other parameters. The objective of the present study was to investigate the pathophysiological role of iNOS induction in renal proximal tubules during experimental endotoxemia in humans. Both TNF-α mRNA and protein levels were detected as soon as 30 min after initiation of CPB and before aortic clamping in both groups, but were lower in pigs that were on hypothermia than in the others (P < 0.05, respectively). This difference persisted during and after CPB. The levels of iNOS and COX-2 were detected during and after CPB but without any difference between groups. Phosphorylation of p38 MAP and ERK1/2 MAP kinases and of IκB was detected before, during and after CPB. Levels of phospho-p38 MAP kinase but not of ERK1/2 MAP kinase and IκB tended to be lower in animals on hypothermia than in the others (P < 0.1). Conclusion This study shows for the first time that cardiac surgery induces the expression of TNF-α in the myocardium as soon as 30 min after institution of CPB, before aortic clamping. This is associated with the activation of p38 MAP and ERK1/2 MAP kinases and NF-κB pathway. The inhibition of TNF-α expression by hypothermia is related to the inhibition of p38 MAP kinase. Corp., Tokyo, Japan), an elastase inhibitor extracted from human urine, has been used to treat for patients with acute pancreatitis or acute circulatory failure since more than 15 years ago in Japan. In the untreated group, the UTI level in plasma at the 7th day after hospitalization was siginificantly higher than that in the treated group (96.9 ± 44.4 vs 15.6 ± 6.5 U/ml, P < 0.05). Also, the TM level was also significantly different between the untreated group and the treated group (6.0 ± 2.4 vs 3.6 ± 1.4 FU/l, P < 0.05) at the 7th day. Other examination values showed no significant differences between the two groups during their clinical courses. Five out of the six placebo-treated Cynomolgus monkeys died or required euthanasia within 24-72 hours after E. coli challenge, while one animal survived for 5 days. In contrast, six of the eight animals treated with the humanized anti-IFNγ mAb survived for 7-14 days (P = 0.013 vs placebo). More specifically within the treated group, two animals died early of sepsis (day 3 and day 4, respectively), two animals were euthanized on day 7 because of limb necrosis (caused by catheter-related thrombosis) and not directly because of the sepsis symptoms, one animal was euthanized on day 9 due to sepsis symptoms, and three animals survived 14 days and appeared to be in good health. Treatment with the anti-IFNγ mAb decreased the systemic TNF-α, IL-6 and IL-1β response to E. coli. Furthermore, renal dysfunction, evidenced by increased creatinine, was significantly decreased by treatment with the anti-IFNγ mAb. Conclusions This study demonstrates that, in a primate model of E. coli-induced septic shock, the neutralization of IFNγ with a mAb, administered after the onset of clinical signs of sepsis, improves survival and attenuates the pathological changes associated with the development of multiple organ dysfunction. This suggests that IFNγ blockade potentially represents an effective mode of intervention in lethal septic shock. Methods We simulated an interventional trial of a neutralizing body against tissue necrosis factor (anti-TNF) in sepsis based on a mechanistic mathematical model that includes a bacterial infection, the host response, and a therapeutic intervention. Simulated cases differed by bacterial load and virulence, as well as individual propensity to mount and modulate an inflammatory response. We submitted 1000 cases to three doses and durations of anti-TNF, and present the results of the simulation. To evaluate the usefulness of modeling to improve patient selection, we constructed a logistic model with a four-valued outcome: (1) helped by treatment, (2) survives irrespective of treatment, (3) dies irrespective of treatment, and (4) harmed by treatment. Independent predictors were 'measured' at the time of disease detection and 60 min later, and included serum TNF, IL-10, IL-6, activated protein C, thrombin, tissue factor, blood pressure and cell counts. All results from the statistical model are reported in a validation cohort. Control survival was 62.9% at 1 week. Depending on the dose and duration of treatment, survival ranged from 57.1% to 80.8%. Higher doses of anti-TNF, although effective, also resulted in considerable harm (Fig. 1) Conclusions Our models points out how to improve patient selection and how therapy could be individualized. Available online http://ccforum.com/supplements/8/S1 Impaired host defense mechanisms following surgical stress such as burn, major surgery and polytrauma are considered important for the development of infectious complications and sepsis. We tested whether interferon (IFN) gamma can improve monocytic and lymphocytic functions and can reduce deaths related to sepsis. In order to restore their antimicrobial defense capacity, recombinant human IFN-gamma, 100 µg, was administered intravenously once daily to six immunoparalyzed patients. Informed consent was obtained from patients in all cases, and the study received local hospital ethical committee approval. Intracytoplasmic Th1 and Th2 cytokine production in isolated peripheral blood mononuclear cells was assessed by flow cytometry following in vitro activation by phorbol myristate acetate plus ionomycin. Monocytic human leukocyte antigen-DR (HLA-DR) expression was also measured. Immunoparalysis was defined as a decreased level of HLA-DR expression of monocytes < 30% or a decreased level of Th1 < 10%. IFN-gamma applied to immunoparalytic patients with low monocytic HLA-DR expression restored the deficient HLA-DR expression and in vitro Th1 cytokine production completely within 3 days. Recovery from immunoparalysis resulted in clearance of sepsis in four of six patients. IFN-gamma administration in septic patients accompanied with immunoparalysis is a new therapeutic strategy. years, P < 0.05) and had a higher SAPS II score (26 ± 10 vs 18 ± 9, P < 0.01). The delay of admission in the critical care unit (CCU) was higher in the pneumonia group (0.3 ± 0.7 days vs 3.2 ± 4.0 days, P < 0.01). The delay of handling by a physiotherapist was also higher (3.7 ± 2.0 days vs 8.1 ± 8.0 days, P < 0.01). Pneumonia was associated with a longer period of mechanical ventilation (10 ± 11 days vs 21 ± 13 days, P < 0.05) and a longer stay in the CCU (8.6 ± 9.5 vs 39.2 ± 29.3, P < 0.0001). Univariate analysis of qualitative factors is presented in Table 1 . Early mechanical ventilation, upper cervical spine involvment and inhospital mortality were not related to pneumonia. Overall mortality is higher in the pneumonia group. Our study suggests that an early and aggressive handling of patients with cervical spine injury, particularly with complete motor deficit, could be beneficial to decrease pneumonia incidence and its associated adverse events. In the past few years the clinical pulmonary infection score (CPIS) has been purposed as a diagnostic tool in ventilator-associated pneumonia (VAP). The CPIS incorporates five variables: temperature (T°C), white blood cells (WBC), tracheal secretions, pO 2 /FiO 2 and RX. The range of CPIS is from 0 to 12 and its positive predictive value (PPV) has been found > 90% at a cutoff point ≥ 6. Recently, the CPIS was purposed in order to monitor the course of VAP and the efficacy of therapy. Objective To evaluate the CPIS in diagnosis of and monitoring the course of illness in children with VAP. Design A retrospective observational study. Setting Pediatric ICU in a national children hospital. Data collection CPIS was collected 48 hours before diagnosis of VAP, at diagnosis, and daily for the first week. In all patients were evaluated the mean PAW, positive end expiratory pressure (PEEP), PO 2 /FiO 2 , RX score, PCR, WBC, T°C and number of bronchial suctionings/day. We have also evaluated the influence of each parameter of CPIS on the final score. Data were analysed with the Student t test (P < 0.05*), chi square (P < 0.05**) and univariate analysis (correlation coefficient R 2 ***). In our population the incidence of VAP was 37% (15/40 patients) with mortality 27% (four patients). The mean CPIS value at the time of diagnosis was statistically higher than 48 and 24 hours before in all patients (4.9 ± 0.8 vs 7.5 ± 1.5, P < 0.05); in 14/15 patients it was ≥ 6 (PPV 93%). At day 3 after diagnosis the population was divided into two groups: patients with CPIS ≥ 6 (group 1, n = 5) and patients with CPIS < 6 (group 2, n = 10). At this time between the two groups were reported statistically significant differences in PEEP (10.5 ± 1 vs 5.6 ± 2.7, P < 0.05*), PAW max (27.5 ± 6.6 vs 14.7 ± 8.6, P < 0.05*), pO 2 /FiO 2 (145 ± 10 vs 282 ± 20, P < 0.05*), PCR reduction > 30% (20% vs 50% of patients, P < 0.05**) and microbiological positivity (80% vs 20%, P < 0.05**). pO 2 /FiO 2 increases significantly in group 2 (P < 0.05*) and univariate analysis revealed that only pO 2 /FiO 2 is related to the CPIS score (R 2 *** 0.77***); WBC, T°C, number of suctioning/day and RX score are not related. All patients with CPIS < 6 survived whereas 80% of patients with persistently high CPIS after 72 hours from diagnosis of VAP died. The analysis of the MSOFA score revealed significant differences in circulatory (P < 0.05*) and respiratory (P < 0.05*) scores between those who died and survivors at day 3 and later after diagnosis of VAP. Conclusions CPIS had an elevated PPV in diagnosis of VAP (93%), and is an early predictor of poor outcome in patients with VAP and allows a good monitoring of the course of illness. Aim Ventilator-associated pneumonia (VAP) is a common cause of morbidity in ICU patients. There is still no evidence that invasive bronchoscopic techniques should form part of a routine approach to suspected VAP [1] . In our study, we compared specimen results in terms of sensitivity and specificity that were taken with bronchoalveolar lavage (BAL) fluid and endotracheal aspirates (ETA) and we examined the value of clinical pulmonary infection score (CPIS) in the diagnosis of VAP. We determined BAL ≥ 10 4 colony-forming units (cfu)/ml in all patients with ETA ≥ 10 5 cfu/ml and exact conformity was achieved. We determined BAL ≥ 10 4 cfu/ml, ETA were ≥ 10 4 to < 10 5 cfu/ml in 18 patients. Although ETA results were below the threshold level, they showed conformity with BAL results in 18 patients. We accepted BAL ≥ 10 4 cfu/ml as a reference value of CPIS ≥ 6, and we determined sensitivity of 83% and positive predictive value of 50% during the diagnosis. When we accepted CPIS ≥ 6 as a reference value, the possibility of inaccurancy of diagnosis is high in every one of the two patients with VAP. Nearly one patient was missed in every five patients with VAP. Conclusions BAL results did not provide superiority in the diagnosis of VAP when compared with the ETA. A threshold level ≥ 10 4 cfu/ml may be reduced for ETA and evaluation of CPIS alone is not suitable for diagnosis or exclusion of VAP. Methods A prospective study during 9 months. Included were all patients who required mechanical ventilation for 12 hours or more. At admission to the ICU patients were randomized ito two groups: one group was suctioned with CESS, and another group with OESS. VAP was defined according to the following criteria: a chest radiographic examination showing new or progressive infiltrate; new onset of purulent sputum; significant quantitative culture of pathogen from respiratory secretions (tracheal aspirate > 10 6 cfu/ml, bronchoalveolar lavage > 10 4 cfu/ml or protected bronchial brush catheter > 10 3 cfu/ml). The statistical analysis was realized by the chi-square test and the Student t test, and we took P < 0.05 to consider a significant difference. Conclusions We conclude that in our series, the CTSS did not reduce the ventilator-associated pneumonia incidence, nor the exogenous pneumonia. Background CPIS is an accepted tool for clinical estimation of ventilator-associated pneumonia (VAP), encompassing five components: temperature, blood leukocytes, tracheal secretions, oxygenation index and chest roentgenogram. VAP is considered a frequent complication in mechanically ventilated severe polytrauma patients. There are some current issues that highlight the influence of VAP development on patient mortality [1] . The aim of this study was to evaluate VAP development in severe polytrauma patients according to CPIS criteria and on that basis to determine the patients' clinical course. Design A prospective observational study. Setting Seventeen-bed trauma intensive care unit. Methods Thirty-one severe polytrauma patients (ISS > 26 at admission) requiring mechanical ventilation for more than 3 days who developed VAP were enrolled. We recorded the length of stay of all patients and examined CPIS criteria daily for a period of 10 days after pneumonia occurrence. Patients were divided into subpopulations according to the severity of post-traumatic complications. We calculated the mean 10-day CPIS value for each patient. We considered CPIS > 5 points to be indicative for VAP. The period that VAP occurred was between the 5th and 8th ventilator day. We observed that the clinical course of VAP depended on the severity of the post-traumatic complications. Patients with no post-traumatic complications had a mean 10-day CPIS value of 4.5. Patients with severe complications had a mean 10-day CPIS value of 5.3, 7.1, 8.1 and 8.4 for patients with single organ failure (survival rate 100%), for patients with pulmonary contusion (survival rate 65%), for patients with severe sepsis (survival rate 26%) and for patients with multiple organ failure syndrome (> 2 organs involved, survival rate 17%), respectively. The VAP resolution was shorter in patients with an adequate initial antibiotic therapy. Conclusion These data suggest that in the length of 10 days, we could have a precise estimation for the severity of VAP and its dynamics. Mean CPIS values showed good correlation with the degree of post-traumatic complications. CPIC dynamics could serve as a good clinical tool for determination of whether the patient would recover or we might expect a bad outcome. A total of 65 patients were included in the study (53 men, 12 women) with a mean age of 54.6 years. The mean ICU stay was 24 days. One hundred and fifty-one infections were recorded: ventilator-associated pneumonia (62.3%), primary bacteremias (22.5%), catheter-related infections (9.4%), meningitis (1.3%) and surgical infections (2%). Microorganisms most commonly isolated were: Pseudomonas aeruginosa (33.7%), Acinetobacter baumannii (28.5%), Klebsiella pneumoniae (14%), and Staphylococcus epidermidis (7.8%). Patterns of resistance were as follows: P. aeruginosa was sensitive to ceftazidime in 16.7% of cases, to imipenem in 38.4%, to ciprofloxacin in 10.2% to piperacillin/ tazobactam in 62.8% and to colistin in 98.7%. A. baumannii was sensitive to imipenem in 61% of cases, to ampicillin/sulbactam in 51.5% and to colistin in 76.5%. K. pneumoniae was sensitive to imipenem in 74% of cases, to piperacillin/tazobactam in 48% of cases and to colistin in 88.8%. One hundred and nine patients enrolled with successful insertion of 109 catheters, 51 of them impregnated (group 1) and 58 standards (group 2). There were no statistically significant differences between the groups in age, seven infection-related risk factors, ICU diagnosis, mean SOFA score, insertion sites, duration of catheterization, wrong location at X-ray, signs of allergy, and catheter colonization rates. The mean times of duration of catheterization in group 1 and group 2 were 15.1 ± 9.5 days and 13.5 ± 8.1 days, respectively (P = 0.3). The mean SOFA scores in groups 1 and 2 were 5.04 ± 2.9 and 4.9 ± 3.1, respectively (P = 0.8). The colonization rates were 29.4% (15 catheters) in group 1 and 34.5% (20 catheters) in group 2 (P = 0.5). Thirty-one catheters presented Gram-positive cocci, four of them associated with Gram-negative bacilli and tyree with fungi. Three catheters presented Gram-negative bacilli alone and one catheter presented fungi alone in the roll-plate. All treatments were well tolerated. Table 1 presents the evaluable sputum AMIK concentrations from tracheal aspirates normalized to the starting dose (mg/ml/mg starting dose), and in vitro lung dose as the per cent of the total dose (means ± SD). Sputum concentrations were greater with AP and APD than with MN (P < 0.05). For the lung dose: APD > AP > MN (P < 0.05). Conclusions APD delivered AMIK with greater efficiency than the marketed nebulizers. Concentrations of AMIK in the sputum were consistent with relative device efficiency measured in vitro. High efficiency delivery via APD may make aerosolized AMIK a viable part of treatment regimens for ventilator-associated pneumonia. In the safety analysis (n = 395 patients), no difference was found between groups. Twenty patients in group L (10.3%) and 16 in group C + O (8.0%) presented at least one adverse event (AE) considered as treatment-related (P = 0.42). The treatment was withdrawn following the occurrence of an AE considered as treatment-related in 2.6% (L) vs 2.0% (C + O) patients (P = 0.75). Conclusion Levofloxacin (500 mg twice daily dose) is at least as efficacious as the cefotaxime (1 g three times daily) + ofloxacin (200 mg twice daily) combination for the antibiotic therapy of patients with a severe CAP hospitalized in an ICU, with success rates around 80%. Methods Twenty patients received linezolid (600 mg intravensouly every 12 hours). CVVH was performed using highly permeable polysulfone membranes (PSHF 1200, Baxter, Germany and AV 400, Fresenius, Germany). The mean blood flow rate and ultrafiltration rate were 182 ± 15 ml/min and 40 ± 8 ml/min, respectively. Postdilution was performed. Linezolid concentrations in serum and ultrafiltrate were determined by high-performance liquid chromatography. The mean linezolid serum concentration peak (Cmax) was 15.32 ± 3.98 µg/ml, and the mean trough level (Cmin) was 1.87 ± 1.70 µg/ml. The elimination half-life (T1/2) was 4.30 ± 1.74 hours. The total clearance (CLtot), hemofiltration clearance (CLhf) and volume of distribution (Vd) were 9.31 ± 3.48 l/hours, 31.25 ± 12.77 ml/min and 51.30 ± 12.30 l, respectively. There were no significant differences in age, sex, diagnosis, APACHE II score, etiologic agents, bacteremia, organ dysfunction and antimicrobial therapy between groups. The CP group showed significantly lower clinical failure (CP, 0/13 vs IP, 15/32 [46.87%], P = 0.001) and significantly lower mortality attributable to VAP (CP, 0/13 [0%] vs IP, 8/32 [25%], P = 0.049). In addition, CP patients received one-third less daily dose than those treated intermittently. There were 5592 ICU patients incurring 6033 hospitalizations and 6758 ICU admissions during the study period. Of all hospitalizations, 60.4% required mechanical ventilation and 11.9% received an antipsychotic in the ICU. Haloperidol was the most frequently used antipsychotic (79.5% of all administered doses), with risperidone (4.7%) and olanzapine (2.3%) the next most common. Haloperidol was given to 24.9% of MV > 48 hours patients and on 6.9% of all ICU days. MV > 48 hours patients received mean (SD) daily haloperidol dose of 10.2 (9.5) mg for 5.8 (8.0) days, or 24.0% of their ICU days. From an observed case analysis (on log-transformed data), the overall mean neurological assessment time (unpaired t test) and between-subject variability (F test) around the assessment time were significantly reduced in the Remi group compared with Fent and Morph. Table 1 presents the median (range) time from reducing analgesia/sedation until neurological assessment (hours). No clinical differences were observed in the incidence of adverse events. Seventeen patients received RBA and 16 patients received HBS for at least 10 days. Table 1 presents the AEs. The obtained results were analysed statistically: SpO 2 decreased substantially (IV, V), mean arterial pressure (MAP) (V), and CO (IV) in relation to output values. A statistical increase was noticed in the pressure in the pulmonary artery (II-V, VIII) and Qs/QT (II-VIII), the highest in interval IV and V. Conclusions OLV causes the increase of Qs/QT and, consequently, the lowering of SpO 2 in the 5th min (43.78%) and 30th min (35.4%) after excluding an operated lung from ventilation. OLV is connected with the lowering of SpO 2 and increasing pressure in the pulmonary artery. Propofol used in TIVA causes the increase of shuntapproximately four times. Increasing Qs/QT does not cause the critical lowering of oxygen pressure in arterial blood. During TIVA a transitional decrease of CI and MAP was noticed. Available online http://ccforum.com/supplements/8/S1 Objective The objective of this study was to analyze the incidence of accidental withdrawal of nonintravascular catheters in critical care. Unfortunately, ketamine exerts some side effects. Many researchers use benzodiazepines to cover these undesirable effects. The incidence of cardiac myocyte damage, diagnosed by an elevated cTnT, was 62/180 (33%) with an associated all-cause mortality rate of 32/62 patients (51.6%) vs 24/118 patients (20.3%) in cTnT normal patients (P < 0.001). The median length of admission was 5.5 days for patients with a raised cTnT and 3 days for patients with a normal cTnT (P < 0.003). In 70.9% of cases, the raised cTnT occurred within the first 72 hours of admission to the ICU. Of those patients with an elevated cTnT, 10 patients were already on aspirin, two on clopidogrel and 14 had clear contraindications to antiplatelet therapy. Four patients (6%) were prescribed aspirin and 31 eligible patients (50%) did not receive antiplatelet therapy. In patients with an elevated cTnT, 60/62 sets of notes were assessed for glycaemic control. In these patients 38/60 (63.3%) had BM > 11.1 mmol/l and 59/60 (98.3%) had BM > 6.1 mmol/l. A past history of impaired glucose tolerance/diabetes mellitus was present in 12/38 (31.6%) of patients with an elevated BM > 11.1 mmol/l. Insulin therapy was not commenced in 6/38 patients with BM > 11.1 mmol/l. In 19/32 (59.4%) of patients prescribed insulin there was a delay in infusion commencement (median 3.5 hours, range 1-9 hours). Hypoglycaemia (BM < 2.2 mmol/l) was documented in 3/32 patients receiving insulin. The mortality rate was high in all patients with a raised BM (BM 6.1-11.1 mmol/l, mortality 12/21 (57.1%) vs 20/38 (52.6%) for BM > 11.1 mmol/l; NS). The one patient without an elevated BM survived. Conclusions Elevated markers of cardiac myocyte damage are common in critically ill patients and are associated with an increased mortality rate. The use of antiplatelet agents and optimisation of glycaemic control in this group might reduce morbidity and mortality. The aetiology of raised cTnT in the critically ill and specific treatment outcomes requires further investigation. Insulin requirement (in mainly cardiothoracic surgical patients) is suggested as being more strongly associated with ITU mortality than poor glycaemic control [1] . We prospectively recorded insulin administration (soluble human insulin, by infusion; Actrapid ® ; Novo Nordisk) in consecutive general ITU patients admitted over a 1-month period to our unit where guidelines are set to attempt to achieve an arterial blood glucose concentration between 4.5 and 8.0 mmol/l. Patients were subsequently divided into two groups according to whether or not they required insulin during the first 24 hours. Blood glucose was measured using the Radiometer ® ABL System 625 or 700 blood gas analysers. Samples were taken at least every 2 hours. Ninety-eight patients were included in the study: 51 received no insulin, 47 received insulin at some time during the first 24 hours of admission and patients were grouped accordingly. There were no patients with a history of diabetes in the 'no insulin' group and 10 in the 'insulin' group. The mean (SD) number of hours patients who received no insulin were recorded as having a blood glucose > 8.0 was 0.40 (1.41) and for the 47 patients who received insulin 4.74 (4.77). The mean (SD) total insulin dose in the first 24 hours for the 'insulin' group was 38.4 (57.3) IU. Mortality in the 'no insulin' group was 13.1% and in the 'insulin' group 19.1% (chi-square 1.238, P > 0.20). There were no deaths among the previously diagnosed diabetic patients. When these patients were excluded from the analysis the mortality was 13.1% and 32.1%, respectively (chisquare 2.78, P < 0.10, P > 0.05). The mean (SD) length of stay in the ITU was 4.12 (6.90) days in the 'no insulin' group and 6.77 (8.89) days in the 'insulin' group (one-tailed t test, unequal variance, P = 0.05). Conclusion An increased length of stay in ITU is predicted if insulin is required to maintain blood glucose < 8.0 mmol/l in the first 24 hours of ITU admission. An increased mortality may be predicted if insulin is required to maintain blood glucose < 8.0 mmol/l in the first 24 hours of ITU admission in nondiabetic patients. Introduction Elevated blood glucose concentration is an important factor for mortality and morbidity in critically ill patients. Previously, a randomized controlled trial showed that a blood glucose level of about 6 mmol/l is associated with less multiorgan failure and a significantly higher survival rate compared with levels above 8 mmol/l. Platelets play a crucial role in hemostasis and inflammation. However, the effect of short-term elevated blood glucose levels on platelet activation has not yet been evaluated systematically. Objective To evaluate the influence of blood glucose levels on platelets in vitro. Methods Citrated blood samples were drawn from healthy blood donors (40% male, age 38 ± 13 years [mean ± SD]). Exclusion criteria were smoking and the use of drugs interfering with platelet function. Blood samples were adjusted with glucose (Sigma, Taufkirchen, Germany) to final concentrations of 5 mmol/l (control group), 10 mmol/l (group 1) and 15 mmol/l (group 2), respectively. Samples were incubated for 10 min at 37°C with fluorescencelabeled monoclonal antibodies against CD62P, CD41, CD36, or CD42b (all: Beckman-Coulter, Krefeld, Germany). To evaluate platelet reactivity 2 and 6 µM thrombin-receptor-agonist-peptide-6 (TRAP-6; Bachem, Heidelberg, Germany) or 5 and 10 µM adenosine-di-phosphate (ADP; Sigma, Taufkirchen, Germany) were added. Analyses were performed in a flow-cytometer (Epics XL; Beckman-Coulter). The mean fluorescence intensity was calculated. Determination of platelet aggregation was performed by the turbidimetric procedure (BCT, Dade Behring, Marburg, Germany). Aggregation was induced with ADP (200 µM/l), collagen (2 mg/l) and epinephrine (100 µM/l; all Dade Behring). Statistics for intergroup differences were performed by one-way ANOVA. The initial blood glucose concentration was 5.0 ± 1.1 mmol/l. The blood glucose level had no significant influence on the expression of CD36 and CD62P, with and without stimulation. By contrast we observed a significant decrease in expression of CD42b in group 2 compared with the control group (unstimulated, P < 0.001; TRAP-6, P = 0.005; ADP, P = 0.012). A similar observation was made for CD41 expression (unstimulated, P < 0.001; TRAP-6, P < 0.05; ADP, P < 0.001). Also in group 1, a significant decrease in CD41 expression was observed after ADP stimulation. No significant differences were seen by aggregometry with either agonist. (1) There was negative correlation between the I/E ratio and M1/M3 (r = -0.31/r = -0.44). (2) Comparison between A (M1, 3.3 ± 1.1; I/E ratio, 55 ± 20; n = 23) and B (M1, 3.5 ± 0.8; I/E ratio, 18 ± 9; n = 11): there was significant difference in I (P < 0.005), BGm (183 ± 16 vs 153 ± 18, P < 0.005), and IC (19 ± 7 vs 14 ± 4, P < 0.05), but no significant difference in E, M1, CPR, IS, and SOFA score. (3) Comparison between C (M1, 7.3 ± 1.7; I/E ratio, 12 ± 8; n = 15) and D (M1, 7.8 ± 2.2; I/E ratio, 62 ± 44; n = 5): there was a significant difference in I (P < 0.005) and BGm (145 ± 21 vs 168 ± 16, P < 0.05), but no significant difference in E, M1, M3, CPR, IS, IC, and SOFA score. Interpretation The I/E ratio was a daily measurable indicator of glucose tolerance. However, there was discrepancy between the M value and the I/E ratio in some patients (groups B, D). the mechanism of the discrepancy was unclear, but the influence of IC and/or an increase of glucose metabolism by BG itself (ex. mass action effect, activation of glucose transporter-2, etc.) in group B, and a decrease of that in group D was speculated, because the M value was measured under a BG level of 80 mg/dl, while the I/E ratio was under BG control aiming at 150 mg/dl. Six out of 20 (30%) patients had a cortisol level > 400 nmol/l. This group of patients had a mean (± SD) ISS of 18 (± 7) and a mean cortisol level of 606 nmol/l (± 155). None required inotropic support, and mortality was 0/6 (0%). Fourteen out of 20 (70%) patients had a cortisol level < 400 nmol/l. This group of patients had a mean ISS of 28 (± 7.5) and a mean cortisol level of 253 (± 89). Six out of 14 (43%) required inotropic support, and the mortality was 3/14 (21.5%). These patients also had significantly higher fluid and blood product requirements. Conclusion Cortisol deficiency is common in patients after major trauma and is associated with a higher ISS, increased fluid and blood product requirements, increased inotrope requirements, and increased mortality. These patients may benefit from early steroid replacement therapy. The objective of this study was to investigate the functional integrity of the hypothalamic-pituitary-adrenal axis in critical illness by stimulating with the low-dose ACTH stimulation test (LDST) and hCRH. The study included 16 (15 male) mechanically ventilated patients, having a mean age of 52 ± 19 years. Underlying diagnoses included major operation (n = 7), multiple trauma (n = 5), stroke (n = 3), and pancreatitis (n = 1). Patients were enrolled in the study 3-14 days after initiation of mechanical ventilation. Median APACHE II and SOFA scores at the study day were 13 (range: 8-23) and 5.5 (range: 4-12), respectively. All patients underwent stimulation first with the LDST (1 µg) and then on the following day with 100 µg hCRH. ACTH and cortisol concentrations were determined from -15 to 120 min after hCRH. Normal cortisol responses to the LDST and hCRH were defined as peak plasma concentrations above 18 µg/dl and 20 µg/dl, respectively. An appropriate ACTH response to hCRH was considered if a twofold increase in ACTH was observed. In the entire patient population, baseline cortisol (mean ± SD) was 15.1 ± 7.1 µg/dl and stimulated cortisol (median) was 21.4 µg/dl following the LDST. Four (25%) of the 16 patients had subnormal stimulated cortisol levels after the LDST. These four patients also had subnormal peak cortisol concentrations following hCRH. The patient mean age was 64.6 years; 97% were white, and 58% were male. Coagulopathy was found in 66% of the patients. Ten patients were on dexamethasone before the test. None of the patients were on any medication known to interfere with the test. There was no patient with previous history of adrenal/pituitary disease. Of the 46 patients who received Etomidate, 36 (78%) were diagnosed as having relative adrenal insufficiency compared with 58/117 (50%) patients who did not (P = 0.0008). Relative adrenal insufficiency was noted in 79% of the patients who received Etomidate within 6 hours compared with 78% of the patients who received Etomidate later than 6 hours of the test (P = 0.9246). The mortality rate was 53% (50/94) in patients with relative adrenal insufficiency compared with 61% (42/69) in patients without relative adrenal insufficiency (P = 0.3287). There was higher CuZn-SOD activity (mean ± SEM, 30,332.5 ± 2369.9 U/g Hb) in septic patients in comparison with healthy controls (23,192.2 ± 1078.7 U/g Hb; P = 0.01). On the other hand, PON1 activity measured with paraoxon (5.58 ± 0.71 U/ml) resp. phenylacetate (17,642.3 ± 1501.1 U/ml) was lower in sepsis when compared with controls (9.55 ± 0.93 U/ml resp. 29,181.1 ± 2198,6 U/ml; P < 0.01 resp. P = 0.001). After recovery there was no difference in activity of both CuZn-SOD and PON1 of patients and controls. Moreover, we found positive correlation between activity of PON1 and level of total and HDL cholesterol in sepsis and after recovery. We observed no age and sex dependence in activity of both enzymes in septic patients and controls. Conclusion Patients admitted to the intensive care unit with severe sepsis exhibit abnormal anitoxidant enzyme activities. Purpose To assess the efficacy of scavengers on lung injury during intra-abdominal sepsis in rats. Methods A retrospective cohort study of children < 16 years (n = 18) admitted for acute management of DKA to two paediatric ICUs. Stewart's physicochemical theory was used to calculate the independent effect of chloride on the bicarbonate and base deficit via a linear regression model. This model was then used to: (1) quantify the effect of chloride on the base deficit, and (2) evaluate the relationship between change in the anion gap and both bicarbonate and base deficit before and after correction for chloride. Results Eighteen children (median age 12.7 years, weight 43 kg) were followed for 20 hours after initiation of therapy (insulin and fluid resuscitation). There was a steady improvement in pH over this time (mean pH 6.97-7.31). However, at 20 hours a significant base deficit persisted (mean 10.1 mmol/l), despite the anion gap having normalised (mean 33.7 to 16.4 mmol/l). The base deficit at this time was almost exclusively due to hyperchloraemia (98%). The relationship between changes in the anion gap and both bicarbonate and base deficit improved dramatically, approaching one-for-one after correction for chloride (slope 0.99, r 2 = 0.96 and slope 1.14, r 2 = 0.95, respectively). There were no differences in terms of age, APACHE II score at admission, reason for coma and BMR between Group 1 and Group 2 (P > 0.05). Mean body temperatures were 35.6 ± 0.9°C and 37 ± 0.6°C (P < 0.01), mean SjVO 2 values were 90.3 ± 9.9% and 77.9 ± 10% (P < 0.01) and mean REE values were 1542 ± 580 kcal (97 ± 26.8% of mean BMR) and 1963 ± 600 kcal (117 ± 29.2% of mean BMR) (P < 0.05) in Group 1 and Group 2, respectively. In Group 1b, the mean body temperature was lower and the mean SjVO 2 was higher than the values before brain death (P < 0.05). In this group, although the mean REE was lower than the value before brain death, this difference was not statistically significant (P = 0.07). There were large differences in EN calculated by the computer, while a number of times the computer designated the use of a different preparation in order to better suit the patient's nutritional needs. There was a reduction of the time consumed for the calculations (65%), and a decrease in false calculations (20%), whereas the early recognition of metabolic complications increased to 40%. The utilization of specialized software seemed to be able to help health professionals to select an optimal EN regimen and to estimate the appropriate fluid volume according to patient needs. Conclusion Implementation of this software enables health professionals to overcome the burden of calculations, while it can also accomplish labeling, statistic analysis, and record management, thus allowing the provision of individualized EN to become an efficient standard routine procedure. It promotes a simple, fast, and safe way of providing individualized nutritional support and the quality of nutritional services would certainly benefit from its routine clinical application. It is difficult to achieve transpyloric placement of an enteral feeding tube in infant cases. We have found a new method to place an enteral diet tube for postpyloric feeding in infants. There were no significant differences between Group I and Group II with regard to gender and carboxyhemoglobin levels. On admission, the QTd, QTc, and QTcd intervals in Group I were significantly increased compared with Group II, but not the QT interval. There were no significant differences in QT interval measurements between Group I and Group II 72 hours after admission. Conclusion Although QT dispersion increased in patients with CO poisoning, age-related increases in QTd in the absence of QT interval prolongation may address this group as high risk. Complications after AAOD: vomiting (more than two times per day) in 10 patients (15%), diarrhoea (more than three times per day) in three patients (4%). No aspiration pneumonia or renal failure was seen. One patient was admitted to a hospital for 2 days to prevent dehydration. (3) The results for abstinence, employment, training and education, and criminal behaviour are shown in Table 1 . Conclusion (1) Although the majority of patients in this group made use of methadone programmes, they still often suffered from health problems common to intravenous drug users such as being underweight, respiratory problems and hepatitis B and hepatitis C. No HIV-positive patients were found. (2) Complications after AAOD were infrequent and not severe. (3) AAOD and naltrexone combined with CBT as provided by our clinic leads to opiate abstinence in 70% of patients after 1 year and to a significantly higher participation in employment, training and education, and a significant decrease in criminal activities.  Blood gas examination showed the mean pH was 7.22 ± 0.14 and the mean base excess was -10.0 ± 6.5. Endoscopy revealed multiple deep brownish-black ulcers (four patients) and perforation (two patients). Chest X-ray revealed air bubbles close to inferior the IIIrd part of the oesophagus while abdominal X-ray revealed no perforation. The ICU stay was 20 ± 7 days. Complications included: four cases of postoperative complications, including in the first surgical procedure break-up of enterostomy (n = 1) and in the reconstruction phase anastomosis pseudo-diverticula (n = 1), and anastomosis leakage (n = 2 died). The surgical mortality was 33%. All patients tolerated oral intake well after surgery; a high-protein and hypercaloric diet seemed to be beneficial for patients. In the finite population studied, two-thirds of all (adult and child) submersion incidents involved children, totaling 420 cases (mean = 42 children/year; annual incidence = 10.0 per 100,000), with 72% (n = 303) occurring in those aged 5 years or younger (20.2 per 100,000/year). In certain years, this younger cohort comprised as many as 87% of cases. Most cases (65%) occurred in summer and 83% between 12:00 and 8:00 pm (none 12:00-7:00 am). The site was a pool in 75% of cases (n = 317) with 64% of these at apartments. Only 19% involved tubs/spas (annual range = 6-34%) and 5% were in buckets, toilets, bayous, lakes, and creeks. Of the 420 total cases, one child was found dead on-scene and 234 clearly required resuscitative efforts (using strict criteria). Bystanders performed CPR in 82% of these resuscitation cases (n = 193) and 72% of these children survived long-term (99% neurologically intact). However, if a child remained apneic/pulseless by the time emergency services arrived (average response = 5 min), less than 5% were revived (none neurologically intact). Of 94 total deaths, two-thirds occurred in pools. In the four hospitals, 110 patient records were reviewed. Fifty-six of the cardiac arrests occurred on a ward and 25 (45%) of these patients fulfilled MET calling criteria. The mean time from the first documented abnormal vital sign to the arrest was 3.8 hours (range 0.25-8.00 hours).The proportion of patients meeting MET criteria differed significantly between the tertiary teaching hospital, the two secondary hospitals and the trauma hospital (14%, 27%, 69% and 80%, respectively; chi-square P < 0.001). The most frequent criteria were respiratory distress, SpO 2 < 90% on oxygen and systolic blood pressure < 90 mmHg. Of the patients suffering cardiac arrest elsewhere than on a ward (i.e. coronary care unit), 22% fulfilled MET criteria, but these patients received immediately intensive treatment. Twenty from 79 subjects out of the LMA-Classic group and 11 from 60 subjects out of the LMA-FastTrach group had an initial tidal volume < 150 ml. The measured tidal volume was 673.7 ± 133.1 ml for the LMA-Classic and 1057.7 ± 158.5 ml for the LMA-FastTrach. The mean time to correct placement was 55.5 ± 29.6 s for the LMA-Classic and 38.1 ± 24.9 s for the LMA-FastTrach. In the second evaluation, initial tidal volume < 150 ml was recorded in 14 out of 79 subjects for the LMA-Classic and in six out of 60 subjects for the LMA-FastTrach. The time to correct placement decreased significantly, with 22.9 ± 13.5 s for the LMA-Classic and 22.9 ± 19.0 s for the LMA-FastTrach. The measured tidal volume was 777.6 ± 367.9 ml for the LMA-Classic versus 1018.4 ± 50.7 ml for the LMA-FastTrach.  The respondents ranked their level of agreement in the manner presented in Table 1 . Age, level of education, income level, perceived health status, and end-of-life planning did not correlate with the responses. Married and widowed respondents, in contradistinction to others, believe that witnessed CPR would benefit the patient (P = 0.023). Respondents desiring CPR were more prone to believe that significant others should be allowed during CPR as opposed to those not desiring CPR (P = 0.005). They are more apt to want others present with them while undergoing CPR than those declining CPR (P = 0.002). They also felt more strongly that the presence of significant others during CPR would benefit the patient (P = 0.018) and family or friends Table 1 "I believe family members or friends have the right 36.5% (n = 149) strongly agree, 10.3% (n = 42) agree, 22.4% (n = 90) neither agree nor to be present in the room while a loved one is disagree, 98.8% (n = 37) disagree and 20.6% (n = 84) strongly disagree with this undergoing CPR" statement. Five respondents answered "I don't know" "I would want to be in the room with a loved one 37.3% (n = 152) strongly agree, 12.0% (n = 49) agree, 12.3% (n = 50) neither agree nor during CPR" disagree, 8.8% (n = 36) disagree, 28.2% (n = 115) strongly disagree with this statement, and 1.2% (n = 5) don't know "I would want family/friends with me if I were 29.9% (n = 122) strongly agree, 12.3% (n = 50) agree, 17.2% (n = 70) neither agree nor undergoing CPR" disagree, 8.6% (n = 35) disagree, 29.4% (n = 120) strongly disagree with this statement, and 2.5% (10) don't know "The presence of family/friends during CPR 24.3% (n = 99) strongly agree, 14.2% (n = 58) agree, 19.9% (n = 81) neither agree nor would benefit the patient" disagree, 13.75% (n = 56) disagree 22.3% (n = 91) strongly disagree with this statement, and 5.4% (n = 22) don't know "The presence of family/friends during CPR 23.8% (n = 97) strongly agree, 13.5% (n = 55) agree, 23.5% (n = 96) neither agree nor would benefit the family/friends" disagree, 12.5% (n = 51) disagree, 24.9% (n = 99) strongly disagree with this statement, and 2.2% (n = 9) don't know (P = 0.022). The desire be present in the room with a loved during CPR did not reach statistical significance (P = 0.078) between the two groups. Conclusion A large segment of the public desires witnessed CPR, and believes it to be beneficial. Age, level of education, income level, and end-of-life planning do not appear to influence these beliefs. Married and widowed respondents were more apt to consider witnessed resuscitation of benefit to the patient. People desiring CPR are more likely to have positive feeling about witnessed CPR. Those in poor health, not desiring CPR, are more pessimistic about witnessed resuscitation. Although healthcare providers have mixed sentiments, it would be wise to develop protocols to accommodate those who wish to remain together during CPR. Healthier individuals, married people and their families, and those widowed will be more demanding in this matter. The more infirm, not desirous of CPR, will be less demanding and less inclined to avail themselves of such formal programs.  Both groups differed significantly in the timing of important measures (Table 1) . The mean time to reach the target temperature was 4.5 hours (0-12 hours). MIH was maintained for a median 13 hours (4-26 hours). The rewarming period to 37°C took a median of 8.75 hours (3-21.5 hours). MIH treatment was followed by fever (> 37.9°C) in 23 patients (88%). Conclusions MIH by use of our external cooling protocol is feasible, simple and inexpensive. However, surface cooling is tardy, imprecise and in some patients unsuccessful. Background and goals Mild induced hypothermia (MIH) improves neurological recovery and survival after cardiac arrest for patients in whom the initial rhythm is ventricular fibrillation (VF) [1] . Other initial rhythms and cardiac arrest due to noncoronary causes may also benefit from such treatment [2] . There was no statistically significant linear correlation between TCD velocities and ICP and between the PI index and ICP. There was a significant correlation between Vmax and CPP and between Vmean and CPP. The best correlation found was between Vmin and CPP and between the PI index and CPP. Linear correlation and regression between TCD findings and ICP and CPP are presented in Table 1 . Conclusions TCD examination cannot be used as reliable noninvasive method to determine a concrete number of ICP. The PI index is more reliable than the TCD blood flow velocities to target therapeutic strategies in patients with severe head injury, but we must keep in mind that the PI estimates the changes of CPP over time and not an absolute value of CPP. Introduction Cerebral blood flow (CBF) is reduced around areas of contused brain after head injury [1] . However, since the cerebral metabolism is also reduced this may represent appropriate flowmetabolism coupling, rather than ischaemia. Matching of CBF to metabolism is quantified as the oxygen extraction fraction (OEF). We performed magnetic resonance imaging (MRI) and Oxygen 15 positron emission tomography (O-PET) to quantify CBF and OEF in regions of pericontusional oedema after head injury. Methods After local ethical approval, five patients with severe head injury underwent structural MRI and O-PET, in the first week after injury. The two studies were performed in immediate succession, with every effort made to maintain stable physiology. The fluid attenuation inversion recovery (FLAIR) MRI sequence provides cerebrospinal fluid-nulled, T 2 -weighted MRI images, on which oedema is hyperintense. The FLAIR images were coregistered and voxel resized to O-PET-derived maps of CBF and OEF, using a published methodology [2] . Each patient's coregistered FLAIR image was inspected for the largest and most apparent region of pericontusional oedema. These regions were then manually outlined and applied to PET maps, and CBF and OEF in these regions of oedema were calculated. Results were compared with unit reference data obtained from healthy volunteers [3] . Results Normal values of CBF and OEF obtained from volunteer datasets for mixed grey-white regions were 35 ± 5 ml/100 g/min and 45 ± 5%, respectively. While pericontusional regions showed a significantly lower CBF (20.5 ± 8.3 ml/100 g/min), we observed a wide range of values both across subjects and within individual lesions (14.7-35 and 5.1-52.3 ml/100 g/min, respectively). However, mean OEF values were low (35.4 ± 2.1%), with a much smaller range of values across patients (31.8-37.5%) and individual image voxels (24.9-41.8%). The 95% confidence intervals for the population mean pericontusional CBF and OEF were 10.2 and 30.8 ml/100 g/min and 32.8 and 38.1%, respectively. Of 102 children admitted to the unit during the period of the study, following a head injury, 59 had intracranial monitors placed within the first 24 hours. Nearly two-thirds (64.7%) were male and all 59 suffered sTBI with mean (SD) admitting Glasgow Coma Scores of 8 (3). The crude mortality rate was 10.2%. When comparing the mean ICP over the first 6 hours we found a significant difference between all three groups. The mean ICPs (SD) at 6 hours were as follows; Group 1, 10.61 mmHg (5.43); Group 2, 18.57 mmHg (7.34) and Group 3, 42.88 mmHg (23.64) The mean (95% confidence interval [CI]) ICP was 7.96 mmHg (CI 1.05-14.87) lower in Group 1 than Group 2 (P < 0.05), and 24.31 mmHg (CI 13.90-34.71) lower in Group 2 than Group 3 (P < 0.05). This difference between groups was maintained at 24 hours. Mean ICPs (SD) at 24 hours; Group 1, 12.61 mmHg (5.12); Group 2, 20.35 mmHg (5.07) and Group 3, 44.69 mmHg (25.70). The mean (95% CI) ICP was 7.74 mmHg (CI 1.3-33.16) lower in Group 1 than in Group 2 (P < 0.05), and 24.34 mmHg (CI 14.31-34.35) lower in Group 2 than Group 3 (P < 0.05) at this time. There was also a significant difference in the CPP between Groups 1 and 3, and Groups 2 and 3 at both 6 and 24 hours, although no significant difference was detected between Groups 1 and 2. Thirty-five NICU patients (age 48.9 ± 19.5 years, male 64%, median Glasgow Coma Scale motor 5) (traumatic brain injury 63%, aneurismal subarachnoid hemorrhage 20%, postoperative 17%) were studied. Infection was clinically suspected in all patients and in 54% of them its was confirmed by microbiological data. We analysed a total of 177 SC doses at a mean 185 ± 89 hours after ICU admission with a median of five administrations per patient. The mean dose was 13.7 ± 6 mg (0.17 ± 0.04 mg/kg). T° decreased significantly after DCF SC, from 38.4 ± 0.4 to 37.6 ± 0.5°C (P < 0.0001), as did the ICP, from 16 ± 8 to 12.8 ± 6 mmHg (P = 0.0002). PaCO 2 and SjvO 2 were not different pre and post DCF. The CPP was stable after DCF (pre, 71 ± 15 mmHg; post, 69 ± 15 mmHg [NS]). The HR significantly dropped (from 97 ± 21 to 89 ± 20 beats/min, P < 0.0001). Blood gas analysis, renal and hepatic parameters were not different after DCF SC. Diuresis was maintained and it did not decrease much (from 175 ± 97 to142 ± 102 ml/hour, P < 0.05). The effects of DCF on T° and ICP are shown in Fig. 1 . The effects of DCF on MAP, CPP and hourly urine output are shown in Fig. 2 . The infarct volume was larger in the placebo group than in the enoxaparin, tirofiban and enoxaparin/tirofiban groups. The neuroscore at 24 and 48 hours was higher for the group receiving both drugs simultaneously. No ICH was present in any of the groups (Table 1) . Conclusion It is probable that besides the anticoagulant and antiaggregant effects of enoxaparin and tirofiban, other intrinsic effects of each drug have an impact on the infarct's volume. Combining both drugs resulted in a synergic effect, probably due to prevention of reperfusion damage. A slight improvement of the short-term clinical outcome could be seen with the drugs, meaning that with less tissue damage, better long-term clinical improvement is expected. In this trial, none of the drugs increased the risk of ICH. Further investigation must be done to define the right therapeutic window of opportunity for both of these agents. Introduction Intractable status epilepticus not responding to conventional pharmacotherapy is a medical emergency. Deeper suppression of cortical activity, documented electrocerebral silence and titrable length of time during which such electrocerebral silence can be maintained all make thiopentone the ideal drug for initial management of status epilepticus [1, 2] . A longlasting anti-epileptic drug regimen can be established during thiopentone-induced burst suppression, which can then be tapered and discontinued with minimal chances of recurrence. Methods Twenty-one pediatric patients suffering from idiopathic generalized tonic clonic disorder with age of onset of 12 months-2 years were included in the study. All patients were admitted to the pediatric ICU after initial management in the emergency room. Rapid sequence intubation with cricoid pressure was done with an induction dose of 4 mg/kg thiopentone intravenously (IV) and 1.5 mg/kg succinylcholine IV. Additional boluses of 4 mg/kg thiopentone were administered at 5-30 min intervals until complete areflexia was achieved, while a continuous intravenous thiopentone infusion (0.5-4 mg/kg/hour) was maintained and titrated to obtain electroencephalogram (EEG) burst suppression. Continuous single channel processed EEGs using a cerebral function analyzing monitor and an intermittent multichannel electroencephalogram (EEG) were done. After control of clinical and electroencephalographic seizure activity, patients were started on phenytoin and phenobarbitone. Thiopentone infusion was progressively tapered over 24 hours and finally discontinued once therapeutic serum levels were achieved for these anti-epileptic medications. Statistical values were obtained from 2 × 2 tables of outcome versus EEG suppression employing Fisher's exact test with significance quantified as P < 0.05. Out of the 21 patients, 16 showed burst suppression and five showed a 'flat' record. Two patients in the burst suppression category showed recurrence of seizure activity after being controlled initially, and none in the flat one. In these two patients, EEG seizures recurred earlier than clinical seizures, which were rapidly controlled with increasing the rate of thiopentone infusion. More sustained control of seizure activity was achieved by adding valproic acid to the anti-epileptic regimen in these two patients. The patients were predominantly (92%) Caucasians; 54% were male. The first and third ICU day mean APSs were 106.8 and 70.5, respectively, and predicted mortality rates were 87.8% and 86.5%, respectively. The observed hospital mortality rate was 61.3%. There was an increase in APS on the third ICU day, compared with the first ICU day, in 34 patients (11.3%). Only two of the 34 patients (6%) with increased APS survived to hospital discharge, compared with 115 of 268 (43%) without increase (P < 0.0001). Of the two patients who survived to hospital discharge, one died within 24 hours of discharge and the second one, who was admitted to the ICU for multiple trauma, died 3 years after hospital discharge. Conclusion An increase in the APS on the third ICU day of the sickest patients identifies a group of patients whose short-term and long-term prognoses are dismal. Introduction Base excess (BE) and lactate (LAC) have been used to monitor ICU patients. Each results from different pathophysiological derangements in perfusion, inflammation and renal function. The individual significance of BE or LAC to predict the outcome of the critically ill patients is still uncertain and was the focus of this retrospective study. The age was 51 ± 18 years, APACHE II was 21 ± 1, BE and LAC at admission were -6.0 ± 7.6 mmol/l and 4.9 ± 9.7 mmol/l, respectively, and the BE and LAC after 24 hours were -5.5 ± 6.2 mmol/l and 5 ± 9.6 mmol/l, respectively. The variations of BE and LAC were calculated as the 24 hours value minus the admission value, and resulted in 0.4 ± 6.6 and 0.03 ± 5.6 mmol/l, respectively. Conclusions Lower values of BE and higher values of LAC are associated with poor prognosis in ICU patients. In a comparative analysis of these two variables, BE measured after 24 hours of admission has the best discriminatory power to predict outcome. . We aimed to assess temporal changes in performance of both of these scores. Specifically, we hypothesised that the 6-year period between commencement of data collection (1998) and publication (2003) of the revised PIM 2 score may have allowed for significant decalibration. Methods A prospective data collection from a single, 20-bed tertiary PICU over 5 years (1999) (2000) (2001) (2002) (2003) . The standardised mortality ratio (SMR) was calculated using the standard formula, discrimination assessed via the area under the receiver-operating characteristic curve (ROC), and calibration using the Hosmer-Lemeshow goodness of fit test. Scores were calculated for 4183 patient episodes (average 800-900 admissions/year). There was no significant temporal variation in either case mix (cardiac surgery 27-31%) or disease severity (data not shown). Both scores discriminated well, consistently yielding an area under the ROC curve > 0.75 (Fig. 1  top) . Not surprisingly, PIM demonstrated a loss of calibration (Hosmer-Lemeshow χ 2 > 15.5, P > 0.05) from 2000 onwards. PIM 2 also showed a temporal trend towards decalibration that became apparent by 2003. This trend was mirrored by a progressive reduction in SMR ( Fig. 1 bottom) , such that the upper confidence limit for the PIM 2 SMR was less than 1.00 by 2002. Interestingly, the SMR derived from either score decreased at a similar rate, 0.07-0.08 per year. Conclusions Both scores continue to discriminate well between survival and nonsurvival. As expected, PIM 2 is better calibrated than PIM, although both appear to be decalibrating at a similar rate. Because PIM 2 reflects the 1998-1999 standard of care, many PICUs will currently exhibit fewer deaths than expected (SMR < 1.00). More frequent calibration appears necessary. A prolonged ICU length of stay (LOS) has been associated with many medical diagnoses and conditions but it is difficult to predict on admission to the ICU. Prolonged ICU LOS can adversely affect patient outcomes by increasing the risk of complications, and possibly mortality. Identification of such indicators may help to improve ICU resource utilization (e.g. bed triage, ICU staffing). Objective To systematically review the literature to determine common 'early' predictors of ICU LOS for adult patients. Results Five studies were identified that were published in full, with a combined total of 16,107 patients. The definition of prolonged LOS varied with the population evaluated (e.g. > 14 days general ICU, > 5 days CVICU) and thus prevented metaanalyses. Approximately 10% of patients had prolonged LOS as defined by the study. Universal positive early indicators were: emergent surgery or admission, trauma, or need for mechanical ventilation in < 24 hours. Abbreviated LOS was associated with coma, DNR orders, and nontrauma surgical reasons for admission. APACHE created as a predictive model for mortality consistently did not predict LOS. The overall mortality was 33%. Immunocompromised patients had a significantly higher mortality than immunocompetent patients (45% vs 29%, P < 0.001). This difference was even more pronounced if patients required MV (64% vs 34%, P < 0.001). Patients with neutropenia tended to have a higher mortality than patients with IS therapy, but this difference failed to show statistical significance. The presence of septic shock at any time during ICU treatment and the associated mortality from septic shock did not significantly differ between immunocompromised and immunocompetent patients. In multivariate analysis, lower APACHE III scores at admission and admission for postoperative care were independently associated with reduced ICU mortality, whereas immunosuppression and MV were independently associated with unfavourable outcome. Immunosuppression remained to be associated with higher ICU mortality if the statistical model was adjusted for APACHE III score, postoperative care and mechanical ventilation. Conclusion Immunosuppression is an independent risk factor of death in the ICU. In order to develop preventive strategies, controlled studies are needed to identify further risk factors in these patients. This study aims to compare the ability of admission lactate, lactate at 24 hours and the APACHE II risk of death (ROD) score to discriminate between intensive care survivors and nonsurvivors. We also combined lactate at 24 hours with the APACHE ROD score to obtain the best discrimination values. Two hundred and forty consecutive admissions to a nine-bed general intensive care unit (ITU) were prospectively investigated. Lactate values at admission and lactate at 24 hours were recorded. Each patient had the APACHE II ROD score calculated from data submitted to the Intensive Care National Audit and Research Centre. The ITU and hospital mortalities were analysed. The area under the receiver-operator characteristic (ROC) curve was calculated for each measure or combination of measures to test discrimination between survivors and nonsurvivors. The overall intensive care and hospital mortalities were 29% and 39%, respectively. Both lactate on admission and lactate at 24 hours were significantly and strongly associated with intensive care mortality (P = 0.000 for both). Areas under the ROC curves show that both lactate measures discriminated between survivors and nonsurvivors ( Table 1 ). The best discrimination is obtained by a combination of lactate at 24 hours and APACHE probability (obtained from a logistic regression). The 24 hour lactate values that give 50-75% mortalities are 1.5 and 3.6, respectively. Lactate at admission and at 24 hours are significantly strongly associated with intensive care mortality. Seventy-five per cent of patients with a lactate value of 3.6 at 24 hours will not survive. The results are presented in Table 1 . Of the 8.2 million hospital discharges, 62,968 (0.8%) had SA and 9742 had severe SA, of whom 4007 (41.1%) were working-age adults (population incidence of 10.7/100,000). Compared with commercially insured patients (n = 2299), Medicaid (n = 1057) and uninsured (n = 651) patients had higher MV rates (30.1% vs 39.1% and 40.1%, P < 0.001) Hospital length of stay (LOS), ICU LOS, mortality and mean costs were 6.2, 8.6 and 5.1 days, 3.5, 4.4 and 2.6 days, 1.9, 4.2 and 1.8% and $8800, $12,600, & $7400, respectively, for commercial, Medicaid and uninsured patients. Adjusting for age, comorbidity, gender, and race, Medicaid and uninsured patients were more likely to receive MV than commercially insured patients (odds ratio:1.51 and 1.41, P < 0.001 for each). Mortality was also higher, but this observation was not significant (odds ratio: 1.17, P = 0.9 and odds ratio: 2.1, P = 0.64). Uninsured patients also incurred lower adjusted hospital costs (P < 0.001) and hospital LOS (P < 0.001). Of 3926 patient visits eligible for the study, 3763 (96%) were included. The overall 1-year mortality was 24% (95% CI: 22.7-25.4%) (904/3763). The 1-year mortalities for the groups were: very low risk 8.6% (0.08-1.2%), low 23% (1.0-3.5%), moderate 40% (5.8-10%), high 68% (11-24%), and very high 79% (37-66%), with all groups being statistically different from each other by Tukey's Test for pair-wise comparisons. The demographic data were similar among groups. The Beck depression scores of the nurses in the university hospital (16.6 ± 9) were higher than that in the state hospitals (13.1 ± 8) (P = 0.028). The Beck depression scores of the mixed ICU nurses in the university hospital (19.8 ± 8) were higher then that in the non-ICU nurses (12.8 ± 7.6) (P = 0.001). Depersonalisation scores of surgical ICU nurses in the university hospital (7.8 ± 4) were higher than those in the non-ICU nurses (5.6 ± 3.6) (P = 0.03). Although a significant difference was not found among the nurses working in different ICUs in terms of the Beck depression inventory, mixed ICU nurses had considerable depression (mixed ICU 17.4 ± 8, surgical ICU 13.6 ± 9, internal medicine ICU 13.5 ± 8 or non-ICU group 12.8 ± 7.6) when considering all ICU nurses together. Positive correlation was found in all groups between the Beck depression score and emotional exhaustion except in the control group (P < 0.01, r >v0.52). Conclusion Nurses operating in the ICU, especially in the mixed ICU, may have a tendency to depression. All ICU staff should be Patients and methods From June 1997 to December 1999 all admissions (≥ 18 years) to our medical intensive care unit (ICU) who were treated for at least 24 hours were eligible. On admission, the pre-ICU functional status and subjective well-being were assessed by interview [1] . Six months after admission survivors' memory of the ICU stay was assessed (none, positive, negative). At 18-month follow-up a standardized interview at the patients home was performed using the PTSD-10 Questions Inventory (PTSD-10) [2] , the 90-item Revised Symptom Checklist (SCL-90-R), the Hamilton Anxiety Scale and Hamilton Depression Scale, the 57-item Giessen Subjective Complaints List and a 28-item quality of life (QOL) scale. A total of 444 patients were enrolled. Cumulative mortality rates were 23% in the ICU, 33% in the hospital, 42% at 6-month follow-up and 53% at 18-month follow-up. From the 209 survivors, 22% were lost to follow-up, 27% were unable to be interviewed due to physical or cognitive reasons and 13% declined the interview. The remaining 80 study patients had a mean age of 46 ± 12 (± SD) years; 69% were male, the mean ICU length of stay was 12 ± 17 days, the mean APACHE II score after 24 hours was 19 ± 9 and the mean SOFA total maximum score was 6.3 ± 4.7. According to PTSD-10 criteria 10 patients (12.5%) had a diagnosis of PTSD. PTSD was more frequently diagnosed in patients who had reported poor pre-ICU subjective well-being compared with patients with good subjective well-being (8/41 vs 2/39 patients; 20% vs 5%; P = 0.05), in patients with multiple organ dysfunction (MOD) compared with patients without MOD (8/38 vs 2/42 patients; 21% vs 5%; P = 0.03), and in patients who had negative or no memories of their ICU stay compared with patients with positive memories (7/30 vs 3/50 patients; 23% vs 6%; P = 0.02). Patients with PTSD had significantly (P < 0.0001) worse scores on the SCL-90-R global index of psychopathology showed a significantly (P < 0.0001) higher degree of somatic and psychic anxiety, major depression, bodily complaints and mental exhaustion, and reported poorer self-perceived QOL. Conclusion A small subgroup (12.5%) of our medical ICU survivors developed PTSD. Subjective well-being before ICU admission, MOD, and ICU memories were associated with PTSD and related psychopathologic symptomatology. These criteria could be used to identify survivors at risk for developing PTSD. Background Cost considerations may influence therapeutic reasoning and decisions in the intensive care unit (ICU). To date only very few data illuminating the association of costs and consequences (i.e. outcomes) of critical care services are available. In this study, the long-term outcome, health-related quality of life (HRQL), and ICU and hospital costs of medical ICU patients were assessed. per life year saved, respectively. The mean costs per QUALY were €3101. Increasing severity of illness (SAPS II quartiles) was associated with higher ECPS and costs per QUALY (Table 1) . Between March 1997 and March 2001, a total of 1285 patients were admitted to the ICU, from which 697 were included in the study. From these, 305(44%) were admitted for severe sepsis/septic shock. Mortality in the sepsis group was 34% and in the control group was 26%. One hundred and four patients from the sepsis group and 133 patients from the control group completed the QOL-SP questionnaire. There were no differences in age and previous health state between both groups. Patients from the sepsis group exhibit a significantly higher APACHE II score and a significantly higher ICU stay. Sepsis survivors reported significantly less problems in the BPA and NDA subscales; furthermore, although not statistically significant, they exhibit a better QOL-SP index than the control group (Table 1) . Conclusion At 6 months after ICU discharge, when evaluated with a specific critical care questionnaire, survivors of severe sepsis/septic shock exhibited a similar, if not a better, HR-QOL than ICU survivors without sepsis.  