The survival and production of cytokines are shown in Table  1 . Histopathological findings in group III were obviously attenuated. Introduction Lethal sepsis occurs if an excessive inflammatory response evolves that cannot be controlled by physiological anti-inflammatory mechanisms. Vagus nerve stimulation showed improved survival in sepsis; however, this seems not to be feasible in septic patients. We therefore investigated the effect of activation of the cholinergic anti-inflammatory pathway by pharmacologic cholinesterase inhibition on survival and inflammation in a septic mouse model. Methods To investigate the therapeutic effect of nicotine and physostigmine we performed cecal ligation and puncture (CLP) in female C57/B6 mice (each group n = 21). Substances were administered by intraperitoneal injection. Control groups received the same volume (50-180 µl) of LPS-free 0.9% NaCl (solvent). CLP was performed blinded to the identity of the treatment group. In addition to survival experiments we performed measurements of cytokines in plasma and the electrophoretic mobility shift assay (EMSA) for NF-κB in peritoneal skin, liver and kidneys. Results (1) Animals treated with nicotine (400 µg/kg) or physostigmine (80 µg/kg) survived significantly better than control mice (P < 0.05). There was no difference between the treatment groups. (2) Dose escalation of physostigmine was not superior to the normal dose. Survival in the high-dose group, however, was still significantly better than in the control group. (3) Proinflammatory cytokine levels of TNFα, IL-6 and IL-1β were significantly reduced in animals treated with physostigmine (P < 0.01). (4) Cholinesterase inhibition with physostigmine in CLP reduced NF-κB activation in the peritoneum, kidney and liver compared with the control and sham-operated group (P < 0.01). Conclusion We show that pharmacological cholinesterase inhibition with physostigmine improves survival in experimental sepsis, most probably by activation of the cholinergic anti-inflammatory pathway. One possible mechanism is modulation of the NF-κB pathway. Therefore, cholinesterase inhibition may have important implications for treatment of sepsis. Introduction High-mobility-group box protein 1 (HMGB1) is a highly conserved, ubiquitous protein present in the nuclei and cytoplasm of nearly all cell types and, secreted into the extracellular milieu, acts as a proinflammatory cytokine. The function of HMGB1 has been widely studied for sepsis and inflammation. HMGB1 was reported as a late mediator in endotoxic shock and was known as an abundant protein present in nuclei and cytoplasm and involved in maintaining nucleosome structure and regulation of gene transcription. Moreover, elevated, circulating levels of HMGB1 also have been described in a case of human hemorrhagic shock due to abdominal aortic aneurysm without evidence of infection. However, the relationship between HMGB1 and trauma has not been studied except for the report of a rat model of burn. The mean IL-12, fT3, fT4 and TSH values of septic patients and the control group are presented in Table 1 . IL-12 was significantly higher in septic patients (19.05 ± 10.7 pg/ml vs 4.8 ± 2.0 pg/ml, P < 0.005). fT3 and TSH values were significantly low in septic patients. There was a significantly strong correlation between IL-12 and fT4 in septic patients but not fT3 and TSH (r = 0.88, P = 000). There was no correlation between IL-12 and other thyroid indices in the control group. S17 center directly after admission into the network hospitals. The final step was the presentation of the project in the different hospitals. Results We treated 10 children with Waterhouse-Friderichsen syndrome in the network. Three of them were attended on site and seven were transferred in the tertiary center. The announcement time in eight cases was 15 minutes-1 hour. Primarily, a consultation was accomplishing routinely. The transportation team of the tertiary center continued the treatment on site and afterwards in the center. All patients showed typical signs of Waterhouse-Friderichsen syndrome with purpura fulminans and severe multiorgan failure. No patient died and only one patient had necrosis of the skin, which existed already at admission. The others had a restitution ad integrum. No adverse effects were observed with the PC concentrate administration. Conclusions The network system and the standard treatment with PC worked without severe problems. The survival rate and the outcome in our small study group were excellent. Our experience allows us to enlarge the system on other diseases. Introduction Neonates and infants in the ICU are at high risk of severe infections and sepsis. Often it is not easy to diagnose sepsis based only on clinical findings; reliable biomarkers are needed to prove the diagnosis. Objective To study the value of procalcitonin (PCT) as a marker, verifying the diagnosis, which enables the start of de-escalating ABT in patients with clinical signs of sepsis. Methods Three hundred and seventy-four patients on artificial lung ventilation from two pediatric ICUs of two Russian hospitals were enrolled. Blood samples for PCT testing (PCT LIA; BRAHMS AG, Germany) were taken under suspicion of sepsis or exacerbation of bacterial infection. In the first stage (January-December 2005), 50 neonates (age 6 (4-12) days) with various perinatal pathologies were studied (Group A), and routine ABT was prescribed, with blood samples taken and stored for further PCT assessment. In the second stage (January-November 2006), 324 infants (age 6 (1.5-9.4) months) after cardiac surgery were enrolled (Group B), and ABT was adjusted based on PCT-testing results. PCT > 2 ng/ml indicative of systemic bacterial inflammation in addition to clinical signs of sepsis was an indication for ABT with carbapenems. Data are shown as the median and interquartile range. Results Group A. Sepsis was diagnosed in 16/50 (32%) patients. PCT > 2 ng/ml was observed in 23/50 (46%) cases, including 15/16 (94%) patients with clinically diagnosed sepsis. In patients with PCT > 2 ng/ml the mortality rate was 7.7% if carbapenems (meropenem or imipenem/cilastatin) were administered (n = 13), compared with 20% with different ABT (n = 10) -although in patients with PCT < 2 ng/ml (n = 27), ABT with carbapenems (n = 12) resulted in paradoxically higher mortality compared with other ABT schemes (n = 15): 17% vs 6.6%. Group B. Sepsis was defined in 24/324 (7.4%) patients. PCT > 2 ng/ml was in 53/324 (16%) cases, including all patients with clinically diagnosed sepsis. Early ABT with meropenem, combined with vancomycin or linezolid, allowed one to decrease sepsis-related mortality in these patients to 29%, which used to be as high as 74% before the introduction of this algorithm (P = 0.0028). Conclusion Early verification of sepsis using PCT combined with carbapenems-based ABT enables decreasing sepsis-related mortality in critically ill infants and newborns staying in the ICU. Available online http://ccforum.com/supplements/11/S2 Introduction The aim of this study was to investigate the prevalence of endotoxemia early after elective surgical procedures in patients admitted to an ICU of a university hospital. Methods One hundred and four nonselect patients were recruited. Patients were excluded if they were admitted during the weekend or from another ICU and if they were on chronic dialysis. Within 4 hours of admission functional data were collected and severity scores (APACHE, SOFA) calculated. Arterial blood samples were also taken and processed according to Spectral Diagnostics' endotoxin activity (EA) assay [1] . The method allows one to express EA as a function of each patient's neutrophil chemiluminescence activity (on a scale from 0 to 1). An EA level of 0.4 is approximately equivalent to an endotoxin concentration of 25-50 pg/ml, and a level of 0.6 is approximately equivalent to a LPS concentration of 100-200 pg/ml. Data were analysed according to EA ranges: low (EA < 0.4), intermediate (0.4 ≤ EA < 0.6), and high (EA ≥ 0.6). Differences between ranges of EA were assessed by analysis of variance (Sigma Stat, SPSS), accepting P < 0.05 as significant. Data are expressed as the mean ± SD. Results In our case mix, patients were 68 (65%) in the low group, 17 (17%) in the intermediate group and 19 (18%) in the high group. Age (61 ± 17 years) was not significantly different in the three groups (P = 0.493). Functional and severity scores were not significantly different between groups. Average values were as follows: WBC 11,093 ± 4605 n/mm 3 (P = 0.385), HR 76 ± 16 bpm (P = 0.898), MAP 88.8 ± 13.6 mmHg (P = 0.576), lactate 1.18 ± 0.77 mmol/l (P = 0.370), PaO 2 /FiO 2 383 ± 109 mmHg (P = 0.474), APACHE II score 8.3 ± 3.7 (P = 0.542) and SOFA score 1.5 ± 1.4 (P = 0.245). Interestingly, those patients with higher levels of EA were characterized by longer length of stay in the ICU. The ICU length of stay was 1.9 ± 3.1 days in the low group, 8.7 ± 6.7 days in the intermediate group and 4.7 ± 7.7 days in the high group (P = 0.038). Conclusions A rather high number of patients admitted to the ICU following elective surgery are characterized by intermediate-high levels of endotoxemia, as assessed by the EA assay, despite their relative low level of complexity on admission. High levels of EA were associated with a longer length of stay. Objectives To evaluate in septic patients the plasma levels of sTREM-1, a soluble form of TREM-1, which seems to play an important role in inflammatory diseases, and to determine whether plasma sTREM-1 could be used as a diagnostic and prognostic marker in sepsis in the surgical ICU. Design An observational clinical study. Setting The surgical ICU of the University Hospital of Heidelberg, Germany. Patients Patients admitted to the ICU over a 6-month period with clinical evidence of severe sepsis or septic shock. Interventions None. The point that marked the onset of sepsis was when each of the physiologic parameters met the current evidence-based screening criteria (HR > 90, RR > 20, MAP < 65, temperature >38°C). Results of this study found statistically significant differences between the standard screen and horizons screen participant groups in the speed in which clinicians were able to reach each measured outcome. This was true in each of the five outcome measurements: onset of sepsis (P < 0.001), initiation of fluid bolus (P < 0.001), initiation of vasopressor (P < 0.001), blood culture order (P = 0.012), and antibiotic administration (P = 0.020 Background Direct microbiological input to critical care is essential for the management of the septic patient. Early broadspectrum antimicrobial therapy with appropriate diagnostic studies to ascertain causative organisms is well established; there should be reassessment with the aim of using narrow-spectrum antibiotics to prevent the development of antimicrobial resistance, to reduce toxicity and to reduce costs [1] . In systematic analysis of ward rounds in ICUs the information most commonly missing from a patient's file concerned microbiology findings [2] . . When asked to rate the value of this ward round, the mean score was 8.6 out of a possible 10 (range 10-5, mode 9). In those units without a microbiology ward round the desirability of such a service was scored on average at 8.5 out of 10 (range 10-3, mode 9). Conclusion Direct microbiological advice at the bedside is highly valued by ICU consultants. Antibiotic prescribing is generally well controlled, with two-thirds of units having an agreed antibiotic policy in place. Work will continue to determine whether these results reflect the national picture in the United Kingdom.  The patient group consisted of 17 males and 10 females, 59.6 ± 12.7 years old. The average APACHE II score was 27.2 ± 9.1, and the average SOFA score was 11.7 ± 5.2 before DHP-PMX. Nineteen patients survived and eight died. When the changes in PAI-1, protein C, ATIII, IL-6 and high mobility group box protein 1 (HMGB-1) were compared between the groups, only the HMGB-1 levels had improved significantly in the SBP increased group (P = 0.0125). The SBP increased significantly after DHP-PMX in the HMGB-1-improved group (P < 0.0001). An improvement in the P/F ratio and a reduction in 2-arachidonoyl glycerol during DHP-PMX were significantly correlated (P = 0.0184). Conclusion We showed that the circulation dynamics of septic shock patients can be improved by reducing HMGB-1 levels and that respiratory function can be improved by reducing 2arachidonoyl glycerol levels using DHP-PMX. The mean age of the study population was 54.7 ± 19.0 years. Inhospital mortality was 36.2%. Hyperglycemia (≥175 mg/dl and ≥200 mg/dl) was observed more often among the nonsurvivors. Over the seven study days, no differences were found in daily morning blood glucose levels between survivors (n = 83) and nonsurvivors (n = 47) (all P > 0.05). Although in the nonsurvivors the evolution of glycemia tended to be higher, this trend was not statistically significant compared with the survivors. Multivariate logistic regression revealed that age (P = 0.022), APACHE II score (P = 0.003), antibiotic resistance (P = 0.001), and hyperglycemia (≥200 mg/dl) upon onset of BSI (P = 0.001) were independently associated with inhospital mortality, whereas appropriate antimicrobial therapy ≤24 hours (P = 0.016) and previous history of diabetes (P = 0.022) were associated with better outcome. Conclusion Trends of blood glucose levels were higher among nonsurvivors. Hyperglycemia (≥200 mg/dl) upon onset of nosocomial BSI adversely affects outcome in a heterogeneous ICU population. The automated blood sampling system performed its operation in all volunteers over the whole trial period. The median Pearson coefficient of correlation between manual and automated withdrawn blood was 0.983 (0.862-0.995). Furthermore, the results (173 data pairs) were analysed via the recently published 'Insulin Titration Error Grid Analysis' and 99.4% were suggesting an acceptable treatment. The results of the traditional 'Error Grid Analysis' showed that 96% of the data were in zone A and 4% in zone B. Conclusion The automated discontinuous blood withdrawing system provides reproducible blood samples from peripheral venous blood. In combination with a glucose sensor and an algorithm it might be used in future as a closed loop system for insulin and glucose infusion at the ICU. Introduction It has been proposed that intensive insulin therapy (IIT) aiming for a blood glucose (BG) of 4.4-6.1 mmol/l reduces mortality in critically ill patients when compared with conventional insulin therapy (CIT) targeting BG at 10.0-11.1 mmol/l. Difficulties with IIT include inadvertent hypoglycaemia and low efficacy at achieving the target BG. We proposed that computerised decision support may mitigate these problems. Objective To comprehensively describe BG and outcome from decision-supported IIT. Methods A clinical information system at each bedspace guided staff through the IIT algorithm. The time spent within glucose ranges was calculated assuming a linear trend between successive measurements. Results Patient characteristics are shown in Table 1 . The IIT group had more frequent BG evaluation (7,007 over 8,944 patient-hours, 0.78 tests/hour) than the CIT group (3,609 over 8,617 hours, 0.42 tests/hour). The median (interquartile range (IQR)) proportion of time spent in the target range 4.4-6.1 mmol/l was similar in the IIT and CIT groups (23.21% (15.4-29.8) vs 17.9% (9.8-29.3), respectively; P = 0.17). Similarly, time spent with a BG between 6.2 and 7.99 mmol/l was no different for the two groups (48.5% (IQR 36.9-59.3) for IIT and 43.9% (IQR 34.7-60.9), P = 0.72). In the IIT and CIT groups, five and six patients experienced a BG below 2.2 mmol/l, respectively. Discussion Computerised decision-support and more intensive monitoring did not improve BG control or reduce the incidence of hypoglycaemia. Introduction The objective of this study was to determine the efficacy and safety of subcutaneous (s.c.) once-daily (OD) glargine insulin, a long-acting insulin, in comparison with a s.c. regular insulin, based on a protocolized sliding scale regimen for achieving glycemic control in patients admitted to the ICU. Methods One hundred patients admitted to the ICU with an admission capillary blood glucose (CBG) >150 mg/dl (8.3 mmol/l) were involved in this prospective, randomized study. Patients with age <18 years, pregnancy, shock, requiring continuous intravenous insulin infusion, renal failure were excluded. Patients were randomly assigned to receive either s.c. glargine insulin 10 U (CBG ≤ 9.9 mmol/l) or 18 U (CBG ≥ 10.1 mmol/l) s.c. OD (Group G, n = 50), or s.c. regular insulin based on a 6-hourly sliding scale (Group R, n = 50). CBGs were recorded at 6-hour intervals up to 96 hours or until ICU discharge, whichever was earlier. The target CBG in both groups was <150 mg/dl (8.3 mmol/l). Patients in group G received rescue doses of regular insulin, as required. Demographic characteristics, mean and median CBG, and episodes of hypoglycemia were studied. Results Demographic profiles were comparable between the two groups. There was no significant difference in mean CBG in both groups (Group G 152.1 mg/dl (8.4 mmol/l), Group R 149.9 mg/dl (8.3 mmol/l), P = 0.66). Median CBGs were comparable at 6hourly time points in both the groups except at 0 and 6 hours in the glargine arm (CBG at 0 and 6 hours, Group G 10.0 mmol/l and Median capillary blood glucose (CBG) at different time points. S53 9.9 mmol/l, Group R 9.4 mmol/l and 8.3 mmol/l, P = 0.04 and 0.02, respectively) ( Figure 1 ). There were three episodes of hypoglycemia in Group G and one in Group R, which were corrected. Conclusion OD s.c. glargine insulin is a safe and effective alternative to regular insulin for glycemic control in critically ill patients. Since insulin sensitivity showed enormous variability, glycaemic control required a high nursing effort. Impeding aspects to titrate blood glucose into the target range were the absence of a nutritional protocol (high carbohydrate intake, despite inflammation/infection leading to hyperglycaemia that was difficult to S55 control) and fear of hypoglycaemia (<60 mg%) leading to low-dose insulin with consecutive hyperglycaemia. Lack of communication (and therefore a loss of information) between critical care nurses and the intensivists and poor acceptance from physicians to leave this field of intensive care medicine to the nurses were additional factors that slowed the implementation process. Conclusion Implementation of protocol-driven medicine requires a high quality of information flow. The lack of linearity between blood glucose and insulin dose (variability of insulin sensitivity) required a sometimes intuitive (experienced) decision to titrate the insulin dose. The conflict of physicians with this new role of critical care nurses might be due to the lack of understanding of the evolution of the nursing profession. Introduction Tight blood glucose (BG) control has been shown to decrease morbidity and mortality in patients in the surgical ICU [1] but is difficult to achieve using standard insulin infusion protocols. We previously evaluated a software model predictive control (MPC) insulin administration algorithm in postcardiac surgery patients [2] . This study investigated the use of an enhanced MPC algorithm (eMPC) in more severely ill patients over 72 hours. Methods Fourteen (seven male) critically ill ventilated medical and surgical patients, mean age 65 years, with an arterial BG > 6.7 mmol/l within 24 hours of ICU admission (RBH) or already receiving insulin infusion, and expected to require mechanical ventilation for more than 72 hours, were treated either with BG control by the standard ICU insulin intravenous infusion protocol [2] or eMPC-advised insulin infusion (n = 6) for 72 hours. The eMPC algorithm, installed on a bedside computer, requires input of current insulin requirements, bodyweight, carbohydrate intake and BG concentration. The algorithm advises the time to next BG sample (up to 4 hours) and the insulin infusion rate, targeted to maintain BG at 4.4-6.1 mmol/l. Patients in the eMPC group had BG measured hourly (for safety) but values were only entered if requested by the algorithm. The mean (SD) glucose concentration was significantly lower in the eMPC group (6.0 (0.34) vs 7.1 (0.54) mmol/l, P < 0.001). The mean insulin infusion rate was not significantly different (4.1 (2.7) vs 3.1 (1.8) IU/hour, eMPC vs standard care). BG sampling occurred more frequently in the eMPC group, with a mean of every 1.1 vs 1.9 hours (P < 0.05). No patients in either group had any BG measurements <2.2 mmol/l. Conclusion The eMPC algorithm was effective in maintaining tight BG control in this more severely ill patient group without any episodes of hypoglycaemia (BG < 2.2 mmol/l), but required more frequent BG measurement. Acknowledgements This study is part of the CLINICIP project funded by the EC (6th Framework). The University of Cambridge also received support from EPSRC (GR/S14344/01 Table 1 ). A single BG measurement < 2.2 mM was detected in the MPC group vs 0 in the control group. The sampling frequency was significantly higher in the MPC group. Introduction Evidence is accumulating that tight glucose control improves outcome in critically ill patients. This study was performed to evaluate the effect of lower blood glucose levels in critically ill patients on outcome. We had a 50% response rate to our questionnaire. An overall dysphagia post ICU stay rate of 19.5% was observed. Fever and age over 65 were both common findings as one may expect and showed the highest association with subsequent dysphagia. We did not find any suggestion of a relationship between changing tracheostomy (suggesting repeat procedures) and subsequent difficulty swallowing. One patient within this group subsequently developed a tracheal stenosis. See Table 1 . Conclusion We found the percentage of patients reporting swallowing difficulties post percutaneous tracheostomy (PCT) (Portex Blue Line Ultra tracheostomy tube) to be higher than one would expect. This may be confounded by neurological injury necessitating the need for a PCT, but we feel this may be an area of concern meriting further investigation given frequent PCT in ICU practice. The Se plasma level was significantly higher in high-dose Se-substituted patients (0.56 µmol/l vs 0.88 µmol/l, P < 0.001). GSHPx was significantly higher in high-dose Se-substituted patients (4,864 U/l vs 6,097 U/l, P < 0.001). No significant differences were found in the level of albumin, prealbumin, CRP, PCT, leucocytes, fibrinogen, cholesterol, D-dimer and creatinine clearance and MAP. The 28-day mortality was lower in a high-dose Se-substituted patients (33% vs 37%), but not significantly. Conclusion The critically ill have an increased demand for Se, which is essential for synthesis of Se enzymes and Se proteins. The increased demand for Se is not covered by standard substitution. High-dose Se substitution (500-1,000 µg/day) normalizes its plasma level and increases the GSHPx plasma level. High-dose Se substitution has no adverse reactions. The decrease of 28-day mortality in high-dose Se-substituted patients is not significant. The trial on high-dose Se substitution further continues. Introduction Nutrition therapy is an integrant aspect of ICU support and can influence outcomes. A delay to starting nutrition support after 24 hours of ICU admission is associated with increased morbidity and mortality [1] , and certain lipid emulsions can exacerbate the inflammatory cascade. For an appropriate evaluation of the impact of these and other recent research findings, information regarding the use of parenteral nutrition (PN) in the ICU is needed. Methods This is the interim analysis of a multicenter, prospective, cohort study aimed to obtain information regarding the use of PN. Data were collected during 3 months from ICU patients over 18 years of age on the use of PN in 20 adult ICUs in Brazil using a web-based clinical research form. One hundred and sixty-six patients were included in this analysis. Among the main results, 63.69% were males and 77.78% were considered malnourished. The mean SOFA score was 6.21, with a mean APACHE II score of 19.39. In total, 97.23% of the PN used in Brazil were manufactured by third-party companies and this was associated with a significant delay in the beginning of the infusion (median time 29.76 hours), and elevated in-ICU (50%) and inhospital (55.17%) mortality rates. A total 24.29% of the patients were immunosuppressed. The most used lipid source was long-chain triglycerides/medium-chain triglycerides (80.69%). Conclusions The use of PN in Brazil is associated with a significant delay in the start of infusion and high mortality rates. The most used lipid emulsion (long-chain triglycerides/medium-chain triglycerides) has been associated with more apoptosis [2] and compromised lymphocyte proliferation [3] . The overall findings of these study indicate that strategies to reduce the delay in start of PN and the use of better lipid sources must be adopted to provide better assistance for patients in need of PN in Brazil. Introduction Ultrasound (US) significantly facilitates central venous catheterization, reducing the percentage of failure, the percentage of accidental arterial puncture, and the percentage of complications (haematoma, haemothorax, pneumothorax). Nonetheless, it is not clear whether US guidance (USG) (so-called 'dynamic' or 'real-time' US techniques: that is, venipuncture under direct US control) may be better than US assistance (USA) (socalled 'static' or 'indirect' US techniques: that is, US imaging of the vein, with or without skin marking, and then blind venipuncture). Methods From February 2005 to September 2006, our CVC Team adopted the following protocol for internal jugular vein (IJV) catheterization: (a) both IJVs were evaluated to assess position, dimensions, and other features known to affect the risk of catheterization; (b) then, a decision was made whether to continue with USA or USG; (c) the IJV was accessed via the low lateral Jernigan approach; (d) after two failed USA attempts, USG venipuncture was adopted; (d) when IJVs were not available, USG venipuncture of other central veins was the second choice; and (e) fluoroscopy was used only in paediatric patients, but all patients had a postoperative chest X-ray to rule out pneumothorax and malposition. Results In 20 months, 821 central venous catheters (CVCs) were inserted in adults (181 short-term CVC + 218 tunnelled + 316 ports) and in paediatric patients (age range 20 days-13 years, average 5.5 years: 20 short-term + 84 tunnelled + two ports). In adults, the procedure started as USA in 522 and as USG in 299 cases: a shift from USA to USG was necessary in 8%. USG was the first choice in all paediatric cases. The IJV was successfully cannulated in most adult patients, with very few exceptions (innominate vein in 12 cases, axillary vein in two cases, femoral vein in one case, all by USG). In one paediatric patient, the CVC was inserted in the subclavian vein, via a supraclavicular USG approach. Complications were: failure 0%; pneumothorax 0%; haemothorax 0%; accidental arterial puncture 1.1% (1.7% USA vs 0.3% USG); haematoma 0.4% (only for USA); malposition (0.8%, exclusively with the left IJV). Conclusion In conclusion, (a) we had a minimal incidence of complications, (b) USG was associated with a relevant reduction of the risk of accidental arterial puncture and haematoma, if compared with USA, and (c) choosing the left IJV was associated with a higher risk of malposition. The threshold value for RSBI that discriminated best between no NIV and the need for NIV was determined in 61 patients. Thirty-five patients who did not require ventilatory support had a mean RSBI of 105, and 26 patients with NIV had a mean RSBI of 222 (P = 0.0001). A receiver-operating-characteristic curve was constructed based upon the dataset in increments of 10 for the RSBI (Figure 2 ). An RSBI > 120 yielded a sensitivity of 0.81 and a specificity of 0.74 for determining the need for NIV. A likelihood ratio positive (LR+) of 3.14 further illustrates the formidable predictive value of the 120 RSBI. , low tidal volume ventilation (TV = 6 ml/kg) [2] , prophylaxis for stress ulcer (SUP) [3] , and deep vein thrombosis (DVTP) [4] . (Table 1) . On average, low tidal volume ventilation was adopted. DVTP and SUP were well implemented without training. There was no effect on frequency of pneumonia, ICU length of stay, or survival. Introduction The aim of the study was to compare the combination of intermittent mandatory ventilation plus pressure-support ventilation (SIMV+PSV) with intermittent trials of spontaneous breathing (ITSB) using a T-tube as two methods of weaning in a surgical ICU. Methods A total of 104 patients who had been ventilated for more than 48 hours in the postoperative period from October 2005 to October 2006 were enrolled in the study. After fulfilling the weaning checklist they were randomly assigned into two groups: SIMV+PSV group (n = 53), and ITSB group (n = 51). In patients assigned to the SIMV+PSV group, the ventilator rate was initially set at 6-8 breaths/minute plus PSV of 15 cmH 2 O and then both reduced, if possible, by 2 breaths/minute and 2 cmH 2 O each time. Patients able to maintain adequate ventilation with SIMV of 2 breaths/minute and PSV of 5 cmH 2 O for at least 2 hours without signs of distress were extubated. Patients assigned to the ITSB group were disconnected from the ventilator and allowed to breathe spontaneously through a T-tube circuit. The duration of the trials was gradually increased. Between the trials, assist-control ventilation was provided for at least 1 hour. Patients able to breathe on their own for at least 2 hours without signs of distress were extubated. Results Until the first attempt was made for weaning, all patients received assist-control ventilation because of haemodynamic instability. The following underlying conditions were present: chronic obstructive pulmonary disease in 67 patients, neuromuscular disorders in nine patients, acute lung injury as a result of surgery in 14 patients, asthma in six patients and miscellaneous causes in eight patients. The duration of mechanical ventilation before weaning was 2.5 ± 0.5 days in the SIMV+PSV group vs 2.4 ± 0.4 days in the ITSB group (P = 0.02) and the duration of weaning was 6.2 ± 0.23 hours vs 8.3 ± 0.44 hours in the two groups, respectively (P < 0.01). Patients who remained extubated for 48 hours were classified as having successful extubation -the rate of successful extubation in the first 24 hours of starting weaning was higher for the SIMV group (79.2%) than in the ITSB group (64.7%, P < 0.01). The total duration of mechanical ventilation was 3.3 ± 0.3 days vs 5.2 ± 1.1 days and the ICU length of stay was 5.6 ± 1 days vs 7.5 ± 1.7 days in the two groups, respectively (P < 0.01). Conclusions The use of SIMV+PSV as a weaning method in the surgical ICU lead to shorter duration of weaning, a higher rate of successful extubation, a shorter duration of mechanical ventilation and less ICU stay than the use of ITSB. The computer-driven ventilator settings could stabilise the ventilation of the lung-injured subject in the predefined thresholds. Compared with the beginning of the study, a reduction in ventilation pressure and PaCO 2 could be observed. Despite the initial low PaO 2 /FiO 2 ratio (<200 mmHg) of the subjects, FiO 2 could be decreased by the system in the given time without penetrating the thresholds for oxygenation. Conclusion Robust execution of an automated ARDS Network protocol with an electronically controlled ventilator is possible and leads to pulmonary stabilisation. Further trials have to be undertaken before this successful approach can be realised in ARDS patients. Introduction The optimal duration of prone position ventilation (PPV) in acute respiratory distress syndrome (ARDS) is uncertain. It has been pointed out that pulmonary ARDS patients respond less than extrapulmonary ARDS patients. Objective To study effects of continuous long-term PPV on gas exchange, PEEP, lung injury score and multiorgan failure in pulmonary ARDS patients. Materials and methods The design was a prospective (cohort). We studied 42 PPV periods in 33 pulmonary ARDS patients. Measures were taken in the supine position before PPV and at 1 hour after PPV, and then every 6 hours until the end of PPV. Statistical values are expressed as the median and interquartile range. Wilcoxon and Kruskal-Wallis tests were used. P < 0.05 was considered significant. Results The mean age was 44 (25-57) years, the initial lung injury score (LIS) was 3.1 (2.75-3.6), and PPV was maintained for 91 (51-117) hours. The PaO 2 /FIO 2 ratio was 125 (99-181) mmHg before PPV and 256 (170-298) mmHg after 1 hour of PPV (P = 0.001). This difference with the supine PaO 2 /FIO 2 ratio was sustained until the end of PPV. Initial values of PEEP were set at 15 (12-18) cmH 2 O by constructing a PEEP-compliance curve; there were no differences in PEEP values along the study. Initial values of PaCO 2 were 47 (41-69) mmHg and there were no significant differences along the study period. After 24 hours of PPV, the LIS was significantly decreased in comparison with the supine value before PPV: 3 (2.25-2.7) vs 2.5 (2.25-2.75), P = 0.001. There were no significant complications. Conclusions PPV had a positive effect on gas exchange even after 6 hours. This effect lasts through the PPV period. Because of its effect on the LIS, a duration of 24 hours for continuous PPV could be useful in this patient setting. Introduction There is great controversy concerning protective ventilation in ARDS. Recruitment maneuvers and PEEP titration sufficient to avoid collapse and tidal recruitment are the major goals of the maximal recruitment strategy (MRS). Objectives To describe clinical and demographic data. To evaluate the incidence of complications related to transportation and to the MRS. Methods Forty-three patients with ARDS were transported to CT and submitted to the MRS, which consisted of 2-minute steps of ventilation with a fixed PCV = 15 cmH 2 O and progressive PEEP levels (10-45-25-10 cmH 2 O), RR = 10, I:E = 1:1, and FiO 2 = 1.0. Opening (recruitment) and closing (PEEP titration) pressures were determined according to the least amount of collapse observed at the CT, and were used to ventilate the patients afterwards. Results Clinical data are presented in Table 1 . There were no complications due to transportation and one patient developed pneumomediatinum after the protocol. Introduction The analysis of the nonlinearity of respiratory compliance to guide ventilator settings in ALI and ARDS is well established. The pressure dependency (or volume dependency respectively) of respiratory resistance of these patients is mostly ignored. This study was performed to investigate the pressure dependency of resistance in ALI and ARDS over a wide range of pressures. Methods Twenty-one patients with ALI or ARDS were analyzed. Ventilation was interrupted by a respiratory manoeuvre: the volume was increased from ZEEP in steps of 100 ml with constant inspiratory flow until the plateau pressure reached 45 cmH 2 O. Each step was followed by a hold of 3 seconds. Inspiratory resistance during each step was determined by a least-squares fitting procedure. Results Resistance decreased from 10.7 ± 5.1 cmH 2 O·s/l at 5 cmH 2 O to 8.1 ± 4.0 cmH 2 O·s/l at 40 cmH 2 O (P < 0.05). Figure 1 shows individual absolute values and means ± SD of all patients. Most of the decrease was found up to 20 cmH 2 O; at higher pressures, changes were not uniform. The average relative changes in inspiratory resistance (±SD) of all patients are shown in Figure 2 . Conclusion Inspiratory resistance in ALI and ARDS is not constant. Especially at higher pressures, individual resistance may change unpredictably. The assumption of a constant resistance should therefore be avoided. Available online http://ccforum.com/supplements/11/S2 Introduction Alveolar microscopy seems to provide important insight into alveolar dynamics during mechanical ventilation [1, 2] . The utility of this method is limited due to high efforts needed to evaluate sequences of images with respect to alveolar geometry. The evaluation -done by hand -is time consuming, places a high cognitive load on the examiner and is error prone. Reproducibility of results is low. This project aims to establish a computer-assisted tool that provides semi-automatic evaluation of video sequences acquired with alveolar endoscopy. Methods We developed a computer program based on Matlab (Mathworks, Natick, MA, USA), which analyses video sequences acquired with an alveolar endoscope (Schölly, Denzlingen, Germany) [2] . The user has to provide a pointer to the alveoli that shall be traced and whose changes in size and shape are to be determined. Filters, smoothing splines and expectation-driven fine tuning is performed to achieve robust and predictable results of the intratidal change in alveolar geometry. Results Animal studies related to alveolar mechanics during artificial ventilation were conducted. Figure 1a shows a plot of a frame taken from a video obtained during an experiment performed on a healthy anesthetized rat. Overlaid circles indicate identified boundaries of a selected alveolus. Figure 1b presents a trace of alveolar diameter during a tidal breath. Evaluation of successive frames allows one to compensate for motion artifacts and to analyze the intratidal changes in alveolar geometry. Conclusion Given a synchronization with respiratory data, this tool will allow one to quantify pressure-related changes of alveolar size. Thus it will allow one to monitor the alveolar distension in a variety of animal models (for example, lavage-induced ARDS) and to correlate these findings, for example, with outcome. Introduction Alveolar recruitment and maintenance of lung volume are important goals in the treatment of acute lung injury (ALI) and essential for improving oxygenation. The most usual employed strategy to achieve this goal is the use of positive end-expiratory pressure (PEEP). Recruitment and collapse are highly dynamic phenomena that are difficult to monitor. Dynamic effects of regional ventilation can be monitored by electrical impedance tomography (EIT) at the bedside [1] . We investigated the ability of EIT for providing a useful tool to detect dynamic changes of regional breath by breath recruitment at the bedside during an incremental and decremental PEEP trial in experimental lung injury. In addition, we analyzed pressure-volume (P-V) curves computed by EIT data. Methods ALI was induced in six pigs by repetitive lung lavage. After stabilization of the lung injury model (> 1 hour) a stepwise PEEP trial was performed consisting of 2-minute steps of tidal ventilation (10-30 cmH 2 O; 30-5 cmH 2 O). During the PEEP trial subjects were ventilated pressure-controlled. Global ventilatory and gas exchange parameters were continuously recorded. Offline we analysed EIT data by computing the amount of breath by breath recruitment (∆V EIT) at each pressure level before and after lung lavage. Nondependent and dependent regions of interest were defined in the tomograms. ∆V EIT was defined as the mean increase or decrease in end-expiratory global impedance per breath. Results Ventilatory parameters clearly showed a recruitment of nonaerated lung areas at the descending part of the pressure ramp. The shape of the P-V curve from EIT data, in particular the increasing slope (lower level > upper level), reflected the recruitment of poorly ventilated lung regions. The flattening of the curve at higher pressures, especially at the upper level, reflected less amount of recruitment but more overdistension. Regional pulmonary recruitment/derecruitment was very high in the lower level. These phenomena were more impressive after induced lung injury. S79 of ventilator settings and respiratory mechanics is crucial for further developments of protective lung ventilation. Up to now, the nonlinearity of compliance has mainly been the focus of interest. We hypothesized that airway resistance also changes intratidally. Therefore, this study was performed to analyze the dependence of resistance on tidal gas volume. Methods After induction of anesthesia and tracheotomy, the lungs of 14 surfactant-depleted piglets were ventilated at zero endexpiratory pressure with three different tidal volumes (8, 12, 16 ml/kg) in a randomized order. In addition, baseline measurements (12 ml/kg) were performed before saline lavage. Before any change of the ventilator settings a recruitment maneuver was performed. The nonlinear intratidal airway resistance was analyzed using the SLICE method [1] . Results Figure 1 shows the intratidal resistance before lavage (grey) and after surfactant depletion (black) plotted against the alveolar pressure. Each curve in the diagram represents the intratidal course of resistance for one ventilator setting. Resistance is increased after surfactant depletion and is intratidally declining before and after lavage. Conclusion The analysis of resistance shows a dependence on intratidal volume. The nonlinear course of intratidal resistance can be interpreted as a volume-related caliber effect leading to an increase of cross-sectional area of the large and small airways. Introduction Alveolar recruitment maneuver (ARM) using high airway pressures has been shown to re-expand atelectasis and to improve gas exchanges after general anesthesia; however, ARM may lead to lung stretching-induced inflammatory response. The objective of this study was to evaluate plasma cytokine behavior after an ARM in healthy volunteers. Methods After obtaining ethical committee approval and informed consent, a basal blood sample was collected in 10 healthy volunteers. Continuous positive airway pressure (CPAP) was noninvasively applied (BiPAP Vision ® ; Respironics, USA) using a total face mask. CPAP was increased by 3 cmH 2 O from 5 to 20 cmH 2 O every five breaths. At CPAP of 20 cmH 2 O, an inspiratory pressure of 20 cmH 2 O above CPAP was implemented during 10 breaths. After that, CPAP was stepwise decreased in an inverse fashion. Pulse oximetry, arterial pressure and heart rate were measured before and after ARM. Additional blood samples were drawn at 30 minutes, 2 and 12 hours. TNFα, IL-1β, IL-6, IL-8, IL-10 and IL-12 were measured by the flow cytometry technique (Cytometric Bead Array BD™ Kit). The highest cytokine value at 30 minutes or 2 hours after ARM was considered the peak value measurement. Data were analyzed using a paired t test and oneway RM ANOVA. P < 0.05 was significant. Results Four men and six women with a mean age of 26 ± 1 years and mean BMI of 23.8 ± 3.6 kg/m 2 were studied. No changes were observed in heart rate or MAP after ARM, while pulse oximetry increased from 97.2 ± 0.8% to 98.4 ± 0.7% (P = 0.009). As shown in Figure 1 , ARM induced a significant increase in the peak plasma level concentration of all cytokines that returned to basal levels within 12 hours. No adverse effects were observed during and after ARM. Conclusions Despite beneficial effects in reversing atelectasis, ARM-induced lung stretching was associated with an inflammatory response in healthy volunteers. Introduction Recruitment/derecruitment (R/D) seems to play an important role in the development of VILI [1] . Many clinicians base their determination of PEEP settings during mechanical ventilation of ARDS/ALI patients on an estimate of alveolar recruitability [2] . This project aims to establish an online tool that provides estimates of R/D in patients at the bedside. approaches [1, 3, 4] . Our model is fitted (currently offline) to patient data acquired during controlled mechanical ventilation. For data acquisition the internal respiratory data of a ventilator (Evita 4; Dräger Medical, Lübeck, Germany) is read in real time. The simulation assumes a quantitative partition into pressuredependent and time-dependent recruitment. Pure pressure-related approaches (for example [1] ) are not able to describe transients (for example, a volume shift after a change in PEEP). The right and left lung distribution of vibration intensity is shown in Figure 1 . The mean percentage change of vibration intensity clearly demonstrates the increased vibration in ventilated lungs (89.1 ± 5.47% vs 10.9 ± 5.4%, P < 0.05) ( Figure 2 ). Conclusions Auscultation is insensitive to endobronchial intubation and chest radiography may not be immediately available. VRI offers the potential to rapidly and noninvasively determine endobronchial intubation. Currently VRI is performed in the sitting position, but the capability of supine imaging will soon be available. Introduction Airflow into a mechanically ventilated patient is easily measured in the inspiratory limb of the ventilator. Regional airflow inside the lungs, up to this point, is a black box. Vibration response imaging (VRI) is a novel technology that measures vibration energy from the lungs to create a real-time structural and functional image of regional vibration during respiration. Sophisticated surface skin sensors are placed on the subject's back to record, analyze and display vibrations noninvasively. Our goal was to assess the correlation of vibration measured at the chest wall with airflow into the lungs. Methods To assess the effect of constant inspiratory flow on lung vibration, VRI was performed on a mechanically ventilated patient on assist volume control, and airflow in the tubing was recorded concurrently. To assess the effect of increasing flow rates on lung vibration, healthy subjects were recorded several times with VRI while taking tidal volumes of 200-1,300 ml at the same respiratory rate. The inspiratory tidal volume was recorded. Available online http://ccforum.com/supplements/11/S2  In the mechanically ventilated patient, when there is minimal flow, the vibration was at its lowest. When flow begins at the ventilator, the vibration measured over the lungs increases and when the flow stops, the vibration decreases. An inspiratory hold was performed to separate inspiratory from expiratory vibrations ( Figure 1 ). As the subject takes increasing tidal volumes, the vibration during the breath cycle increases linearly. A sample subject is shown in Figure 2 (R 2 = 0.81). Conclusion Vibration measured using VRI correlates with lung airflow. Given the difficulty in assessing airflow in the lungs, measuring lung vibration could potentially serve as a surrogate for regional lung airflow. The generated aerosol had a mass median aerodynamic diameter of 1.6 µm, with 85% of all particles being smaller than 5 µm, and the average mass of surfactant being nebulized under these conditions was approximately 1 g/min. Biochemical and biophysical studies showed that the composition and surface tension reducing properties of the rSP-C surfactant remained unaltered after nebulization. In both rabbit models, administration of 130 mg/kg body weight rSP-C surfactant resulted in a far-reaching restoration of gas exchange and compliance. In bleomycinchallenged, spontaneously breathing mice, surfactant aerosolization resulted in a restoration of compliance. Conclusions Nebulizer characteristics and results from the in vivo studies suggest that the herein-described dry powder nebulizer might proffer for surfactant therapy of ARDS. Objectives (1) To study the effects of BAL on respiratory mechanics in mechanically ventilated patients with suspected pneumonia, and (2) to find out whether these effects are related to the extension of radiographic infiltrate and preceding respiratory mechanics measurements. Methods BAL was performed with 150 ml sterile isotonic saline in three aliquots of 50 ml. Respiratory mechanics (static compliance and airway resistance) was measured using the rapid airway occlusion technique immediately before and after the BAL and 90 minutes later. The heart rate, arterial blood pressure and body temperature were recorded continuously in all patients. Patients were classified according to the presence of unilateral or bilateral infiltrates. Results Fifty-eight critically ill patients undergoing mechanical ventilation were included. Following the BAL, compliance of the respiratory system (Crs) decreased from 50.9 ± 36.1 to 35.6 ± 14.8 ml/cmH 2 O (P < 0.01) and airway resistance increased from 16.2 ± 7.6 to 18.1 ± 11.3 cm H 2 O/l/seg (P < 0.05); 90 minutes later, both parameters had returned to pre-BAL values (P = not significant). Patients who showed >20% decrease in Crs had higher pre-BAL Crs than patients with less severe decrease (55.8 ± 20.1 vs 36.9 ± 14.1; P < 0.001). On the contrary, neither pre-BAL airway resistance nor the extension of the radiographic infiltrates were related to the changes in respiratory mechanics. Conclusions (1) BAL in mechanically ventilated patients can lead to a significant but transitory deterioration on pulmonary mechanics characterized by a decrease in Crs and an increase in airway resistance. (2) Patients with better initial Crs showed the more severe affectation. Clinical examination (CE) and chest X-ray (X-ray) have limited sensibility and specificity. Contrast-enhanced computed tomography (CT scan) is the gold standard. CT scan has limitations: it takes time to be performed, implies transport of severely injured patients, and has ionising effects. Thoracic ultrasonography (US) can be quickly performed at the bedside in the emergency room. It has good diagnosis accuracy in ARDS patients [2] . The purpose of this study is to evaluate the diagnosis accuracy of US in severely injured patients in the emergency room. Methods We prospectively evaluated 90 patients (median age: 41 (7-89) years) who were admitted to the emergency room of the Grenoble University Hospital over a period of 9 months. Pneumothorax, hemothorax and alveolar consolidation were diagnosed by CE, X-ray and US. The physician who performed the US was not involved in the patient's management. Results During 123 missions, 15 adult patients underwent prehospital endotracheal intubation (cardiac arrest n = 9, multiple injuries n = 4, drug poisoning n = 1, pulmonary edema n = 1) with the Bonfils intubation fiberscope, the use of which was either planned (n = 13) or unplanned (n = 2). All intubations were successful in the first attempt, even in two cardiac arrest victims who had an unexpected difficult airway (Cormack&Lehane grade IV under direct laryngoscopy). In those patients with multiple injuries the cervical immobilization collar did not need to be unfastened or removed for endotracheal intubation. Sufficient retropharyngeal space -which is mandatory for sufficient use of the Bonfils -was created by a digital jaw thrust maneuver in the first three patients. Using a standard Mackintosh laryngoscope blade significantly enhanced ease of insertion of the Bonfils fiberscope and visualization of the glottic aperture, thereby decreasing the procedure time from 35-40 seconds to 20-25 seconds. Conclusion Despite this first promising series of in-the-field use, physicians and paramedics should familiarize themselves with the Bonfils device under optimal clinical conditions before using it under emergency or prehospital conditions. In our experience, the learning curve with the Bonfils device is steep, and 10 intubations supervised by an instructor usually prove effective for achieving sufficient skills to use the Bonfils on one's own and under less optimal conditions. In summary, we believe that the Bonfils fiberscope will prove its value as an additional airway management device in both, emergency and prehospital settings. Introduction This study was designed to assess the ability of ICUs to deal with the unanticipated difficult intubation. The ICU is a location in which the incidence of difficult intubation has been found to be significantly higher than in theatre (8-22.5% vs 1.5%). Method We contacted all adult general ICUs in the South of England and invited the physician responsible for airway management to take part in a structured interview. The interview was designed to follow the Difficult Airway Society (DAS) guidelines. We designed six equipment-related questions that identified a unit as achieving the minimum levels of equipment necessary. These included availability of laryngoscopes, capnography, LMA/ILMA, and rescue techniques. Introduction Occasionally, rescuers are confronted with a hard situation to establish tracheal intubation compared with doctors in the anesthetic room. Especially in the confined space, the tracheal intubation must enter technical difficulties with any supporting device. This may be caused by the fact that there was no device developed specially from a standpoint in the clinical emergency use. Objective The AirWay Scope (AWS) is one of the newest intubation devices, manufactured using modern technology to alleviate the tracheal intubation in emergency scenes. The AWS is equipped with a full-colored CCD, a LCD monitor and a specially configured introducer guiding a tracheal tube into the glottis (Figure 1 ). The aim of this study is to confirm the potential of the AWS as an intubation-supporting device in emergency scenes. Method Six doctors in the emergency department were enrolled in this study. All doctors have experienced using the AWS in cases on the operation Available online http://ccforum.com/supplements/11/S2 Of 350 patients admitted to the burn center from July 2005 to December 2006, 20 (6%) required a tracheostomy. Eighteen were performed percutaneously, 13 at the bedside. The total burn surface area averaged 46% (range 2-95%). PT were performed within an average of 10 days from admission (range 0-32 days). Overall mortality in the tracheostomy group was 35%. There were no short-term complications associated with this method. Conclusion PT can be performed safely in severely burned patients using a semi-open percutaneous technique. Exposing the trachea and palpating the trachea avoids the risk of losing the airway and permits immediate access to the trachea in the event of an untoward loss of the airway. We believe that this method is safer than the more commonly used technique requiring bronchoscopic visualization. Introduction A retrospective analysis of a year cohort of tracheostomies discharged from intensive care in a specialist cardiothoracic centre was undertaken to analyse whether facilitated outreach-led discharge was safe. Methods A retrospective analysis of the ICU database was undertaken to identify all patients who had a tracheostomy (percutaneous or surgical) inserted in the ICU, and a chart review of patients discharged from the ICU with a tracheostomy in situ was performed. The following variables were collected: patient demographics; diagnosis; number of days of tracheostomy in situ; number of days on noninvasive ventilation (CPAP); and tracheostomy-related complications. A review of the risk management database was performed to identify any tracheostomy-related reported adverse events. Results One hundred and eight tracheostomies were performed in intensive care in the 2-year period. Sixty-two patients were discharged with tracheostomy in situ and were reviewed by the outreach team for a cumulative total of 710 days until decannulation. There were 383 days whereby patients with a tracheostomy in situ had been noninvasively ventilated. There were three reported critical events relating to tracheostomy and no deaths. Conclusion More than 60% of patients who had a tracheostomy inserted are discharged from critical care with a tracheostomy in situ. With the support of the outreach team these patients were successfully managed in Level 2 and Level 1 areas. This reduced the requirement for critical care (Level 3) bed-days. There was a low rate of complications. We concluded that outreach services can facilitate early and safe discharge of tracheostomy patients from critical care. Indication of levosimendan therapy was acute heart failure due to myocardial infarction in 23 cases and acute progression of chronic heart failure (NYHA III-IV) in 18 cases. After a 10-minute bolus levosimendan infusion was administered at rate of 0.1 µg/kg/min for 6 hours and 24 hours in each group, respectively. We investigated the occurrence of sustained ventricular or supraventricular arrhythmias for the first 48 hours from the beginning of infusion. The ratio of hypertension, diabetes, earlier myocardial infarction and ACBG were 58%, 27%, 32% and 15%, respectively, in the monitored population (13 females, 28 males; mean age: 68 years). Three ventricular arrhythmias and one supraventricular arrhythmia were observed during the 48-hour period, all of them occurred in acute heart failure patients with acute myocardial infarction. Parallel usage of catecholamines (noradrenalin and/or dopamine) and levosimendan therapy was observed in three cases, in one of them ventricular tachycardia was observed 3 hours after starting levosimendan infusion. No arrhythmia was observed in chronic heart failure patients. The incidence of proarrhythmic effects during levosimendan therapy was 9.75% of the whole analysed population and was 17.4% at acute heart failure during acute myocardial infarction. Conclusion With these results the authors would like to draw attention to the proarrhythmic effects of levosimendan during acute heart failure therapy, especially in the case of parallel usage with catecholamines. Introduction Myocardial depression in sepsis, among other factors, is due to calcium (Ca 2+ ) desensitization in the myofilament. So using a Ca 2+ sensitizer drug may play a beneficial role in this situation. Levosimendan has a dual mechanism; it causes Ca 2+ sensitization through binding to Troponin C and opening of ATPdependent K + channels in vascular smooth muscle. The average age was 67.6 ± 10.39 years and the APACHE II score was 26.33 ± 2.37. Patients were divided into three subgroups: survivors, 7th-day and 30th-day mortality groups. There was no significant difference in these subgroups regarding age and APACHE II score. Levosimendan group 7th-day and 30thday mortality was 33% and 66% as compared with historical data of 37% and 71%, respectively. The change in CI in the survivor group was significant (P = 0.021), from 2.11 ± 0.17 to 3.8 ± 0.28, while in the 7th-day and 30th-day mortality groups it was insignificant. SvO 2 increased in the survivor and 30th-day mortality groups significantly (P = 0.011 and P = 0.035, respectively). It did not show any significant improvement in the other group. MAP also showed significant improvement in the survivor group (P = 0.026) and insignificant in others. Conclusion It is evident from our study that levosimendan improves hemodynamic response in septic patients. Although it improves the mortality, we cannot say with full confidence that these improved hemodynamic parameters are responsible. Randomised control trials are needed to answer this question, which are underway. The average age was 84 ± 3.6 years, 39 (58%) were women. The location of the AMI was anterior in 56%, and 25% were diabetic. The average follow-up time was 19 ± 17 months. During the follow-up, 43 patients developed events, most of them (n = 28) consisting of death (23 by cardiac death). However, most of these events occurred in the first month after the admission, the mortality between 1 month and 3 years being low ( Figure 1 ). Conclusion Our data show that the octogenarian patients with STEMI treated by primary PCA developed a very high mortality. However, this mortality especially concentrates in the first month after the procedure, being low between 1 month and 3 years. Purpose Although invasive management of ST-segment elevation myocardial infarction (STEMI) has improved the clinical outcome, early mortality remains an important issue. Our purpose is to assess the utility of the initial electrocardiographic (ECG) pattern in detecting patients who are at increased risk despite the current recommendations of revascularization. Methods We analyzed 446 consecutive patients (age 61.9 ± 13.8 years, 76.5% male) admitted in the first 12 hours of STEMI to our coronary unit. Exclusion criteria were left bundle branch block at admission or previous myocardial infarction. Most patients (87%) were treated with primary angioplasty. Patients treated with thrombolytics and with early reperfusion criteria were programmed to coronary angiography the following day. Two groups were defined according to the presence of ST-segment elevation (STE) together with distortion of the terminal portion of the QRS in two or more adjacent leads (group 1) or the absence of this pattern (group 2) (Figure 1) . Results ST elevation with distortion of the terminal portion of QRS were present at initial ECG in 55 patients (23%). This group had a lower incidence of Rentrop grade 2/3 than group 2 (P = 0.006, Figure 1 ). Moreover, group 1 had higher enzyme release, worse maximal Killip class and more frequently the combined variable death/shock. Group 1 more often had proximal occlusion of the infarction-related artery and nonreflow. Multivariate analysis found ECG to be an independent predictor of outcome. Available online http://ccforum.com/supplements/11/S2 The prevalence of anaemia (Hb < 11 g/dl in women and Hb < 12 g/dl in men) in patients with an ACS was 15.4%. This group was characterised by the following: woman (P < 0.0001), higher age (P = 0.0001), less weight (P = 0.01), higher frequency of high blood pressure (P = 0.0001), diabetes mellitus (P = 0.0001), history of ischaemic heart disease (P = 0.002) and peripheral artery disease (P = 0.0001). This group presented a major proportion of the NSTEMI (P = 0.015), higher level of renal dysfunction (77% to 32%, P = 0.0001), and microalbuminuria (61% to 32%, P = 0.0001). Patients with anaemia presented a worse intrahospital prognosis: major incidence of cardiac insufficiency (42% to 20%, P = 0.0001), refractory angina pectoris (14% to 6%, P = 0.01), more electric complications (12% to 9%, P = 0.01) and a higher mortality (14% to 7%, P = 0.009). The presence of anaemia was an independent predictor of cardiac insufficiency and death at the moment of admittance to the CCU (OR = 2.20, 95% CI = 1.10-4.35; P = 0.002) Conclusion The presence of anaemia is a powerful predictor of a worse prognosis in patients with ACS. Anaemia is associated with other factors of a worse prognosis such as renal dysfunction, peripheral artery disease and diabetes mellitus. In both ESCAPE-1 and ESCAPE-2, clevidipine demonstrated a statistically significant decrease in mean arterial pressure from baseline (P < 0.0001) compared with placebo at the 5-minute time point. A BP lowering effect was observed within 1-2 minutes with clevidipine, with the median time to achieve target systolic blood pressure (SBP) of 6 and 5.3 minutes, respectively (see Figure 1 ). In the patients with acute severe hypertension, the VELOCITY trial studies the percentage of patients in whom the SBP falls below the lower limit of a patientspecific predetermined target range at the initial dose of 2.0 mg/hour within 3 minutes of initiating the infusion, as well as the percentage of patients who reach the prespecified target SBP range within 30 minutes of the beginning of the study drug. Conclusion In both the ESCAPE-1 and ESCAPE-2 studies, clevidipine demonstrated the ability to precisely achieve target blood pressure reductions in a short period of time, in a high-risk patient population. Further analysis of the rapid decreases noted with clevidipine is being conducted in patients with acute severe hypertension in the VELOCITY trial. The incidence of the primary endpoint was 17.7%. By multivariate Cox analysis, including baseline characteristics and the study biomarkers, elevated circulating levels of TNFα (RR = 2.1; P < 0.001), BNP (RR = 3.5; P < 0.001) and cTnI (RR = 3.8; P < 0.001) were independently associated with the primary endpoint. When the patients were divided according to the number of positive biomarkers (estimated by ROC analysis) there was a significant gradual increase in the rate of the primary endpoint with increasing of the number of the positive biomarkers (4.1%, 10%, 21.5% and 53.5% 31-day mortality rate for patients with zero, one, two and three positive biomarkers, respectively; P < 0.001) (Figure 1 ). Conclusions VS post-CPB was associated with activation of serin protease systems, which leads to higher blood loss and excessive bleeding. Introduction Vasoplegic syndrome (VS) after cardiac surgery with cardiopulmonary bypass (CPB) can vary from mild to severe complication and it appears with an incidence ranging between 5% and 15%. The etiology is not completely elucidated but risk factors such as temperature and duration of cardiopulmonary bypass and preoperative treatment with angiotensin-converting enzyme (ACE) inhibitors have been associated [1] . We wanted to investigate the possible role of several genetic polymorphisms in patients with VS after elective CPB. We observed 17 (34%) patients with vasoplegia criteria, 11 (65%) men and six (35%) women, age 67 (61-72) years. The only one associated with VS was the PAI-1 polymorphism, and its distribution in the study population was: 4G/G genotype in 10 (20%) patients, 4G/5G in 26 (52%) patients, and 5G/G in 14 Introduction Body mass index (BMI) has been described as a risk factor for coronary artery disease, but association with postoperative bleeding after cardiopulmonary bypass (CPB) has been found in several studies recently. Nevertheless the strong relationship between a low BMI and excessive bleeding remains unexplained. We sought to investigate the BMI role on postoperative bleeding and its relationship with leptin levels, coagulation, fibrinolysis and complement parameters. Methods We performed a nested case-control study of 26 patients, who did not receive antifibrinolytic prophylaxis. We used Bray's classification for BMI: lower than 27 kg/m 2 ; 27-30 kg/m 2 ; higher than 30 kg/m 2 . Variables were collected preoperatively, at ICU admission (0 hours), and at 4 and 24 hours after surgery. Excessive bleeding was defined as blood loss higher than 1 l in the first 24 hours after intervention. Figure 1 ). BMI presented a direct correlation with leptins, fibrinogen and plasminogen activator inhibitor-1 (PAI-1) on arrival, meanwhile 24-hour bleeding showed an inverse correlation with the same parameters and BMI (Table 1) . Patients with BMI < 27 kg/m 2 had significantly greater coagulation, fibrinolysis and complement activation. Therefore these patients required significantly greater hemoderivatives. Conclusions Lower BMI was associated with higher postoperative bleeding and lower procoagulant factor levels. 49) ), respiratory control ratio (11 (7-15) vs 10 (9-11)) (not significant). Hepatic mitochondrial state 4 was higher (27 (16-31) vs 19 (13-22)) and respiratory control ratio lower (3 (3-4) vs 5 (4-6)) in the hemorrhage/endotoxemia group, compared with controls. Background Sepsis-induced multiple organ failure may crucially depend on the development of mitochondrial dysfunction and consequent cellular energetic failure. We investigated whether hepatic mitochondrial dysfunction was present in a clinically relevant porcine model of fluid-resuscitated septic shock. Methods Anesthetized and ventilated pigs (40 ± 3 kg) were randomly assigned to septic shock by fecal peritonitis (F, n = 3) or control (C, n = 3) after placement of portal/hepatic vein catheters and portal vein and hepatic artery flow probes. F and C received 8 ± 13 ml/kg/hour and 5 ± 7 ml/kg/hour ringer lactate + starch, respectively. The mean arterial pressure (MAP), total liver flow (TLF), hepatic O 2 delivery (DO 2,h ) and hepatic O 2 consumption (VO 2,h ) were recorded at baseline (BL), 12 and 24 hours (ml/kg/min). Activities of mitochondrial respiratory chain enzymes (complex I-IV) were assessed by spectrophotometry in snapfrozen liver samples. Data are presented as the mean ± SD. Results Hyperdynamic circulation developed in F with increasing DO 2,h and decreasing VO 2,h ( Table 1) . Complex II activity significantly decreased from 19.3 ± 4.2 to 9.5 ± 2.6 (P < 0.05 vs BL and between groups) in F compared with C. Complex I-III-IV function decreased in parallel in F. Monitoring of the mitochondrial NADH redox state (an indicator of intracellular oxygen levels) together with microcirculatory blood flow (TBF) and with oxygenation (HbO 2 ) could serve as a preferred approach to evaluate tissue O 2 balance or viability. We hypothesize that in the presence of reduced oxygen delivery and extraction, blood flow will be redistributed in order to protect the most vital organs by increasing their regional blood flow, while O 2 delivery to the less vital organs will diminish. Thus, the NADH redox state of less vital organs could serve as an indicator of overall O 2 imbalance as well as an endpoint of resuscitation. We have therefore developed an optical device embedded in a Foley catheter to provide real-time data on the NADH redox state, TBF and HbO 2 in critically ill patients. The CritiView is a computerized optical device that integrates hardware and software in order to provide real-time information of S107 tissue viability [1] . A modified three-way Foley catheter that contains a fiberoptic probe connects the CritiView to the mucosal side of the urethral wall. We have used this device in five female pigs that underwent graded hemorrhage, and in four patients who were monitored during aortic abdominal aneurysm operations. These preliminary swine model and human studies confirm the feasibility of collecting information about mitochondrial function from the urethral wall. The main effects of graded hemorrhage started when the blood volume decreased by 30%. At 40% blood loss, minimal levels of TBF and HbO 2 were correlated to the maximal NADH levels. The values of the three parameters returned to baseline after retransfusion of the shed blood. Aortic clamping in patients led to a significant decrease in TBF and HbO 2 while NADH levels increased. After aortic declamping, the parameters recovered to normal values. Our preliminary results show that the CritiView may be a useful tool for the detection of O 2 imbalance and the development of an emergency metabolic state in nonvital tissues.  The MFI decreased in all sizes of microvessels <15 minutes after starting CPB in comparison with baseline (P < 0.05, Table 1 ). After starting CPB, the mean arterial pressure (MAP) was lower (61 mmHg (53-65 mmHg)) than at baseline (100 mmHg (92-118 mmHg); P = 0.01). After return to the ICU, the MFI increased (P < 0.05) and returned to baseline values in all microvessels. Conclusions SDF imaging can be used as a bedside tool to evaluate sublingual microcirculatory changes during cardiac surgery. Despite maintaining common circulatory parameters during CPB, the nonpulsatile status, hypothermia, and the temporary drop in MAP after starting CPB were associated with decreased sublingual MFI, which normalized after surgery. Further studies should reveal whether these changes are related to outcome. Introduction Complications of oesophagectomy with gastric tube reconstruction include leakage and stenosis. This can be explained by compromised local perfusion, although it is unclear to which extent local and systemic factors contribute to this process. The aim of this study was to observe the microvascular blood flow in an unaffected, distant tissue during the perioperative period. Methods Twelve patients were included. Anesthesia consisted of thoracic epidural analgesia, restrictive peroperative fluid therapy (net peroperative fluid balance below 4 l) and early extubation. In the ICU, fluid infusion was adjusted in order to maintain hourly urine production of 0.5 ml/kg. The mean arterial pressure was maintained at or above 60 mmHg with administration of noradrenalin if necessary. Microcirculation was visualized in the sublingual tissue with the MicroScan, a sidestream dark field imager. Data were collected at five time points: immediately after induction, after gastric tube reconstruction, directly postoperative, and days 1 and 2 postoperatively. Video data collected with the MicroScan were analysed according to semiquantitative analysis described by Boerma and colleagues [1] . We divided the vessels into three categories: small (5-10 µm), medium (10-15 µm) and large (>15 µm). By dividing the images into four quadrants and categorizing the flow per vessel-size per quadrant, we calculated the microvascular flow index (MFI) Results See Figure 1 .  The FCD was decreased significantly in QFM in rats with IPPV with respect to Group SB (184 ± 27 resp. 197 ± 61 cm/cm 2 ), but the FCD of the intestinal serosa was not affected by IPPV (265 ± 46 resp. 267 ± 25 cm/cm 2 ). There were no differences in mean blood pressure and temperature between groups (128 ± 7 Torr and 36.6 ± 0.1°C in Group SB, or 128 ± 10 Torr and 36.5 ± 0.1°C in Group IPPV). Conclusion The use of IPPV should be taken into account in the interpretation of the studies examining the changes in microcirculation in rats.  In the control group, all parameters were not changed during the observation period of 400 minutes. In the experimental group, the mean arterial pressure (MAP) remained fairly stable until 300 minutes after injection of LPS, and the MAP gradually decreased subsequently. While the MAP was maintained, the PtO 2 gradually decreased linearly ( Figure 1 ). TL increased with time linearly. Meanwhile, BL did not change from 150 to 250 minutes; after 300 minutes it increased abruptly in the experimental group ( Figure 2 ). Conclusions In our experimental endotoxemia model it has been shown that partial pressure of oxygen in subcutaneous tissue decreased even if systemic blood pressure was maintained. Boekstegers and colleagues [1] revealed that mean skeletal muscle PO 2 was increased in patients with sepsis compared with patients with limited infection. We obtained conflicting results to those of Boekstegers and colleagues. The reason for this is unknown. BL abruptly increased during 50-150 minutes, probably from abnormal metabolism induced by LPS in whole-body organs. It is considered that BL did not show a rise during 150-250 minutes due to metabolization of lactate in liver and muscle. TL, which is insusceptible of lactate metabolism by other organs, may reflect abnormality of tissue metabolism precisely. Shunting of the microcirculation contributes to the pathology of sepsis and septic shock. In this study, we hypothesize that shunting of the microcirculation occurs after superior mesenteric artery (SMA) ischemia (occlusion) and reperfusion, and we explore functional consequences using intravital microscopy. Spontaneously breathing animals (rats) (n = 30) underwent occlusion of the SMA for 0 (controls), 30 or 60 minutes followed by reperfusion (4 hours) with normal saline. Leukocyte-endothelial interactions in mesenteric venules were quantified in an exteriorized ileal loop using intravital microscopy. Abdominal blood flow was recorded continuously, and arterial blood gases were analyzed at intervals. Continuous SMA blood flow measurements were performed in comparable groups without exteriorizing an ileal loop. Adherent leukocytes increased shortly after reperfusion in ischemia groups, and plateaued in these groups. The centerline velocity and shear rate in the recorded venules were significantly reduced after reperfusion down to low-flow/no-flow in animals undergoing 60 minutes of mesenteric artery occlusion compared with animals with 30 minutes occlusion and controls, whereas perfusion of the SMA and ileal vessels persisted. The microcirculatory changes in animals with 60 minutes occlusion were accompanied by progressive metabolic acidosis, substantially larger volumes of intravenous fluids needed to support arterial blood pressure and significantly reduced survival (30%). In the groups with continuous SMA blood flow measurements, SMA blood flow increased in SMA occlusion for 60 minutes and subsequent reperfusion causes perfusion abnormalities in the mesenteric microcirculation as often seen in sepsis and septic shock with increased microcirculation shunting, progressive metabolic acidosis and increased mortality. To detect these significant changes requires prolonged observation periods and might help to find new treatments to improve the poor prognosis of mesenteric ischemia. Introduction Targeting oxygen delivery in the postoperative period has been shown to reduce hospital length of stay and complications [1] . Using a near-infrared spectroscopy device such as the Inspectra™ 325 allows the measurement of tissue oxygen saturation (STO 2 ) noninvasively as well as a rudimentary measure of blood flow beneath the probe. It is plausible, then, that changes in oxygen delivery (DO 2 ) during postoperative optimisation may be reflected in changes in STO 2 and provide a noninvasive surrogate of DO 2 . Methods All adult patients admitted to the ICU after surgery who underwent protocolised haemodynamic optimisation were included. All patients had STO 2 recorded over the thenar eminence using an Inspectra™ 325 for the first 8 hours of their stay. We found a significant correlation between the changes in STO 2 and oxygen delivery index (DO 2 I) over the first 8 hours of intensive care stay (n = 40, correlation coefficient of 0.947, P = 0.0001, Figure 1 ). We classified patients who achieved DO 2 I > 600 ml/min/m 2 as responders. These responders had higher STO 2 values by 3 hours of optimisation, a change that remained significant throughout the duration of the study (Figure 2 ). Conclusion Changes in STO 2 during postoperative optimisation appear to mirror changes in DO 2 I and may allow more widespread use of noninvasive tissue oxygenation devices in surgical optimisation. Methods We randomized 36 healthy subjects undergoing maxillofacial surgery to receive general anesthesia with a sevofluoraneremifentanil (Group S) or a propofol-remifentanil association (Group P). We collected noninvasive measures of hemoglobin concentration from the gastrocnemius muscle of the subjects using a NIRS device (NIMO, NIROX srl, Italy), which performs quantitative assessments of the [HbO 2 ] and [Hb] exploiting precise absorption measurements close to the absorption peak of the water. Data were collected during a series of venous occlusions at different cuff pressures, before and after 30 minutes from induction of general anesthesia. The muscle blood volume and microvascular compliance were obtained with a process previously described elsewhere [1] . Data were analyzed with a one-way analysis of variance test. Results Demographic data of the 36 subjects were similar in both Groups S and P. General anesthesia reduced the heart rate and mean arterial pressure and increased the total muscle blood volume in both groups (Group S: from 2.4 ± 0.9 to 3.2 ± 1.2 ml/ 100 ml; Group P: from 2.4 ± 1.2 to 3.5 ± 1.8 ml/100 ml; P < 0.05). During general anesthesia, despite no differences in muscle blood volume between the two groups, sevofluoraneremifentanil significantly decreased microvascular compliance (from 0.15 ± 0.08 to 0.09 ± 0.04 ml/mmHg/100 ml; P = 0.001) whereas propofol-remifentanil did not (from 0.15 ± 0.08 to 0.16 ± 0.11 ml/mmHg/100 ml; P = 0.39). Available online http://ccforum.com/supplements/11/S2 We studied 20 healthy subjects; 10 males and 10 females (mean age = 38 ± 18 years, range 21-74 years). Both µHbO 2 and flow measurements were consistently higher when measured from the deep tissue layers (6 mm) than those measured from the superficial layers, regardless of the site of measurement. Buccal mucosal µHbO 2 ranged from 78% to 96% and varied only minimally (CV: 4-7.5%), whereas there was a marked variability in flow measurements (CV: 29-63.9%). The reproducibility of buccal mucosal µHbO 2 and flow measurements were moderate to good (that is, intra-individual reliability, ICC: range 0.7-0.87, P < 0.05). However, only measurements from the superficial mucosal layers showed a moderate to good degree of inter-individual agreement (that is, inter-individual reliability, ICC: range 0.68-85, P < 0.001). LDF and VLS values measured on the thenar eminence were highly variable, were not reproducible, and the inter-individual agreement was poor. Conclusion O 2 C ® provides reliable measurement of buccal µHbO 2 and microvascular flow. Skin measurements on the thenar eminence are highly variable and unreliable. We found a statistically significant correlation of both inspiratory and expiratory IVC diameter with central venous pressure (P = 0.004 and P = 0.001), extravascular lung water index (P = 0.001 and P < 0.001), intrathoracic blood volume index (P = 0.026 and P = 0.05), the intrathoracic thermal volume (both P < 0.001), and the paO 2 /FiO 2 oxygenation index (P = 0.007 and P = 0.008, respectively). Conclusions Sonographic determination of the IVC diameter is useful in the assessment of volume status in mechanically ventilated septic patients. This approach is rapidly available, noninvasive, inexpensive, easy to learn and applicable in almost any clinical situation without doing harm. IVC sonography may contribute to a faster, more goal-oriented optimization of fluid status and may help to identify patients in whom deleterious volume expansion should be avoided. It remains to be elucidated whether this approach influences the outcome of septic patients. The comparison of the CIpc immediately before calibration and the calibration-derived CItd resulted in a correlation coefficient of 0.84 with a P value of 0.02. In the Bland-Altman analysis the CIpc was a mean 0.14 l/min/m 2 lower than the CItd. The standard deviation was 0.72 l/min/m 2 . There was no correlation of the timelag between the calibrations and the difference of CIpc and CItd (r = -0.03; P = 0.13). Conclusion The PiCCO system allows a reliable continuous measurement of the cardiac index using the pulse contour analysis. In our study we could not find an increased difference of CIpc and CItd even with longer time periods between the calibrations using transpulmonary thermodilution. Because calibration is easy to achieve and additional data for the intrathoracic blood volume and the extravascular lung water are obtained, a 12-hour period between the calibrations is reasonable. The precision has been looked into previously and strategies to improve it have been made (that is, averaging three or four measurements over the respiratory cycle) yet not much is known about the precision of transpulmonary techniques in terms of repeatability. This study aims to look into the coefficient of variation (CV) of the lithium dilution technique in a mixed (medical/surgical) intensive care population and propose a method to improve its precision. Conclusions When considering ScvO 2 as a surrogate measure of perfusion adequacy, it is mandatory to consider the relative effect of hypoxemia. Anemia was less relevant in our case mix. Introduction Increasing oxygen delivery in high-risk surgical patients led to a dramatic reduction in both mortality and morbidity. Yet, it is still not widely practised due to logistical difficulties associated with its use. We aimed to evaluate whether pulse power analysis calibrated by the lithium dilution technique, a pragmatic minimally invasive technique, can be used to optimize the oxygen delivery index (DO 2 I) in high-risk patients during major surgery. Methods Lithium indicator dilution and pulse power analysis were used to measure cardiac output and to calculate DO 2 I (LiDCOplus system). We prospectively evaluated the oxygen delivery pattern and perfusion variables of 26 high-risk patients (LiDCO group) submitted to major surgeries and goal-directed therapy during surgery and 8 hours postoperatively, aiming to maximize the DO 2 I to levels higher than 600 ml/min/m 2 using dobutamine and either 'restrictive' (4 ml/kg/min) or 'liberal' (12 ml/kg/min) strategies of intraoperative fluid management (partial results). Postoperatively both groups received 1.5 ml/kg/min lactated ringer. Fluid challenge with 250 ml colloid was done in the presence of signs of hypovolemia and additional fluids were given if necessary. Patients were considered responders if they achieved the therapeutic goal. A historical group of 42 high-risk surgical patients in whom the therapeutic goals were to keep a mean arterial pressure between 80 and 110 mmHg, a central venous pressure between 6 and 12 cmH 2 O, hematocrit > 30% and urine output > 0.5 ml/kg/hour in the first 24 hours after ICU admission was used as control.  The mean baseline FTc was 278 ms, and the mean target FTc was 405 ms. The mean average blood loss was 3.77 l/patient. The mean preoperative urea and creatinine were 5.9 mmol/l and 95.3mmol/l, respectively. The mean 24-hour postoperative urea and creatinine were 5.23 mmol/l and 76.77 mmol/l, respectively. See Figure 1 . Conclusion Goal-directed intraoperative fluid therapy aiming for FTc of 375-425 ms as a target improved the 24-hour Available online http://ccforum.com/supplements/11/S2 Results From September 2006 to December 2006, 10 patients, weighing 70 (64-93) kg, were included in the study. Cooling was initiated 14 (7-20) minutes after ROSC. The cooling-blanket decreased the T es from 36.5 (36.2-36.7)°C at the start of cooling to 34.0°C within 61 (47-93) minutes, and to target temperature T es 33°C within 83 (61-119) minutes, resulting in a cooling rate of 2.6 (1.6-3.6)°C/hour. Hospital admission was 45 (40-53) minutes after ROSC, and T es 33°C was achieved 78 (32-107) minutes after admission. In eight patients, precooled parts of the coolingblanket had to be applied repeatedly on the chest and abdomen to maintain the target temperature of T es 33°C for 24 hours. No skin lesions were observed. Conclusion Noninvasive surface cooling with the EMCOOLSpad ® immediately after resuscitation from cardiac arrest, in the out-ofhospital setting, was shown to be feasible and safe. Whether early cooling, as compared with delayed cooling in the hospital, will improve neurological outcome needs to be determined in a prospective randomized trial. The induction time for whole body cooling was significantly shorter than that for selective head cooling. The rewarming time for head cooling was significantly shorter than that for whole body cooling. The mean arterial pressure and heart rate were both stable in the head cooling group. The urinary 8-hydroxy-2-deoxyguanosine concentrations decreased significantly in both groups, but data were significantly lower in the whole body cooling group compared with the selective head cooling group. Five and seven patients, respectively, exhibited good recovery 28 days after admission, in the whole body and selective head cooling groups. Conclusions Mild brain hypothermia therapy suppressed the production of free radicals following global brain ischemia. Whole body cooling had a stronger effect of suppression of free radicals compare with selective head cooling. It is considered that selective head cooling exhibits neuroprotection similar to whole body cooling. The average temperature at admission did not differ in both groups (35.5 ± 0.9°C vs 35.89 ± 0.8°C). In the group with initial cooling by means of 4°C cold infusions, a significant temperature decrease could be reached during the invasive coronary diagnostics to admission to the ICU of an average 0.84°C (35.88 ± 0.9°C vs 35.04 ± 0.9°C, P < 0.0001). The middle chill duration up to the achievement of the target temperature after admission was significantly shorter with the combined method (341 ± 113 min versus 553 ± 342 min, P < 0.01). The period to the achievement of the target temperature after the beginning of the external cooling device with the group of the combined method was significantly shorter (163 ± 91 min versus 342 ± 258 min, P < 0.01). Conclusions The combined method with initial cooling with 4°C cold solutions shows a sure and actual prestationary cooling procedure to the introduction or realisation of mild hypothermia and offers the possibility to reach the purpose temperature significantly faster. Preclinical introduction of mild hypothermia by means of 4°C cold solutions could be a beneficial criteria in the future treatment, and probably affects the outcome of these patients. Introduction Therapeutic hypothermia (TH) following cardiac arrest is associated with several complications including symptomatic bradycardia, coagulopathy, and pneumonia [1] . Furthermore, hyperthermia is associated with poor outcome following brain injury. The incidence of these complications may be increased by excessive temperature fluctuations. We sought to compare complications between two techniques used to induce TH; surface cooling (SC) using ice packs, and endovascular cooling (EV), using the Coolgard™ system (Alsius Corp., USA). Methods A retrospective review was performed of all cardiac arrest patients undergoing TH and surviving ≥48 hours between June 2005 and November 2006. Results Thirty-five patients underwent our TH protocol (SC group = 21, EV group = 14). The incidence of overcooling (<32°C) in the SC group was significantly higher than the EV group (10 vs 1, P = 0.01), whilst a trend towards more episodes of symptomatic bradycardia (SC 9 vs EV 2, P = 0.07) and rebound hyperthermia (SC 9 vs EV 2, P = 0.07) was also present. The incidence of pneumonia (SC 7 vs EV 4, P = 0.77) and coagulopathy/bleeding (SC 2 vs EV 3, P = 0.32) were similar between groups. Conclusions (1) SC is associated with a significantly higher incidence of overcooling than EC and may be associated with an increase in complications such as symptomatic bradycardia. (2) SC may also be associated with an increase in rebound hyperthermia. Introduction Hypothermia may be therapeutically beneficial in stroke victims; however, it provokes vigorous shivering. Buspirone, a partial serotonin 1A antagonist, and dexmedetomidine, an α 2 agonist, linearly reduce the shivering threshold (triggering core temperature) with minimal sedation and respiratory depression. We tested the hypothesis that buspirone and dexmedetomidine synergistically reduce the shivering threshold without producing substantial sedation or respiratory depression. Methods We studied four healthy male volunteers (18-40) on 4 days: (1) control (no drug); (2) buspirone only (60 mg orally); (3) dexmedetomidine only (target plasma concentration 0.6 ng/ml); and (4) combined buspirone and dexmedetomidine in the same doses. Lactated Ringer's solution (3°C) was infused via a central venous catheter to decrease tympanic membrane temperature by ≈2.2°C/hour; the mean skin temperature was maintained at 31°C. An increase in oxygen consumption more than 25% of baseline identified the shivering threshold. Sedation was evaluated using the Observer's Assessment Sedation/Alertness scale. Two-way repeated-measures analysis of variance was used to identify interactions between drugs. Data are presented as means ± SDs; P < 0.05 was statistically significant. The shivering thresholds were 36.4 ± 0.5°C on the control day; 34.9 ± 0.6°C (P < 0.01 from control) on the buspirone only day; 36.1 ± 0.6°C (P < 0.01 from control) on the dexmedetomidine only day; and 34.2 ± 0.5°C (P < 0.01 from control) on the combined buspirone and dexmedetomidine day. The calculated mean difference between the thresholds on the combined and the control days was 1.9 ± 0.4°C, while the measured mean difference derived from the difference between the combined and control days was 2.3 ± 0.4°C. There was only trivial sedation with either drug alone or in combination. The respiratory rate and end-tidal PCO 2 were well preserved on all days. Conclusion Buspirone and dexmedetomidine act synergistically to reduce the shivering threshold with only mild sedation and no respiratory depression. This combination might be a valid treatment to prevent shivering in stroke patients during therapeutic hypothermia. Introduction Recently, the medical treatment in acute stroke has been making rapid progress. Especially, in the ischemic stroke of acute stage, the efficacy of thrombolysis, systemic t-PA or local transarterial urokinase infusion has been proved. However, the effective treatment time is still quite limited. The patients must be brought to the stroke center as soon as possible. We analyzed the reason why most stroke patients delay coming to the stroke center. We extracted the problems and proposed some solutions. Of the trauma patients directly transferred to our center, 48% were transferred to the 'affiliated hospitals', whose medical staffs were dispatched from the 'departments' in our university, 17% were transferred to the nonaffiliated hospitals, and 34% were directly discharged from our center. Of emergency disease patients, 28% were transferred to the affiliated hospitals, 20% were transferred to other hospitals, and 52% were directly discharged. Patients staying in our center for more than 14 days tended to be transferred to the affiliated hospital. Of trauma patients indirectly transferred from other hospital to our center, 30% and 11% were transferred to the affiliated and nonaffiliated hospitals, and 19% were directly discharged. Of emergency disease patients, these values were 21%, 7%, and 13%, respectively. Patients staying in our center for more than 14 days tended to be transferred to the affiliated hospital. Discussion and conclusion These results are thought to be a common situation in a typical urban city in the world. Now, the interhospital cooperation between city hospital and referral hospital does not function well because of poor understanding of retransfer to the previous hospital, resulting in dysfunction of the management of critical patients in the local medical area. It is important to construct a new interhospital-cooperation system based on the local medical area. The mortality in patients (n = 1,031) with normal PH and ED blood pressure was 5.4%. The mortality in patients (n = 80) with PH and ED hypotension was significantly higher at 45% (P < 0.0001, chi-square test) (Table 1) . We identified 48 patients, 24 for each group. The groups were comparable regarding all the considered parameters except for GCS at admission (group 1, 8.63 ± 5.12; group 2, 12.2 ± 3.99; P = 0.01) and TRISS (group 1, 62.04 ± 34.55%; group 2, 82.37 ± 18.60%; P = 0.01). We observed in group 2 a significant decrease of mortality (5 vs 0; P = 0.02), incidence of ALI-ARDS (13 vs 4; P = 0.01) and pneumonia (18 vs 6; P = 0.01), a decrease of SOFA score (mean SOFA score: 7.58 ± 4.11 vs 3.97 ± 2.39, P < 0.001; maximum SOFA score: 9.83 ± 4.36 vs 5.62 ± 2.97, P < 0.001; days with SOFA >6: 3.79 ± 3.08 vs 2.16 ± 2.18, P = 0.04). Results ARF occurred more frequently in patients with great vessel disease than in those with coronary/valve disease (33.5% vs 11.2%, P < 0.05). The prognosis of patients with ARF was poorer than those without ARF in both groups (Figure 1 ). Patients with ARF showed a longer operation time, larger intraoperative bleeding and a higher level of blood lactate on admission to the ICU than those without ARF. Patients with ARF showed higher incidence of liver dysfunction, and needed a longer mechanical ventilation and ICU stay. Conclusion ARF is common after cardiovascular surgery, especially after surgery for great vessel disease. ARF was associated with more postoperative organ disorders. were included in a retrospective observational study. The incidence of postoperative renal dysfunction was compared in patients given aprotin, tranexamic acid or no antifibrinolytic agent, using propensity-adjusted multivariable logistic regression. Further analysis was performed comparing patients taking ACE inhibitors preoperatively with those not taking ACE inhibitors. Renal dysfunction was defined as creatinine higher than 200 µmol/l and/or renal dialysis. Patients with a previous history of renal dysfunction were excluded from the study. Results Using propensity-adjusted multivariable logistic regression (C-index, 0.82), the use of aprotinin in patients taking ACE inhibitors was associated with more than doubling the risk of acute postoperative renal failure in patients undergoing nonemergency cardiac surgery (odds ratio 2.64; confidence interval 1.32-5.27). Tranexamic acid was also associated with a significant increase in the risk of renal failure (odds ratio 1.59; confidence interval 1.09-2.31) in patients taking ACE inhibitors. However, in this study, there was no association between either aprotinin (odds ratio 1.01) or tranexamic acid (odds ratio 1.19) and postoperative renal failure in patients not taking ACE inhibitors. Conclusion In cardiac surgery, there is a significant association between use of the antifibrinolytic drugs aprotinin and tranexamic Available online http://ccforum.com/supplements/11/S2 Conclusions ICG-PDR < 5% is a significant predictor of irreversible liver failure. It is a good complement of such scores for decision-making. Introduction Desferrioxamine (DFX) is a clinically approved iron chelator used to treat iron overload. It has also shown beneficial effects in experimental acute liver failure (ALF) by inhibiting oxidative damage [1] . Lung dysfunction commonly complicates ALF. Ironmediated processes have been shown to contribute to it [2] . We hypothesized that inhibition of oxidative reactions by means of iron chelation could attenuate lung injury after ischemic ALF. This study aimed to analyse the incidence of relative adrenal insufficiency (RAI) in these patients, to identify factors associated with relative adrenal insufficiency and to describe how adrenal responsiveness affects outcome. Methods In a prospective observational multicenter study, a short Synacthen test (SST) was performed within 5 days after admission to the hospital in 25 patients with severe acute pancreatitis, after signed informed consent was obtained. The incidence of RAI, defined as an increment after SST of less than 9 µg/dl, was the primary endpoint of the study. Serum cortisol was measured at baseline and 30 and 60 minutes after 250 µg adrenocorticotropic hormone administration. The median baseline cortisol level was 26.6 µg/dl, and increased to 43.2 µg/dl and 48.8 µg/dl after 30 and 60 minutes, respectively. RAI was found in 16% of all patients, and in 27% of patients with organ dysfunction. Patients with RAI were more severely ill and had higher SOFA scores from day 4 through day 7 after admission. All patients with RAI developed pancreatic necrosis, and all of them needed surgical intervention. Mortality was significantly higher in patients with RAI (75% vs 10%, P = 0.016). Patients who died had a lower increment in cortisol levels after the SST than patients who survived. Conclusion RAI is frequent in patients with severe acute pancreatitis and organ dysfunction. It occurs in patients with more severe pancreatitis and is associated with an increased mortality rate. The maximal pain intensity was significantly higher on POD 1 and 2 (3.7 ± 2 and 3.9 ± 1.9, respectively) and lower on POD 3 (3.2 ± 1.5). The order of overall pain scores among activities (P < 0.001) from highest to lowest was coughing, moving or turning in bed, getting up, deep breathing or using the incentive spirometer, and resting. After chest tubes were discontinued, patients had lower pain levels at rest (P = 0.01), with coughing (P = 0.05). Age and sex was found to have an impact on pain intensity, with patients <60 years old and male patients having a higher pain intensity than older patients on POD 2 (4.  The final tool comprised five categories (three levels of severity each) allowing for a range of scores from 0 to 15 ( Figure 1 ). Three levels of urgency were defined: semi-urgent (score <8), urgent (score 8-10), immediate (score >10). Overall the tool showed a good to very good strength of inter-rater agreement (kappa scores ranging from 0.65 to 0.88; Figure 2 ). There were no obvious differences between levels of staff seniority. The mortality in the blunt trauma patients (n = 527) was higher in the ambulance transport group, but this was not statistically significant. However, the mortality in the penetrating trauma patients (n = 808) was significantly higher in the ambulance transport group (P = 0.020, chi-square; Table 1 ) despite similar Revised Trauma Scores (Table 1) . Of 108 units in the analysis, 79 (73%) had a formal CCOS introduced between 1996 and 2004. For admissions from the ward, the presence of a CCOS was associated with significant reductions in: the proportion of admissions receiving cardiopulmonary resuscitation during the 24 hours prior to admission (odds ratio 0.84, 95% confidence interval 0.73-0.96); the proportion of admissions between 22:00 and 06:59 (0.91, 0.84-0.97); and the mean ICNARC physiology score (absolute reduction 1.2, 0.3-2.1). No significant effects of CCOS on outcomes including hospital mortality and readmission to critical care were identified for patients discharged to the ward. Interpretation The results of this study were mixed. While some differences in the characteristics of patients admitted to critical care units were found to be associated with the introduction of CCOS, there was no evidence for an impact on the outcomes of patients discharged from critical care. It was not possible to identify any clear characteristics for an optimal CCOS. Introduction Blood groups may be related to differences in inflammatory responses [1] . We looked at blood group as a risk factor for ICU mortality in general and for patients with sepsis. Methods Data were retrospectively collected from all 11,553 patients that were admitted from 1997 to 2005 to our medical/ surgical ICU. Results ICU mortality and SAPS II score for different blood groups are shown in Table 1 . P values are given for the difference between blood groups A and O. No differences were found for age, gender, and reason for admission. No influence of rhesus blood group type was seen on mortality.  The CIG on day 1 predicted mortality (P = 0.001, analysis of variance). A CIG > 10 mmol/l correlated very strongly with mortality. The mortality in patients with a CIG < 10 mmol/l (n = 86) was 4.7%. The mortality in patients with a CIG > 10 mmol/l (n = 23) was 26.1% (P = 0.006, chi-square test). There were no differences in CIG with respect to mortality on admission or day 2 (P = 0.273 and 0.104, respectively). The mean hospital stay was significantly longer in patients with a CIG > 10 mmol/l (46.6 vs 18.7 days, P = 0.015, t test) ( Table 1) . Conclusion We describe the CIG for the first time in the critically ill surgical patient, and quantify it using simple bedside calculations derived from routine blood investigations. Failure to normalise the CIG by day 1 after admission to the HDU is an excellent marker for mortality and length of hospital stay, and should be used to guide resuscitation.  Six hundred and forty-three patients enrolled. The overall mortality rate was 11.51%. The new model predicted accurately 99% of survivors and more than 60% of nonsurvivors. Conclusion The 'multiscore' model seems to refine prognosis. This is partly due to mixing of new evaluated parameters. Testing the latest developed generations of scores and also organ dysfunction systems could be interesting. We included 100 patients (62 males), mean age 60.9 years. Of these admissions, 45 were elective surgical, 22 emergency surgical, 33 medical. The median Sequential Organ Failure Assessment (SOFA) score on admission was 4.50 (IQR 4). The median maximum SOFA score was 5.00 (IQR 5). The median length of ICU stay was 3.0 days (IQR 3). The overall ICU mortality rate was 14.0%. For patients with a maximum SOFA score ≤8, mortality was 5.1% -vs 45.5% for those whose maximum SOFA score was >8 (P < 0.001). Sixty-four per cent of patients scored their maximum SOFA score on admission. In patients whose SOFA score increased after admission, the mortality was 24.3%. Logistic regression analysis showed the maximum SOFA score bore a stronger correlation with mortality than admission SOFA score. See Figure 1 . Conclusion Maximum and admission SOFA scores are of prognostic value in the intensive care setting; allowing patients with increased risk of mortality and prolonged stay to be identified. like India, and is associated with significant mortality. The outcome of malarial MODS predicted in various studies is extremely variable and dependent on many patient parameters. Objective We prospectively evaluated the correlation of the APACHE II score, parasite index, procalcitonin (PCT) levels, number of organ dysfunctions/failures and Sequential Organ Failure Assessment (SOFA) score with the outcome of severe malaria. Methods Eleven patients with acute severe malaria with MODS were treated in our ICU in the last 5 months. All these patients were treated with artesunate and/or quinine as per the WHO antimalarial treatment schedule, along with standard ICU care. The APACHE II and SOFA scores were calculated on admission. PCT levels were measured semiquantitatively on admission. The parasite index was confirmed by two pathologists. Results Nine out of 11 patients survived without any residual organ damage, and the remaining two died due to MODS (Figure 1 ). Both these patients had five organ dysfunctions on admission, and their SOFA scores were 18 and 20, respectively. They had a low parasitic index of 1% and 2.5% and their PCT levels were 0.5-2 and >10 (semiquantitative method), respectively. Their APACHE II scores were 16 and 10. Conclusion The pretreatment APACHE II score, parasite index, PCT levels and number of organs involved have variable correlation with mortality and are not consistent predictors of outcome. A higher SOFA score on admission is a more reliable predictor of mortality in malarial MODS. One hundred and seventy-six patients were studied (71 males (56%), median age 51 (IQR 36-67) years, 78 (44%) with severe sepsis, median length of ICU stay 10 days (IQR 7-16), median admission SOFA 6 (IQR 4-9), median APACHE II score 19 (IQR 13-26), ICU mortality 27.84% (49/176 patients)). The SOFA score and its components scores along the five admission days distinguished the survivors from the nonsurvivors. Considering the SOFA score and its respiratory, neurologic and circulatory components, survivors presented lower scores as the days passed (P < 0.001). Mortality was increasingly higher for those patients who persisted with a SOFA score ≥ 7 as the days passed. Conclusion In the sample studied, the persistence of an elevated SOFA score and its components during the first 5 days of admission predicted a higher mortality. Survival appears to be related to early organ dysfunction recovery. The SOFA score and SOFA-related variables' day-to-day changes in a population of septic patients may have an important prognostic implication and some patterns of daily evolution may distinguish those patients with a more ominous outcome. The mean absolute difference with the measured tacrolimus blood concentration in the predicted regression model was 2.34 ng/ml (SD 2.51). Linear SVM and RBF SVM prediction models had mean absolute differences with the measured tacrolimus blood concentration of, respectively, 2.20 ng/ml (SD 2.55) and 2.07 ng/ml (SD 2.16). These differences were within an acceptable clinical range. Statistical analysis demonstrated significant better performance of linear (P < 0.001) and nonlinear (P = 0.002) SVM ( Figure 1 ) in comparison with linear regression. Moreover, the nonlinear RBF SVM required only seven data components to perform this prediction, compared with 10 and 12 Available online http://ccforum.com/supplements/11/S2 S189 increase in APACHE II score, delay to ICU readmission, need of mechanical ventilation and three or more organ dysfunctions were significantly associated with mortality. Conclusions Admission to the ICU is common in lung transplant recipients, and it is associated with a high mortality. Sepsis is the main cause of ICU readmission and the most frequent cause of death. Lung transplant recipients with higher APACHE II score and three or more organ dysfunction present higher mortality. The delay on ICU readmission is also associated with higher mortality.  Of 200 plans, 130 were successful, for three plans data were missing and 67 (34%) plans were unsuccessful. Of unsuccessful plans, 36 were completed late, 22 were never completed and nine had missing data. Thirty-six per cent, 34% and 18% of arbitrarily defined high-priority, medium-priority and lowpriority plans were unsuccessful. Most plans were to be actioned by nurse or senior house officer, and 36% and 28% were unsuccessful, respectively. More unsuccessful plans than successful plans were recorded in the computerised notes, 79% vs 67%. Only 40% of data (staff opinions) on perceptions of causes and consequences were gathered. Patient consequences of failed plans included increased ICU stay in 24%, increased morbidity such as risk of inadequate nutrition in 9%, delayed definitive treatment in 7%, delayed weaning in 6%, increased risk of infection in 5% and no impact on patient in 44%. Consequences for family included no impact in 53%, misinformation given in 8%, delayed patient access in 2%, and delayed communication in 2%. Service consequences were bed blocking/increased workload in 20%, delayed admission of another patient in 14%, cancelled elective operations in 4%, and loss of unit capacity and cohesion in 7%. Conclusions We failed to achieve 100% successful plans. Small numbers and failure to gather more than 40% of staff opinions on causes and consequences of failed plans limit this pilot study. Documentation in (electronic) notes did not improve completion of plans. The process and efficiency of care has an impact on at least aspects of morbidity and length of stay, and deserve further study. Conclusion In octogenarians admitted in the ICU after OHCA, hospital mortality is higher than in the younger group but still an important proportion survives. Non-octogenarians survived more often than predicted by APACHE II. Despite the higher mortality, ICU treatment after out of hospital resuscitation of octogenarians seems worthwhile. In the academic hospital the average total costs per ICU day amounted to €1,775, compared with €1,703 in the general hospital. The distribution of the costs by cost component varied. The majority of data (77.5%) was collected with the manual system and the remaining 22.5% with an integration software. The mean admission data completeness ratio (CR) increased from 85.3% at 1998 to 97.9% at 2005 (P = 0.01). Between the ICUs, the mean CR varied from 91.6% to 99.6% (P = 0.01). The mean CR of the data collected with the IVT was 98.7% and with the manual system was 95.1% (P = 0.01). The rate of 100% complete records per patient was 48.7% and it increased from 0.0% in 1998 to 71% in 2005. Conclusion Data completeness in the FICQC has improved during the study period, although there is still significant variation between ICUs. Improved data completeness and decreased proportion of missing data are most likely due to the increasingly common use of CIS and automated data collection. We conclude that measuring/reporting the amount of missing data is mandatory when data collection and data management procedures for benchmarking are being developed. The heart was donated in 18 of 37 patients (49%). Lung donation was possible in only eight of 37 donors (22%). Most hearts and lungs were rejected for transplantation for valid reasons. In some patients there was room for improvement: in two of the three cases where hemodynamic instability impeded heart and lung donation (one dying from subarachnoidal bleeding and one from ischemic cerebral infarction), hemodynamic instability was closely associated with the moment of cerebral death. In three further patients heart donation was not carried out because of wall movement abnormality or electrocardiogram abnormalities. None of Available online http://ccforum.com/supplements/11/S2 Introduction Critical care research involves data from many countries, but critical care resources in these countries are unknown. We hypothesized that there are large differences in critical care resources between countries. Methods We identified original research articles on critical care in three high impact factor journals (N Engl J Med, JAMA and The Lancet) published from 2001 to 2005. A list of the countries where data collection occurred was extracted. Eight countries contributed to ≥10 studies. A collaborator in each country was asked to provide baseline critical care information for their country from 2005, or as close to that date as possible. Results Sixty-two studies involving data from 51 countries were identified. Eight countries contributed data to ≥10 studies during this time period: the USA (26 studies), France (18), the United Kingdom (14), Canada (13), Belgium (12), Germany (10), The Netherlands (10) and Spain (10). Relevant data on baseline hospital and critical care resources for the eight countries identified are presented in Figure 1 (data from Canada not available). Adult ICU beds ranged from 3.3/100,000 population in the United Kingdom to 24.6 in Germany, and represented a range of 1.4% of all acute care hospital beds in the United Kingdom to 11.0% of all beds in the USA. Conclusions Many countries contribute substantially to critical care research. However, the underlying critical care resources vary dramatically among these countries. Available online http://ccforum.com/supplements/11/S2 