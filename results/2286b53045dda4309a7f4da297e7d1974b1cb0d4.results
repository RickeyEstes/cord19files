Among 724 dermoscopy images, 71 images were from the hands and fingers, and the others were from the feet and toes. A total of 350 AM images included homogenous diffuse irregular pigmented, parallel ridge, and multicomponent patterns, while 374 BN images included parallel furrow, fibrillar, lattice-like, reticular, globular, and homogenous patterns (S1 Table) . In the group A results obtained by the training of Group B images, CNN showed 92.57% sensitivity and 75.39% specificity, which were similar to those of the expert (94.88% and 68.72%, respectively). However, the non-expert showed lower sensitivity (41.71%) and relatively higher specificity (91.28%, Table 2 ). For diagnostic accuracy, both the CNN and expert group showed similar scores (83.51% and 81.08%, respectively), which were higher than that of the non-expert (67.84%, Fig 5) . In the result of group B by the training of group A images, CNN also showed a higher diagnostic accuracy (80.23%) than that of the non-expert (62.71%) but was similar to that of the expert (81.64%). For validating diagnostic reliability, both the CNN and expert showed an AUC above 0.8 in group A and B (Fig 5) . However, the non-expert Regarding the concordance rate between the CNN and expert group, 73 cases (73/362, 20.17%) in Group A (AM: 14 cases, BN: 59 cases) were discordant. Of these, 41 cases (56.16%) of the CNN and 32 cases (43.84%) of the expert were identical with the pathologic results. However, in the concordant cases between them, 29 cases (29/362, 8.01%) differed from the pathology reports. In Group B, 57 cases (AM: 12 cases, BN: 45 cases) showed discordance between the CNN and expert, and 26 cases (45.61%) of the CNN and 31 cases (54.39%) of the expert were identical with the pathologic results. Among the concordant cases in group B, 39 cases (39/362, 10.77%) differed from the pathology results. Cohen's kappa between CNN and Expert, CNN and Non-expert, Expert and Non-expert is shown in Table 3 . To verify the performance of CNN architecture for the discrimination of acral melanoma, we perform the deep learning architecture, Inception-V3, in [13] , the state-of-the-art publication for the classification of skin cancer. In [13] , a single image was used for learning. Meanwhile, we applied multiple images for learning. Thus, we compared Inception-V3 with a single image and Inception-V3 with multiple images to CNN with multiple images. The results are shown in Table 4 . 