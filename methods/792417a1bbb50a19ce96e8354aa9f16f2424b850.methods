The study was carried out in a 525-bed tertiary-referral teaching hospital over a 14-year study period (1997 to 2010). All inpatients referred for PN via CVCs were included. Prospectively collected data were recorded in a specifi c PN record. The CRBSI audit group met quarterly to review all sepsis episodes, assigning a diagnostic category (CRBSI or non-CRBSI). Patient risk factors for development of CRBSI were examined using a logistic regression model to take account of the dichotomous nature of the outcome. Odds ratios from a model incorporating demographic and clinical data were tested for statistical signifi cance. Introduction Many patients develop infections following operations. Decreased immune competence has been demonstrated in acute neurological conditions. A strong cytokine-mediated antiinfl ammatory response was observed in stroke patients at infection, although infection due to the decreased proinfl ammatory mediators can be expected as well. To investigate this question the following experiment was performed. Methods Twenty-two urinary bladder cancer patients with radical cystectomy and lymphadenectomy were studied. Blood samples were taken on day 0 (before) and days 1, 3, 6, 9 and 14 after operation as well as on days 30, 60, 90 and 270 during follow-up. TNFα, soluble TNFα receptor I and IL-6 levels in sera were determined by HS ELISA and/or ELISA. Plasma ACTH and cortisol values were measured by RIA kits. Results From 22 patients, eight deep wound and urine infections were found in 14 days and six urine and wound infections in 30 days after surgery, all survived. All patients were bacterially contaminated, as wound samples taken at the end of operation demonstrated. On day 0 the circulating TNFα values were lower in infected patients. TNF started to increase from day 3 to day 9, never reaching values of the uneventful healing group. Soluble TNF receptor I, IL-6, ACTH, and cortisol concentrations did not demonstrate any diff erence on day 0 but from day 1 started to increase transiently, reaching higher levels in septic patients. Conclusion A low proinfl ammatory response is a key facilitating factor for the development of infection. Measuring serum TNFα levels before and after operations can thus predict the outcome. evaluation during 3 days in May 2012 including direct observation of hand hygiene compliance by control nurses and hand cultures of 50 healthcare workers (HCW). Based on the WHO Guidelines on Hand Hygiene in Health Care [1] , cleaning of hands with alcohol-based hand rubs (Sterillium) was prescribed before touching a patient and before aseptic procedures, after body fl uid exposure risk and after touching a patient and touching his/her surroundings. Promotion of the hand hygiene program consisted of lectures and web-based self-learning, posters located near points of care and verbal reminders by control nurses. New observations of hand hygiene by control nurses during 3 days and hand cultures of 50 healthcare providers were performed in September 2012. Consumption of alcohol-based hand rub (product volume use per patient-days) was used as a surrogate marker of hand hygiene over time. The diff erence in hand hygiene compliance during the two periods was examined using a chi-squared test. Diff erences in hand cultures were examined using a Student's t test. Time trends in the consumption of alcohol-based hand rub were examined using linear correlation. P <0.05 was considered statistically signifi cant. The study was approved by the institutional Ethics Review Board. Results During the survey, in May 158 opportunities to observe hand hygiene were presented and 286 in September. Overall compliance improved from 34.2% (54/158) to 51% (146/286), χ 2 = 11.7 (P <0.001). In May, 50 HCW had a mean of 63.20 ± 39.37 colony-forming units (CFU) on their hands compared with 43.0 ± 40.19 CFU on the hands of 50 HCW in September (P = 0.024). We also observed an initial increased use of alcohol-based hand rubs from 21 ml per patient-day in May to a maximum 72 ml per patient-day in June, but a decline to 44 ml per patient-day in September, Pearson correlation coeffi cient = 0.31 (P = 0.61). Conclusion Implementation of a new hand hygiene program at our ICU resulted in improved hand hygiene compliance and less CFU on the hands of HCW. There was no signifi cant increased use of alcohol-based hand rubs over time. The results indicate that constant awareness is vital for success. Reference Introduction ICU-acquired infection is directly related to hospital mortality. Hand hygiene is an eff ective, low-cost intervention that can prevent the spread of bacterial pathogens, including multidrugresistant organisms. Historical compliance with hand hygiene guidelines by physicians, nurses and other care providers is poor. Methods Present expectations by the Infection Control Committee are to 'pump in, pump out' of every room, using 63% isopropyl alcohol. We performed 17,622 observations of hand hygiene in the surgical ICU from March through October 2012, and intervened to change behavior by providing monthly feedback to specifi c provider groups and services. We made use of the Unit Coordinator to measure compliance of all individuals in the ICU. Results Overall compliance by physicians was 82.1%, for nonphysicians was 84.8%. Feedback to physicians, individually and by service, dramatically increased hand hygiene compliance, defi ned as both on entry and exit from the patient room, over the study period. See Figure 1 . Conclusion Physician behavior is responsive to monthly feedback that is specifi c to the individual or surgical service. Use of the Unit Coordinator was very eff ective at gathering a very large sample size in a short period of time. Introduction The Benefi ts of Universal Glove and Gowning (BUGG) study is a cluster-randomized trial to evaluate the use of wearing gloves and gowns for all patient contact in the ICU. The primary outcome is VRE and MRSA acquisitions; secondary outcomes include frequency of healthcare worker visits, infection rates, hand hygiene compliance and adverse events. Methods We enrolled 20 ICUs in 15 states. ICUs collected nasal and perianal swabs on all patients at admission and discharge/transfer. After a 3-month baseline period, 10 units were randomized to the intervention arm and required to wear gloves and gowns for all patient contact. An intervention toolkit was created based on site feedback and compliance reports. Swab collection compliance was fed back and discussed during site conference calls on a weekly basis. Site coordinators monitored compliance with gloves and gowns, hand hygiene and frequency of HCW visits and reviewed patient charts for adverse events. Results During the 12-month study period, 100,210 swabs were collected. After the baseline period, we were able to achieve and maintain swab compliance rates between 85 and 97%. Monthly discharge compliance increased by 21% by the beginning of the intervention period ( Figure 1 ). Observers found 86% compliance with universal glove and gowning over 1,242 30-minute observation periods ( Figure 1 ). Ninety charts at each site were reviewed for adverse events. Conclusion Over a diverse group of US hospitals, we achieved high compliance with surveillance cultures and implementing universal gloving and gowning was achieved quickly with high compliance. Introduction Sepsis accounts for a very high mortality. The Surviving Sepsis Campaign recommends a fi rst 6 hours resuscitative bundle to improve patient outcome. Despite this, the bundle is poorly performed because of several organizational and cultural barriers. In recognition of this, we guess that an Educational and Organizational Intervention out of the ICUs could impact on septic patient outcome. In order to test our hypothesis we carried out, in 12 hospitals, a pre-intervention survey of the human and organizational resources (HOR) available in the management of septic patients. The aim is to seek any barrier potentially aff ecting correct Guidelines implementation. Methods Thirty-nine medical wards (MW) and 12 emergency departments (ED) were enrolled. Every unit was asked to fi ll in a pre-agreed HOR Checklist focused on the main requirements suggested by the Guidelines. Results Analysing the human resources available, we see that the bedto-doctor ratio signifi cantly (P <0.01) increases from the day to the night shift: from 6 to 43 beds per doctor on the MW (median). Otherwise, the ED staff remains roughly the same: from 3.5 to 2.5 doctors on duty (median). The analysis of the organizational tools (Table 1 ) points out a low percentage of hospitals having: a Diagnostic and Therapeutic Protocol for sepsis management (8.3%), some Hospital Empirical Antibiotic Therapy Guidelines (0%) and an Infective Source Eradication Protocol (8.3%). Moreover, just 25% of hospitals involve an infectious diseases expert in every case of severe sepsis or septic shock. Conclusion We guess that the poor availability of HOR showed by the hospitals could have a role in the Guidelines implementation and in the patient's outcome. Only a comparison between these results and data collected from a Clinical Checklist, focused on sepsis bundle compliance, and from a patient's outcome summary could confi rm our hypothesis. This is the aim for our next part of the study. Reference Introduction The incidence of patients carrying ESBL-positive bacteria in our ICU (12 in 780 admissions in 2011) was not considered problematic. However, routine cultures had identifi ed ESBL-negative patients who had become colonized with ESBL strains during their ICU stay. Self-disinfecting siphons, preventing bacterial growth by antibacterial coating and intermittent heating, and biofi lm formation by electromechanical vibration, were placed in all sinks in the ICU. The aim of the present study was to evaluate the eff ect of this intervention. Methods An intervention study in a 12-bed ICU. The intervention involved placement of 19 self-disinfecting siphons (Biorec). All patients with an expected ICU stay of 2 days or more between January 2011 and December 2012 were studied. Samples of throat, sputum and rectum were taken at admission and twice weekly, and cultured for ESBLs. Between June 2011 and October 2011, sinks in patient rooms were cultured regularly for ESBLs. After the intervention in April 2012, multiple repeat cultures were taken. Whenever the species and antibiogram of bacteria cultured from patients and sinks matched, they were typed by AFLP. Results Before intervention Multiple ESBL-forming strains were found in sinks of all patient rooms. Eighteen patients who were ESBL-negative on ICU admission became colonized with 11 diff erent ESBL strains, that were present in sinks of their admission rooms ( Figure 1 ). Four contaminations were proven by AFLP-tying. One patient died of ESBLpositive E. cloacae pneumonia. After intervention All sinks were negative for ESBL strains. No further patients became ESBL colonized during the ICU stay. Conclusion Wastewater sinks were the likely source of ESBL colonization for 18 ICU patients. After placing self-disinfecting siphons Introduction The present study investigated the eff ects of a single dose of intraperitoneal (i.p.) IgG and IgGAM administration on various behavioral alterations in a cecal ligation perforation (CLP)-induced sepsis model in rats. Methods Female Wistar albino rats (200 to 250 g) were divided into fi ve groups (n = 8): a naive Control group, a Sham operated group receiving conventional antibiotic treatment, a CLP group receiving CLP procedure and conventional antibiotic treatment, and IgG and IgGAM groups which were also applied 1 g/kg, i.p. IgG and IGAM therapy 5 minutes after the CLP procedure. Ten, 30 and 60 days after the surgery, animals underwent three behavioral tasks: an open fi eld test to evaluate the locomotor activity, an elevated plus maze test to measure the level of anxiety, and a forced swim test to assess the possible depressive state. The results acquired from these tests were used to estimate the eff ect of immunoglobulin therapy on behavioral changes in CLP-induced sepsis in rats. We developed a simulation model to determine clinical costs and outcomes attributable to AAD. To assess the cost-eff ectiveness of probiotics, as part of a perioperative regime, we constructed a decision Critical Care 2013, Volume 17 Suppl 2 http://ccforum.com/supplements/17/S2 S30 tree. The model observes long-term costs and outcomes of probiotics as compared with conventional therapy, from a societal perspective. Input parameters, extracted from meta-analysis, clinical trials and national databases, include incidence numbers, costs and qualityadjusted health states for the remaining life (QALYs). Outcomes assessed were overall costs attributable to ADD and the cost-eff ectiveness of probiotics, described as costs/QALY. Introduction Low tidal volume (VT) ventilation in intensive care patients without lung injury attenuates the systemic infl ammatory response [1] . The contribution of the specifi c organ infl ammatory responses to the systemic picture remains to be elucidated. We investigated the eff ect of low VT ventilation compared with medium high VT on hepatic, splanchnic and cerebral cytokine responses in an experimental large animal postoperative sepsis model. Methods Twenty pigs, group Protective Ventilation (PV), were ventilated with low VT (6 ml/kg) and PEEP 10 cmH 2 O while 10 pigs, group Control (C), were ventilated with a VT of 10 ml/kg and PEEP 5 cmH 2 O. Catheters were introduced into an artery, the jugular bulb, the hepatic vein and the portal vein. Laparotomy for 2 hours simulated a surgical procedure after which baseline ensued and a continuous endotoxin infusion was started at 0.25 μg/kg/hour for 5 hours. Diff erences were analyzed with ANOVA for repeated measures. Results TNFα levels were higher in the hepatic vein than in the artery, the jugular bulb and the portal vein. IL-6 levels were higher in the artery and the jugular bulb compared with the portal and hepatic veins. IL-10 levels were higher in the portal vein compared with the jugular bulb and hepatic vein. The organ-specifi c IL-10 concentrations were all higher than the arterial concentration. Comparison between the ventilation groups showed that TNFα, IL-6 and IL-10 in the hepatic vein were higher in group C compared with group PV at the end of the experiment. Peak concentrations of TNFα and IL-6 in the portal vein were higher in group C compared with group PV. In this experiment TNFα was mainly generated in the  liver while the results point to signifi cant nonhepatic IL-6 and IL-10 production. Ventilation with low VT and medium-high PEEP attenuated hepatic and splanchnic cytokine production compared with mediumhigh VT and lower PEEP. Reference Introduction Airway pressure release ventilation (APRV) allows spontaneous breathing throughout the ventilation cycle. It increases venous return and cardiac index, which will signifi cantly improve organ perfusion. This is important in septic shock patients to prevent extrathoracic organ system failure secondary to poor perfusion. Benefi ts of APRV with cardiovascular changes are noticed in patients with acute lung injury and acute respiratory distress syndrome. It is not well established whether applying APRV will improve the survival outcome for septic shock patients. The primary outcome is whether the use of APRV in septic shock patients restores hemodynamic stability earlier than the CMV mode. The secondary hypothesis is whether the use of APRV in septic shock patients improves their survival in the ICU. Methods After Institutional Review Board approval, we retrospectively analyzed the clinical data of 129 septic shock patients who received ventilator support between January and December 2011 at a tertiary care hospital. The Cox proportional hazards model was used in adjusting potential confounding factors. The nonparametric Wilcoxon rank sum test was used to assess signifi cant outcome diff erences between groups. Time to event/survival data will be analyzed using Kaplan-Meier methods. These analyses were accomplished using SAS, version 9.3. Results Among the 187 patients, 58 were excluded as per the exclusion criteria: incomplete data (n = 28), do not resuscitate (n = 16), ICU readmission (n = 12) and head injury (n = 4). Finally, 129 patients were included, from these 91 received CMV and 38 received APRV. At the beginning of the study, there were no diff erences between the groups in relation to hemodynamic parameters. Reversal of shock achieved in less than 72 hours was statistically signifi cant between the groups (APRV, n = 16 (42%) and CMV, n = 8 (9%), P = 0.0101). The proportion of patients recovering from septic shock after initiation of ventilator therapy was higher in APRV than the CMV group (72% vs. 49%, respectively, P <0.0001). The mortality rate was signifi cantly higher in CMV (n = 46, 51%) as compared with APRV (n = 11, 29%) (P = 0.022). Introduction aPTT is a common tool for anticoagulation monitor ing during extracorporeal membrane oxygenation (ECMO). Thromboelasto graphy (TEG) is another available option in this setting. Methods A prospective observational study on 12 consecutive patients during venovenous ECMO. Anticoagulation was provided Critical Care 2013, Volume 17 Suppl 2 http://ccforum.com/supplements/17/S2 S47 with unfractioned heparin titrated to an aPTT ratio target of 1.5 to 2. Kaolin-activated TEG (K-TEG) was contemporarily measured but did not guide heparin infusion. Baseline K-TEG reaction time (R) >20 minutes is accepted for anticoagulation but when it exceeds 90 minutes anticoagulation may be too great [1] . Results Mean ECMO duration was 9 ± 4 days. A total of 152 K-TEGs were collected. Comparison between aPTT and K-TEG R is reported in Table 1 . Four patients (33%) had hemorrhagic complications. Neither aPTT nor K-TEG R were signifi cantly diff erent in patients with hemorrhagic events compared with patients without hemorrhagic events but the latter received a signifi cantly lower total heparin dose (P = 0.0097). Conclusion Anticoagulation was excessive in more than one-half of the samples according to TEG monitoring, while negligible based on aPTT. Reference Introduction The usefulness of extracorporeal membrane oxygenation (ECMO) is being rediscovered in the wake of the pandemic of H1N1 infl uenza. However, it has been reported that patients who received ECMO often developed virus-associated hemophagocytic syndrome (VAHS), compared with those without ECMO support. Although there is ample evidence that extensive cytokine activation is a key factor in VAHS, ECMO itself could be a potential trigger to exacerbate the pathology by amplifying cytokine activation. In this study, we investigated whether mediators such as cytokines may be produced by ECMO. Methods Patients with severe respiratory failure who were placed on ECMO were enrolled between June and July 2012. This study was approved by the ethics committee. Blood specimens were drawn from the blood circuit at the inlet of the centrifugal pump (before) and outlet of the hollow fi ber oxygenator (after) at a frequency of three to four times per day. Blood IL-1β, IL-2, IL-4, IL-5, IL-6, IL-7, IL-8, IL-10, IL-12(p70), IL-13, IL-17, G-CSF, GM-CSF, IFNγ, MCP-1, MIP-1β, and TNFα were measured globally using a multiplex cytokine bead array system (Bio-Plex; Bio-Rad, Tokyo, Japan). HMGB1 was measured using an ELISA kit (Shino-Test, Tokyo, Japan). Results Two patients with interstitial pneumonia were studied. The ECMO system consisted of a Rotafl ow Centrifugal Pump (Maquet Japan, Tokyo, Japan), a Biocube TNC coating 6000 (NIPRO, Osaka, Japan), and a percutaneous cardiopulmonary support system (Capiox EBS; Terumo, Tokyo, Japan). The blood fl ow rate was 2.0 ± 4.0 l/minute. A total of 34 blood sets were collected. In most cases, blood levels of IL-1β, IL-2, IL-4, IL-5, IL-12(p70), IL-13, IL-17, GM-CSF, IFNγ, and TNFα were below the detection limit and did not increase during ECMO. The other mediators were detected at the inlet (before), but no signifi cant increase was observed at the outlet (after) (HMGB1, P = 0.33; IL-6, P = 0.12; IL-7, P = Introduction During severe exacerbation of chronic obstructive pulmonary disease (COPD) tachypnea, as a consequence of respiratory acidosis, and airfl ow limitation, due to small airway obstruction, lead to lung hyperinfl ation, respiratory distress and gas exchange impairment. Invasive mechanical ventilation could worsen lung hyperinfl ation and produce a vicious circle. We investigated whether increasing extracorporeal carbon dioxide removal (ECCO 2 Cl) could reduce the respiratory rate (RR), so prolonging time for lung emptying and allowing resolution of hyperinfl ation. Methods Six patients with COPD exacerbation with respiratory acidosis (PaCO 2 83 ± 27 mmHg, pH 7.19 ± 0.1) and tachypnea (RR 39 ± 5) despite maximal non-invasive ventilation underwent venovenous extracorporeal membrane oxygenation (VV-ECMO). All patients were awake and spontaneously breathing an adequate air-oxygen mixture to correct hypoxemia (PaO 2 72 ± 27 mmHg). While keeping the blood fl ow stable (2.9 ± 0.5 l/minute), we changed the gas fl ow of the artifi cial lung to modify the extracorporeal CO 2 clearance as a percentage of total patient CO 2 production (% ECCO 2 Cl/total VCO 2 ) and we observed the variations of RR. We recorded RR at three levels of gas fl ow in each patient ( Figure 1) . We conducted a preliminary prospective study. We included septic shock patients hemodynamically optimized according to international recommendations. A microdialysis catheter was inserted in the femoral quadriceps. Interstitial fl uid samples were collected every 6 hours for 5 days. The determination of muscular glucose was performed by the CMA 600 analyzer (CMA/Microdialysis AB, Sweden). We also performed a dosage of concomitant blood glucose. The study population was divided into two groups according to hospital mortality. Statistic analysis: Mann-Whitney test and chi-squared test: comparisons between groups. Quantitative variables were expressed as mean ± standard deviation or median (interquartile range) as appropriate. Results We included 12 patients with septic shock. The mortality rate was 50%. Demographics were comparable between groups except for age (66 ± 9 vs. 41 ± 12, dead patients vs. survivors, respectively; P = 0.002). Pneumonia was the major cause of septic shock (10 patients). We analysed 167 blood samples and 166 muscular glucose samples. We found a positive association between muscular glucose, blood glucose and mortality. Tissue glucose was signifi cantly higher among dead patients compared with survivors at the 54th hour. Comparing all data, muscular glucose (P = 0.02) and blood glucose (P = 0.007) were signifi cantly higher in dead patients (Table 1) . Conclusion Our data suggest that muscular glucose assessed by microdialysis and blood glucose are associated with mortality in septic shock patients. Therefore, muscular glucose may refl ect the metabolic alterations and microcirculatory dysfunction induced by septic shock. Methods The audit had the Trust Audit Committee's approval. The existing protocol was used as the benchmark. Patients were studied prospectively to assess compliance with the local bowel protocol, incidence of constipation and relationship to weaning from respiratory support and feeding. All HDU and all mechanically ventilated ICU patients who stayed on the ward for more than 3 days were included, except for patients after bowel surgery and patients with encephalopathy. This was an open, single-centre, prospective, nonrandomized clinical trial at a university hospital. All patients that needed prophylactic dosing of enoxaparine after cardiac surgery were duly informed and after giving written consent we included 44 patients with a mean Euroscore of 1.66. The demographic specifi cations, medical and surgical history of all patients were collected. Anti-Xa activity was measured at three diff erent points in time. We determined baseline, peak and trough anti-Xa activity: preoperatively, and respectively 4 hours after the third dose of enoxaparine and 30 minutes before the fourth dose. Each measurement was done with both techniques, the two-stage chromogenic assay at the laboratory (Biophen®) and the bedside assay (Hemochron® Jr). Results Our dose regimen of enoxaparine achieved in one-half of the included patients a suffi cient anti-Xa activity for prevention of thromboembolic events. One-half of the patients with insuffi cient anti-Xa activity had a body mass index over 30 kg/m 2 . Comparison of the bedside assay with the two-stage chromogenic assay by means of the Pearson's correlation coeffi cient showed correlation of the two tests if no variables were taken into account. In the Bland-Altman analysis we could not confi rm this correlation. Conclusion The bedside anti-Xa activity assay with a Hemochron device tends to show some correlation with the two-stage chromogenic assay, but insuffi cient to be used as an alternative, in this small but uniform patient population. Use of a standard dosing protocol for enoxaparine administration is prone for underdosage in post-cardiac surgery patients and may increase postoperative morbidity. References Introduction We hypothesized that higher doses of enoxaparin would improve thromboprophylaxis without increasing the risk of bleeding. Critically ill patients are predisposed to venous thromboembolism, leading to increased risk of adverse outcome [1] . Peak anti-factor Xa (anti-Xa) levels of 0.1 to 0.4 IU/ml, 4 hours post administration of enoxaparin, refl ect adequate thromboprophylaxis for medico-surgical patients. Methods The sample population consisted of 78 patients, randomized to receive subcutaneous (s.c.) enoxaparin: 40 mg ×1 (control group), versus 30 mg ×2, 40 mg ×2 or 1 mg/kg ×1 (test groups) for a period of 3 days. Anti-Xa activity was measured at baseline, and at 4, 12, 16 and 24 hours post administration on each day. Patients did not diff er signifi cantly between groups. Results On day 1 of administration, doses of 40 mg ×1 and 40 mg ×2 yielded similar mean peak anti-Xa of 0.20 IU/ml and 0.17 IU/ml respectively, while a dose of 30 mg ×2 resulted in subtherapeutic levels of anti-Xa (0.08 IU/ml). Patients receiving 1 mg/kg enoxaparin achieved near-steady-state levels from day 1 with mean peak anti-Xa levels of 0.34 IU/ml. Steady-state anti-Xa was achieved for all doses of enoxaparin at day 3. At steady state, mean peak anti-Xa levels of 0.13 IU/ ml and 0.15 IU/ml were achieved with doses of 40 mg ×1 and 30 mg ×2 respectively. This increased signifi cantly to 0.33 IU/ml and 0.40 IU/ml for doses of 40 mg ×2 and 1 mg/kg enoxaparin respectively (P = 0.0000) (Figure 1) . A dose of 1 mg/kg enoxaparin yielded therapeutic anti-Xa levels for over 80% of the study period. There were no adverse eff ects. Introduction Unfractionated heparin is preferred over LMWH in ICU patients but LMWH is used more frequently in many European ICUs. Thromboprophylaxis with standard doses of nadroparin and enoxaparin has been shown to result in signifi cantly lower anti-Xa in ICU patients when compared with medical patients [1, 2] . Methods ICU patients (SAPS 44 ± 16, MV, n = 44; pressors n = 32) received 7,500 IU (Group 1, n = 25) or 5,000 IU dalteparin s.c. (Group 2, n = 29). Twenty-nine medical patients receiving 5,000 IU dalteparin served as controls (Group 3). Results Group 2 had signifi cantly lower areas under the Xa curve (AUC) compared with Groups 1 and 3 (Table 1) . Diff erences were not signifi cant between Groups 1 and 3. Peak anti-Xa activities (C max -anti-Xa) were delayed (t max -anti-Xa) in Group 2 compared with Groups 1 and 3 (Table 1) . Conclusion In ICU patients a s.c. dose of 5,000 IU dalteparin results in signifi cantly lower Xa activities when compared with normal ward patients. A s.c. dose of 7,500 IU dalteparin in ICU patients resulted in kinetics and peak anti-Xa activities comparable with medical patients receiving 5,000 IU dalteparin. The study was conducted in 44 patients with ANP, who were divided into two groups according to type of analgesia: epidural or opioids. Patients from the fi rst group (n = 23) had epidural analgesia by ropivacaine 6 to 14 mg/hour during 7 to 10 days, and from the second group (n = 21) opioid analgesia by trimeperidine 20 mg three times a day during the same period. We monitored the level of septic and thrombohemorrhagic complications by clinical and instrumental data, during the month after treatment starting. The hemostatic system was evaluated using indicators of hemoviscoelastography (Mednord-01M analyzer). Results It was found that all patients with ANP initially have hypercoagulation and fi brinolysis inhibition. Levels of hemostatic disorders correlate with the level of septic complications, treatment in the ICU, and mortality. In the fi rst group we noted a deep vein thrombosis, two pneumonia, seven pseudopancreatic cysts and abscesses, two deaths and time of stay in the ICU as 15.4 days. In the second group: three cases of deep vein thrombosis, four pneumonia, 10 pseudopancreatic cysts and abscesses, two episodes of gastroduodenal bleeding, fi ve deaths and time of stay in the ICU as 27.8 days. Conclusion Using epidural anesthesia in patients with ANP reduced the number of septic complications on 36.6%, and reduced the mortality rate from 23.8% (second group) to 8.7% (fi rst group). We think that violations of blood coagulation and microcirculation are the basis for ischemia, necrosis in tissues and septic complications. Epidural analgesia is an eff ective method to decrease the level of septic and thrombohemorrhagic complications and mortality in ANP patients. Methods After ethics approval and informed consent, we studied the functional state of hemostasis in a group of 57 healthy volunteers, who were not receiving drugs aff ecting coagulation, and 43 patients with postphlebothrombotic syndrome (PPTS). In the PPTS patients we conducted baseline studies of coagulation state and daily monitoring of dynamic changes in the functional state of hemostasis, a comparative evaluation of performance low-frequency piezoelectric vibration hemoviscoelastography (LPVH) and platelet aggregation test (PAT), standard coagulation tests (SCT), and thromboelastogram (TEG). We prospectively analyzed all patients to whom elective major orthopedic surgery was consecutively performed in a 2-month period. All the patients received FOND 2.5 mg in the postoperative period according to ACCP 2012 Guidelines. Native and heparinase (hep) TEG (Haemoscope Corporation, Niles, IL, USA) tests activated with kaolin were performed using whole blood citrated samples at four times: T0, before FOND administration; T1, 2 hours after administration; T2, 17 hours after administration (half-life); T3, 24 hours after administration. The following native and hep TEG parameters were analyzed: reaction time (R), α angle, maximum amplitude (MA) and coagulation index (CI). These parameters were compared with levels of anti-Xa. Unvariate analysis and Spearman's test were applied to our data. Results Eighteen patients were analyzed. Ten patients met the inclusion criteria. The mean R value increased from T1 to T3. The mean R parameter was in the normal range at any phase of the study and there was no signifi cant diff erences between the R mean value at the diff erent phases. The lowest value of R was at T1, which coincides with plasmatic peak concentration of FOND. This value did not correlate with anti-Xa mean value at T1, which showed the highest value at that time. There was signifi cant diff erence between the mean native and hep R value only at T2 (P <0.05), native and hep α angle at T3, MA and MA hep at T2 (P <0.01) and CI and CI hep at T3 (P <0.02). Only the parameter MA had signifi cant variation over time (P <0.02). Conclusion R represents the time necessary to thrombin formation and in the presence of FOND we hypothesized a prolonged R time. In our population, TEG performed with citrated kaolin-activated whole blood was not able to detect prophylatic doses of FOND in every phase. On the contrary, levels of anti-Xa were able to reveal the exact pharmacokinetics of the drug. Further studies including a large number of patients are necessary. Introduction Coagulopathy, particularly a trend toward hypercoagula bility and hypofi brinolysis, is common in critically ill patients and correlates with worse outcome. Available laboratory coagulation tests to assess fi brinolysis are expensive and time demanding. We investigated whether a modifi ed thromboelastography with the plasminogen activator urokinase (UKIF-TEG) [1] may be able to evaluate fi brinolysis in a population of critically ill patients. Methods UKIF-TEG was performed as follows: fi rst urokinase was added to citrate blood to give fi nal concentrations of 160 UI/ml, then thromboelastography (TEG) analysis was started after kaolin activation and recalcifi cation with calcium chloride. Basal TEG (no addition of urokinase) was also performed. Fibrinolysis was determined by the loss of clot strength after the maximal amplitude (MA), and recorded as Ly30 (percentage lysis at 30 minutes after MA) and as Ly60 (percentage lysis at 60 minutes after MA). Results UKIF-TEG was performed on 17 healthy volunteers and 18 critically ill patients. Ly60 was predicted by Ly30 according to an exponential function, so we used Ly30 as an indicator of clot lysis. Basal TEG showed increased coagulability and a trend toward less fi brinolysis in critically ill patients compared with healthy volunteers (reaction time 8.7 ± 3.4 minutes vs. 12.2 ± 1.9 minutes, P <0.001; α-angle 59.7 ± 9.4 vs. 47.2 ± 11.8, P <0.01). This reduction of fi brinolysis was more evident at a urokinase concentration of 160 UI/ml (Figure 1 ). Conclusion UKIF-TEG could be a feasible point-of-care method to evaluate fi brinolysis in critically ill patients. Methods We performed a randomized, double-blind study in 37 patients who underwent cesarean section. Patients were divided into two groups: the fi rst group (n = 19) received preoperative (30 minutes before operation) tranexamic acid 10 mg/kg; the second group (n = 18) received preoperative placebo. The condition of hemostasis was monitored by haemoviscoelastography. Results All patients included in the study before surgery had moderate hypercoagulation and normal fi brinolysis: increasing the intensity of clot formation (ICF) to 11.4% compared with normal rates; the intensity of the retraction and clot lysis (IRCL) was 16.45 ± 1.40 in both groups. At the start of the operation in patients (Group 1), ICF decreased by 9.7% (P <0.05), and IRCL decreased by 27.6% (P <0.05) compared with preoperatively. In Group 2, there was ICF decrease by 8.8% (P <0.05), and IRCL increase by 11.4% (P <0.05) compared with preoperatively. At the end of the operation, the condition of hemostasis in both groups came almost to the same value -moderate hypocoagulation, depressed fi brinolysis. In both groups there were no thrombotic complications. Intraoperative blood loss in the fi rst group was 300 ± 40.5 and in the second was 500 ± 60.6. Conclusion Using of tranexamic acid before surgery signifi cantly reduces intraoperative blood loss by 60%, without thrombotic complications. Introduction Rotational thromboelastography (ROTEM) can detect dilutive and hypothermic eff ects on coagulation and evaluate corrective treatments. The aim of this in vitro study was to study whether fi brinogen concentrate alone or combined with factor XIII could reverse colloid-induced and crystalloid-induced coagulopathies in the presence and absence of hypothermia. Methods Citrated venous blood from 10 healthy volunteers was diluted by 33% using 130/0.42 hydroxyethyl starch or Ringer's acetate. ROTEM was used to evaluate the eff ect of addition of either fi brinogen concentrate corresponding to 4 g/70 kg, or this fi brinogen dose combined with factor XIII equivalent to 20 IU/kg. Blood was analyzed at 33 or 37°C with ROTEM ExTEM and FibTEM reagents. Results A signifi cant dilutive response was shown in both groups: hypocoagulation was greater in the starch group. Hypothermia lengthened the following: ExTEM clotting time (CT), clot formation time and α angle; FibTEM maximal clot formation (MCF). Irrespective of temperature, fi brinogen overcorrected Ringer's acetate's eff ects on all ROTEM parameters and partially reversed starch's eff ects on ExTEM CT and FibTEM MCF. FibTEM demonstrated that factor XIII provided an additional procoagulative eff ect in the Ringer's acetate group at both temperatures but not the starch group. The only ExTEM parameter to be improved by addition of factor XIII was MCF at 33°C. Conclusion ROTEM shows that fi brinogen concentrate can reverse dilutive coagulation defects induced by colloid and crystalloid at both 33 and 37°C. Some additional reversal was provided by factor XIII: higher doses of both fi brinogen and factor XIII may counteract starch's eff ects on clot structure. Introduction Natural colloid albumin induces a lesser degree of dilutional coagulopathy than synthetic colloids. Fibrinogen concentrate has emerged as a promising strategy to treat coagulopathy, and factor XIII (FXIII) works synergistically with fi brinogen to correct coagulopathy following haemodilution with crystalloids. Objectives were to examine the ability of fi brinogen and FXIII concentrates to reverse albumininduced dilutional coagulopathy. High and low concentrations of both fi brinogen and FXIII were used to reverse coagulopathy induced by 1:1 dilution in vitro with 5% albumin of blood samples from healthy volunteers, monitored by rotational thromboelastometry (ROTEM). Results Haemodilution with albumin signifi cantly attenuated EXTEM maximum clot fi rmness (MCF), α angle (AA), clotting time (CT) and clot formation time (CFT), and FIBTEM MCF (P <0.001). Following haemodilution, both doses of fi brinogen signifi cantly corrected all ROTEM parameters (P ≤0.02), except the lower dose did not correct AA. Compared with the lower dose, the higher dose of fi brinogen signifi cantly improved FIBTEM MCF and EXTEM MCF, AA and CFT (P <0.001). The lower dose of FXIII did not signifi cantly correct any of the ROTEM parameters, and the high dose only improved EXTEM CT (P = 0.004). All combinations of high/low concentrations of fi brinogen/ FXIII signifi cantly improved all ROTEM parameters examined (P ≤0.001). Fibrinogen concentration generally had a greater eff ect on each parameter than did FXIII concentration; the best correction of ROTEM parameters was achieved with high-dose fi brinogen concentrate and either low-dose or high-dose FXIII. Conclusion Fibrinogen concentrate successfully corrected initiation, propagation and clot fi rmness defi cits induced by haemodilution with albumin, and FXIII synergistically improved fi brin-based clot strength. Results IOCS was used in 70 severe PPHs and 254 severe PPH controls were managed without IOCS. Placenta accreta can be selected as the best indication for RBC restitution. In the 1,500 to 3,000 ml PPH, allogeneic transfusion was decreased in the IOCS group: 17.6 versus 56.3% (P = 0.006); PRBC: 0 (0 to 3) versus 3 (0 to 6) (P = 0.045). IOCS spared 87 blood bank PRBC (17,374 ml); that is, 24.2% of the total transfusion need. No amniotic fl uid embolism has been observed in the group with IOCS whereas one case appeared in the control group without IOCS. Conclusion Regarding the literature [1] [2] [3] [4] and our study, IOCS could be used safely in PPH during CS. A leukocyte fi lter for retransfusion has been recommended and Rhesus isoimmunization must be precluded and monitored by repeated fetal RBC testing. bleeding with the use of a protamine infusion and an abolishment of heparin rebound [1] . The aim of this study was to see whether the use of postoperative protamine infusions in our cardiac ITU was associated with a reduction in heparin rebound and blood loss. Methods Data from 240 cardiac surgery patients were retrospectively analysed. Of these, 157 had routine management with a bolus of protamine to correct the activated clotting time and then expectant management of subsequent bleeding, and 47 had the same but also a protamine infusion of 10 to 80 mg/hour for between 3 and 8 hours postoperatively. Blood loss was measured at 1, 6, 12 and 24 hours. In all, excessive bleeding was investigated using thromboelastography (TEG). Rebound heparinisation was determined by a ratio of R-times (heparinase/plain) <0.8. The Mann-Whitney U test and the chi-squared test were used to assess statistical signifi cance. Results There was no signifi cant diff erence in blood loss between the two groups. Blood loss at 1 hour in the infusion and non-infusion group was 145 and 88 ml, respectively (P = 0.06); at 6 hours: 450 and 392 ml (P = 0.5); at 12 hours: 620 and 595 ml (P = 0.62); and at 24 hours: 971 and 872 ml (P = 0.12). There was also no signifi cant diff erence in those getting heparin rebound with 40% in the infusion group and 47% in the non-infusion group (P = 0.54). Conclusion Unlike Teoh and colleagues [1] , we did not fi nd an advantage in using protamine infusions. That there were still cases of heparin rebound in the infusion group suggests that the infusion was not as eff ective as expected and/or the dose was inadequate. However, previous studies assessed heparin rebound using isolated clotting parameters [1, 2] . Here, we used TEG. As TEG measures the thrombodynamic properties of whole blood coagulation, perhaps it is a more reliable indicator of heparin activity? As a retrospective study, there are limitations; namely, the nonstandardised management of the patients and the potential bias in the anaesthetists' selection of patients for an infusion. This group may be inherently higher risk for bleeding. However, heparin rebound is common and protamine is a simple, relatively safe and low-cost intervention compared with transfusion and so further study is needed. Introduction The objective of this study is to investigate the eff ect of intraoperative administration of dexamethasone versus placebo on the incidence of delirium in the fi rst four postoperative days after cardiac surgery. Methods Within the context of the large multicenter Dexamethasone for Cardiac Surgery (DECS) trial [1] for which patients were randomized to 1 mg/kg dexamethasone or placebo at induction of anesthesia, a monocenter substudy was conducted. The primary outcome of this study was the incidence of delirium in the fi rst four postoperative days. Secondary outcomes were duration of delirium, use of restrictive measures and sedative, antipsychotic and analgesic requirements. Delirium was assessed daily by trained research personnel, using the Richmond Agitation Sedation Scale and the Confusion Assessment Method. Medical, nursing and medication charts were evaluated for signs of delirium and use of prespecifi ed medication. Analysis was by intention to treat. Results Of 768 eligible patients, complete data on delirium could be collected in 738 patients. The incidence of delirium was 14.2% in the dexamethasone group and 14.9% in the placebo group (odds ratio = 0.95, 95% CI = 0.63 to 1.43). No signifi cant diff erence was found on the duration of delirium between the intervention (median = 2 days, interquartile range 1 to 3 days) and placebo (median = 2 days, interquartile range 1 to 2 days) group (P = 0.45). The use of restrictive measures and administration of sedatives, haloperidol, benzodiazepine and opiates were comparable between both groups. Conclusion Intraoperative injection of dexamethasone seems not to aff ect the incidence or duration of delirium in the fi rst 4 days after cardiac surgery, suggesting this regimen is safe to use in the operative setting with respect to psychiatric adverse events. Reference Introduction The beliefs, knowledge and practices regarding ICU delirium among ICU professionals may vary. This may interfere with the implementation of the Dutch ICU Delirium guideline. We aimed to get insight into potential barriers and facilitators for delirium guideline implementation that may help to fi nd an eff ective implementation strategy. Methods An online survey was sent to healthcare professionals from the six participating ICUs. Respondents included ICU physicians, nurses and delirium experts (psychiatrists, neurologists, geriatricians, nurse experts). The survey consisted of statements on beliefs, knowledge and practices towards ICU delirium. Agreement with statements by more than 75% of respondents were regarded as facilitating items and agreement lower than 50% as barriers for implementing protocolled care. We conducted a retrospective cohort study in eight ICUs of a tertiary academic center. We constructed a robust clustered linear regression model of daily fl uid balance and all-cause hospital mortality among 595 critically ill patients receiving CRRT. We adjusted the model for the Charlson comorbidity score, the daily SOFA scores in the fi rst week after initiation of CRRT as well the type of ICU. Results After adjusting for the type of ICU and the daily severity of illness, patients who died had on average 779 ml higher daily fl uid balance compared with patients who survived (P <0.001, 95% CI = 385 to 1,173 ml, Figure 1 ). Severity of illness predicted daily fl uid accumulation; each additional point of the SOFA score predicted an additional 57 ml of extra daily fl uid (P = 0.002). balance and intradialytic hypotension with mortality and recovery of renal function. Methods We conducted a retrospective cohort study among patients aged ≥16 years who had RRT initiated and continued for ≥2 days in a level 2 or 3 ICU at two academic centres, and had fl uid balance data available. Patients with end-stage kidney disease, within 1 year of a renal transplant or who had RRT initiated to treat a toxic ingestion were excluded. We used multivariable logistic regression to determine the relationship between mean daily fl uid balance over the fi rst 7 days following RRT initiation and the outcomes of mortality and RRT dependence in survivors. Introduction Acute kidney injury (AKI) is a common complication of critical illness and sepsis [1] . Dosing of antibacterial agents in septic patients is complicated by altered pharmacokinetics due to both acute renal failure and critical illness [2] . Current dosing regimens for administration of gentamicin and vancomycin to septic patients with AKI on continuous venovenous hemofi ltration (CVVH) at a fi ltration rate of 45 ml/kg/hour are missing. The ICU of the Triemli City Hospital in Zurich has an interdisciplinary organisation with surgical and internal medical patients, with a maximum occupancy of 18 beds and a centre function for the surrounding hospitals of the region. In this prospective ongoing observational study, we collect and analyse the anonymised data of all patients admitted to our ICU from an external hospital during 12 months prior to (1 January to 31 December 2011) and after (1 January to 31 December 2012) the introduction of the DRG in Switzerland. Exclusion criteria are admissions by the emergency department, self-assignments into the hospital and internal relocations. The primary endpoint is the number of admissions from an external hospital to our ICU. Secondary endpoints are the severity of the disease of the admitted patients, detected by the scoring systems SAPS II and APACHE II as well as the length of stay in external hospitals before admission. The statistical analysis is descriptive. Results We present the preliminary data for 10 months (in each case January to October) before and after the introduction of the DRG. We observed an increase of 9.2% (391 vs. 427 patients) of admissions to our ICU after the introduction of the DRG. The severity of disease determined by the SAPS II score is unchanged (mean 26.7 vs. 26.0 points, P = 0.466). The severity of disease determined by the APACHE II score is signifi cantly lower (15.4 vs. 14 points, P = 0.017). We also noted that after the introduction of the DRG the patients were earlier transferred from an external hospital to our ICU (mean time until transfer 29.9 vs. 18.7 hours), but this value was not signifi cant (P = 0.55). Conclusion Up to now the introduction of the DRG in Switzerland has had a complex infl uence on the number and the kind of patients (LWP, n = 300); and patients whose waiting time was equal to or less than that period, short waiting period (SWP, n = 113). Results In total, 413 patients were included, 300 of which belonged to the LWP group (65.4%). For the entire cohort, the mean APACHE II score was 19 ± 7, the mean age was 52 ± 22 years, and 211 patients were male (51.1%). The LWP group did not show diff erence in the APACHE II score (19 ± 7 vs. 18 ± 8, P = 0.13), but was older (55 ± 20 vs. 49 ± 23, P = 0.01). LWP also had a higher incidence of primary bloodstream infection (23.8% vs. 10.4%, P = 0.01) and catheter-associated urinary tract infection (10.2% vs. 1.9%, P = 0.01). LWP patients had higher mortality (37.8% vs. 25.9%, P = 0.02) and longer ICU LOS (21 ± 47 vs. 14 ± 18 days, P = 0.01). Relative risk for death in the LWP was 1.74 (95% CI: 1.11 to 2.72). Conclusion Despite showing no signifi cant diff erences on APACHE II scores from the SWP group, patients from the LWP group presented greater incidence of primary bloodstream infection, catheterassociated urinary tract infection, higher mortality outcomes and longer ICU LOS. References We selected a convenience sample of seven large cities with varying geographical and socioeconomic characteristics: Boston, Paris, Bogota, Recife, Liaocheng, Chennai, and Kumasi. To estimate acute care supply, we developed an instrument to collect data on acute and critical care infrastructure. We collected data from municipal authorities and local research collaborators. We expressed the burden of acute disease as the number of deaths due to acute illnesses, estimated from the 2008 Global Burden of Disease Study. Results were expressed as acute care supply and acute deaths per 100,000 population and acute care supply per 100 acute deaths. 