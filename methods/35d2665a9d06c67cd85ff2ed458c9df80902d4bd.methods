Motivation, justification and overview. Our goal is to estimate the location and nature of host-associated selection upon the pathogen genome sequence through statistical analysis of association between host factor and pathogen genomic variation. We desire our method to have four properties: the ability to use all available pathogen sequence data, irrespective of whether host factors have been measured; the ability to measure the evidence for selection across the genome analysed in a hypothesis-free manner; the ability to combine information across neighbouring positions where appropriate; and the ability to account for confounding factors such as recombination and population structure. To meet these requirements we have developed a Bayesian model-based approach in which we use an approximation to the coalescent with recombination and codon-level selection 42 . In extension to the earlier work, we enable host-specific factors to influence patterns of variation and consider the case of two data sets. The first, D, represents the collection of pathogen sequences for which host factor data (e.g., HLA genotype or drug treatment) is also available. The second, D B , represents a much larger data sets of pathogen sequences for which host factor data is not available. We use D B to model the set of potential pathogen sequences that a host can be infected with (allowing for recombination) and assume that genetic differences between this reference panel and D largely reflects evolution within the host. Thus host-induced selection will result in an association between host factors and the evolutionary changes observed in D. A cartoon of the underlying process and our model is shown in Fig. 1 . The justification of the approach is that if jD B j ( jDj then members of D will typically coalesce very recently and approximately independently with members of D B . Thus the prior on D can be modelled with the Li and Stephens imperfect mosaic hidden Markov model (HMM), utilising a modified NY98 codon model 44 . To incorporate host-induced selection, we define a consensus codon C i at site i and model selection as a scaled increase in the rate of non-synonymous change away from C i . Conversely, we model reversion as a scaled increase in the codon substitution rate towards C i . To obtain emission probabilities we integrate over the distribution of coalescent time between a member of D and D B assuming a coalescent model. The HMM formulation enables efficient computation of the probability of observing a given sequence in D given current parameter values. The product over all members of D is used to approximate the joint probability P DjD B ; H; Θ ð Þ , where H is host factor data for members of D and Θ represents the parameters of recombination and codon substitution. To speed up computation, we a priori identify a subset of D B for each member of D that is used to model its ancestor. The model parameters we aim to infer are: the synonymous transition rate, μ, the dN dS ratio at each site, ω i , the recombination probabilities between neighbouring sites, r i , the rate of reversion ζ i , and the host factor dependent scaling of escape rate at each NATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-019-10724-w ARTICLE NATURE COMMUNICATIONS | (2019) 10:3017 | https://doi.org/10.1038/s41467-019-10724-w | www.nature.com/naturecommunications site, γ h;i . We impose a piecewise constant prior on γ h to enable rapid exploration of γ h;i and regularisation of the inference. While motivated by the size distribution of epitopes, the piecewise constant prior is extremely flexible, for example encompassing a small number of discrete sites with high selection parameters. Other parameters (transition-transversion rate and fraction of codon substitutions more than one nucleotide change away) are estimated from external data. We use Markov chain Monte Carlo (MCMC) to sample from the posterior distribution for all parameters (See Supplementary Methods for details and MCMC moves). To guard against overfitting, we use shrinkage priors on the dN dS ratio and host factor associated selection coefficients. Similarly, the window structure on γ h borrows information across neighbouring sites, further guarding against overfitting in the absence of signal 42 . Statistical and computational details. In order to calculate the likelihood of the collection of parameters, Θ, governing an evolutionary model, given a collection of sequence data D, it is important to account for the non-independence of samples by considering the underlying genealogy G. For our purposes, we are not interested in estimating G. We, therefore, treat the genealogy as a nuisance parameter and integrate over it Here, P(G) is our prior on the genealogy G. PðDjΘ; GÞ is the probability of the data under some parameter values Θ and genealogy G, which can be evaluated using Felsenstein's peeling algorithm 45 . Since the space of genealogies is very large, evaluating this integral is problematic. However, without recombination it is possible to estimate using a numerical summation approximation, as employed by BEAST 46 and MrBayes 47 , for example. However, analysis is limited to hundreds or thousands of sequences depending on the properties of the analysed sequences. In the presence of recombination, G becomes an ancestral recombination graph and so the state space of G becomes far larger, making it impossible to use this approach in all but the simplest of models, and only for very small sequence data sets. The solution that we use is to estimate the integral using an approximation to the coalescent with recombination 41 . The model we present has two components: 1. An approximation of the coalescent with recombination. 2. A model of codon substitution. By combining these two components, we are able to approximate the probability of observing a given sequence in the presence of host factor dependent selection, and recombination. We make the assumption that each pathogen sequence is from a distinct individual. In practice, when applying the model to real data, we perform a number of data filtering steps to ensure this assumption is reasonable. We use the Li and Stephens imperfect mosaic HMM to approximate the coalescent with recombination. In the Supplementary Methods we describe the Li and Stephens model and the use of the forwards and backwards algorithms in evaluating likelihoods under this approximation. In our inference problem we have two data sets. One query data set; D for which we have associated host factor information and another larger reference data set; D B without host factor information. Recall from our model summary that we make two important assumptions: 1. All selection along the lineages connecting a member of D to D B occurred within the host of the member of D. 2. The reference data set D B is a good approximation of the distribution of pathogens an individual can be infected with (which is reasonable when jD B j ) 0). These two assumptions allow us to apply the Li and Stephens approximation. In the Li and Stephen's HMM we require emission probabilities. For our model these will be probabilities of codon substitutions in the presence of some host factor. Making assumption 1 allows us to approximate PðDjD B ; ΘÞ. This is because we have host factor information for the members of D ¼ D 1 ; D 2 ; ; D n f g which we can use to determine the relevant emission probabilities. I.e., The first assumption allows us to use the sequence data in D B : Using assumption 2, we may write  Here,π is the function describing the Li and Stephens approximation (described in the Supplementary Methods) with our model of recombination and codon evolution. In other words, assumption 2 results in the approximation that D is generated by independent realisations of recombination and mutation through D B . This avoids any need for averaging over orderings of D, allowing rapid evaluation of the approximate likelihood. Throughout the remainder of the Methods section we will refer to HLAassociated selection, but note that the method is general and extends to any host factor associated selection on pathogen sequence. Codon model of substitution. We use a codon model of substitution model to describe sequence change. Importantly for our purposes, a codon model allows us to detect selection through non-synonymous nucleotide changes. At each site we are interested in detecting if these types of nucleotide changes away from some wild-type consensus sequence are enriched in a particular HLA background. We first write down the Nielsen and Yang (NY98) codon model (without HLAassociated selection) 44 and then extend it to incorporate the HLA types of the host transmitted to (a given member of D). This will allow us to infer HLA-dependent selection along the pathogen sequence. Note that in Eqs. (5)-(24) we consider codon substitutions at a single site (and drop any site subscript). However, when we perform inference we will allow our codon model to be parameterised by distinct collections of parameters at each site. In the NY98 codon model 44 , the substitution rate from codon i to codon j is  where κ is the relative rate of transitions to transversions and ω is the ratio of nonsynonymous base changes to synonymous base changes assuming equal codon usage. The original model 44 weighted by the frequency of the codon switched to at that position to ensure reversibility. This is not a requirement for us. In fact, the process we want to model is not reversible, as we will include a boost in movement away from the consensus codon in the presence of a given HLA, and assume a distinct boost towards consensus independent of HLA (to model reversion). Finally μ is the scaled mutation rate parameter for the rate of synonymous transversions measured in units of N generations (where N is the effective population size). We note that while the original model was used to model fixed substitutions within species, here (as in many cases) the model is actually of how sequence diversity is generated within a population sample. The exact probability of a substitution from codon i to codon j in time t cannot be solved analytically, though we may estimate it by numerically evaluating the matrix exponential of the 64 × 64 instantaneous rate matrix described by Eq. (5) 42 . This is computationally expensive so we look for an approximation. If the expected time until the first coalescence of a given lineage with all other sampled lineages t, is small (reasonable if the number of sampled sequences in D B is very large), we can assume that the vast majority of codon changes occur through single-base changes (as the probability of observing more than one nucleotide change in a codon is low). This allows us to avoid matrix exponentiation and reduce computational cost. Consider a switch from codon C 1 to codon C 2 . The total rate of substitution out of codon C 1 is where β S , β V , α S and α V are the counts of the number of synonymous transitions, synonymous transversions, non-synonymous transitions, and non-synonymous transversions from C 1 , respectively. If the overall movement away from a particular codon C 1 is Λμ, then the probability a change has occurred in time t is Here, Θ is the collection of parameters governing codon substitution. We can make an approximation by splitting up PðC 1 ! C 2 jΘ; tÞ. We consider two classes of moves from C 1 ! C 2 : those which result from a single nucleotide change in time t (e.g., AAA → AAG) and those that result from multiple nucleotide changes in time t (e.g., AAA → ATA → AAA → AAG). For C 1 ≠ C 2 , PðC 1 ! C 2 ji changes; tÞPði changesjΘ; tÞ ð8Þ PðC 1 ! C 2 jleave C 1 ; i changes; tÞ Pði changesjΘ; tÞ where ϕ is the probability of undergoing a 1 step change from C 1 to C 2 and π C 2 is the probability of observing codon C 2 at that position in the sequence. Thus, for each codon C 1 , we generate the following collection of probabilities for state changes at each site 1 step non-synonymous transition 1 step synonymous transition 1 step non-synonymous transversion 1 step synonymous transversion ! 2 step change if C 1 ≠ C 2 , and No change in codon at the site 1 À ðð12Þ þ þ ð16ÞÞ ¼ ð17Þ if C 1 ¼ C 2 . We estimate π C (for each codon C) and ϕ empirically using the Durban data set [48] [49] [50] . Codon model of substitution: adding HLA-associated selection. In order to account for HLA-associated selection we may choose to incorporate transmission and HLA proportions in the same way as the existing models 17, 18 . Alternatively, we can consider a simpler model in which we are only concerned with the HLA type (h, say) of the sampled host in the smaller population. We explore the latter approach. For movement away from the consensus codon C at a given site, Λ is modified to Λ ′ in the presence of HLA type h So, as an example, for a non-synonymous transition from the consensus (which is predefined, in practice, we set it as either the consensus subtype B, or subtype C codon at the position) codon C to C 2 , explicitly writing down the HLA dependence and using the approximation from Eqs. (13)-(17) γ h is a scaling of the non-synonymous/synonymous substitution ratio ω associated with HLA type h, away from C. This weighting provides extra selection away from the consensus codon C if γ h > 1 and less if γ h < 1 to create a new total rate of movement out of the consensus codon C in the presence of HLA type h, Λ′. Thus an association between a particular HLA type and non-synonymous change from consensus at the site would result in γ h > 1. Notice that no selection is applied to synonymous codon changes. Extending to an HLA profile of a host H ¼ fh 1 ; h 2 ; ; h n g We also wish to incorporate reversion into our codon model. Given the state of the codon under consideration, there is some set of nucleotide substitutions resulting in C at that position. It is these substitutions which we wish to scale through reversion parameters. We let ζ denote the scaling of selection due to reversion at a particular site. We assume that each ζ is independent of the host's HLA profile, H. By doing so, we are assuming that in the absence of HLA pressure there is a selection towards the consensus codon C at each site. Note that reversion only acts on non-synonymous changes that result in the consensus codon C. Consequently, the parameterisation is identifiable and we are able to distinguish ω i and ζ i in the product ω i ζ i . Consider the case in which a non-synonymous transition results in the consensus codon, C, from some codon C 1 . Then Λ is modified to Λ′: Reversion is therefore modelled by ζ is a scaling of the non-synonymous/synonymous substitution ratio ω towards C. This weighting provides extra selection towards the consensus codon C if ζ > 1 and less if ζ < 1. We assume that the same ζ scales all the potential 1 step nonsynonymous base changes to C. We have now created a codon model which accounts for reversion and HLAassociated selection within a host, and can now determine emission probabilities; ε j;i . We define ε j;i as the probability of copying the codon at position i from sequence j (see Supplementary Methods for background details). Therefore, by evaluating which is the probability that a change from codon C 1 to C 2 has occurred in the time to coalescence with the reference set, we can substitute in the relevant codon change (C 1 ! C 2 ) and determine ε j;i . We integrate out t assuming the coalescent with fixed population size. In the standard coalescent with a fixed population size, the distribution of the divergence time between a sequence and its closest relative from among k other sequences may be approximated by an exponential distribution with rate k 2 PðtÞ ¼ k 2 exp À k 2 t À Á À Á 42 (see Supplementary Notes for a derivation of the mean). This is simply a case of substituting in and integrating. For example, for a nonsynonymous transition from the consensus, Notice that in evaluating this integral we are focused on sequence evolution between a member of D and its nearest neighbour in D B . Only considering nearest neighbours in the genealogy has two clear advantages: 1. We only use the parts of the genealogy that contain the most information about HLA-dependent selection within a sampled host: terminal branches. 2. The resulting reduction in computation time allows us to use far more sequence data. Using more sequence data will shorten terminal branches and so increase our power to detect HLA-associated selection. Using very large data sets is important for our method. As terminal branches shorten through increased sampling, assumption 1 (that selection occurs in the member of D along the lineage connecting each member of D to its nearest neighbour in D B ) becomes more reasonable as we may assume that no or very few transmissions occur along the lineage connecting sequences in D to their nearest neighbour in D B . In Eqs. (18)-(24) we considered a single host with an HLA type h or collection of HLA types H. We can trivially extend this to obtain the desired approximation of the likelihood given in Eq. (3) . Let H be the collection of HLA profiles of the associated hosts for sequences in D. Let H j denote the HLA profile of host j. Then We have now created a model which accounts for recombination using the Li and Stephens 41 approximation and incorporates both reversion and HLAassociated selection. We perform inference using MCMC. Restricting D B : sample-specific reference data sets D B j . In order to determine the posterior probability of a new state within the MCMC quickly, we keep track of two large arrays for each query sequence (as well as other quantities required to evaluate the likelihood). This requires storing two jcodon sequencej jDj jD B j arrays of doubles. When evaluating the likelihood of observing~2,000 query sequences from a collection of~60,000 reference protease sequences from the Stanford drug resistance database, over 300 GB of RAM was required! We require a method to reduce the memory required to perform inference. We restrict D B to a different subset D B j for each D j 2 D. We make the approximation If the sequences we choose for each D B j are similar to the true ancestors of each of the D j , then this will be a good approximation. The simple approach we use to restrict D B is by considering the closest n sequences to D j by Hamming distance (the Hamming distance between two strings is the total number of differences between the strings, giving each difference equal weighting). A drawback of using Hamming distance to restrict D B is that in the presence of high recombination rates, one can imagine sequences which should be included in D B j but are excluded on the basis this metric. For the small amount of overhead, this sample-specific restriction reduce the computational time and memory footprint required by the programme to the extent that a run of 1,500,000 updates analysing~1,000 query sequences over a codon sequences of length~100, considering the closest 100 reference sequences according to some metric may be performed in~24 h on an Intel i7 desktop machine using <1 GB of RAM. MCMC inference regime. The structure of the model we have presented lends itself to inference using MCMC to sample from the posterior. For our MCMC implementation, we use the Metropolis Hastings algorithm. We fix κ, ϕ and π C for each codon C at empirical estimates. We perform MCMC moves on the following collection of parameters: • The recombination probability r i between neighbouring sites i and i + 1. In our sampling scheme we allow ζ i and γ h;i to vary via piecewise constant functions across the codon sequence, which we call selection windows. This is analogous to the 'block-like' model used by Wilson and McVean 42 . Imposing this window structure allows information about HLA-dependent selection (and reversion) to be combined across sites. This makes sense in a biological setting where sites close together in the coding sequence may result in amino acids lying in the same epitope or close together in the protein structure. The window model will act to smooth across sites, but will be overwhelmed if a given site is subject to strong HLA-dependent selection 42 . How strict the window model is depends on the expected number of windows, which is controlled by the parameter p w (see the merge and split moves in Supplementary Methods MCMC moves subsection, and Wilson and McVean 42 ). If p w ¼ 1, the number of selection windows is equal to the number of sites, if p w ¼ 0 then there is just one selection window. The piecewise constant prior is extremely flexible. Using a piecewise constant prior in combination with MCMC moves to shrink/expand and merge/ split these blocks allows us to explore the space of HLA-associated selection rapidly while maintaining a far smaller number of parameters than considering HLA-associated selection site by site. See Supplementary Methods for MCMC move details. Simulation study 2: simulating a sampled birth-death process. For a second large simulation study, we consider a more realistic generative process for creating our reference and query data sets. Rather than using an existing large reference data set and simulating query sequences under our model, we generate an instance of a sampled birth-death process. We then simulate sequence data down the resultant sampled birth-death tree. We simulate the sampled tree backwards in time together with unseen transmission events using the following procedure: Let birth rate be λ and the death rate be δ. Thus, backwards in time λ is a death rate, and δ a birth rate. Let N and M denote the total number of infected individuals and sampled infected individuals respectively. Setting r as the sampling proportion for extinct lineages, we consider a collection of competing Poisson processes. Set t ¼ 0, and let the total number of infected individuals and sampled infected individuals at the present be N ¼Ñ and M ¼M, respectively. While M > 0, sample the time of the next event t ! t þt wherẽ t $ ExpðNðλ þ δÞÞ. First, we determine whether this event is a birth or a death. Sample u $ U½0; 1. Ifû $ U½0; 1 < q then the death event is sampled M ! M þ 1, and we store the time of the event t. Given that birth and death events are lineage independent, we may just use the time information to then generate the a tree. Code is available at https://github. com/astheeggeggs/mcqueen. We note that this generative process is based on the equations laid out in the Supplementary Materials of Palmer et al. 17 and Frost and Volz 51 , and that it is similar to the backwards episodic birth-death process algorithm outlined by Stadler 52 , except that we have a fixed birth and death rate over the entirety of the tree, store unseen transmissions, and do not have mass extinction events. We now have a sampled birth-death tree. Given our knowledge of all the transmission events along the lineages of this sampled birth-death tree, we may assign HLA types to each node by passing the information down the tree from the root. Note that at each coalescence event, one of the daughter lineages will be in the same host, whilst the other will represent the transmission to a new host and HLA environment. All unseen transmission events which we count are transmissions to a new host, so also coincide with a change in HLA environment. We then simulate sequence change down this tree conditional on all the HLA information, using the codon substitution model outlined in the methods subsection: Codon model of substitution, again by passing a sequence at the root and tracking changes down the tree. Finally, we sample m of these sequences at the leaves to be our query sequence set with associated host HLA information, and the remainder to define our reference sequence data set, after throwing away the host HLA information. In this simulation study, we set N = 1,000,000, M = 100,000, q = 0.1, and m = 1,460, and use the same selection profiles, but increase the number of flat selection profiles to 16, so that the total frequency of a given HLA allele more closely resembles that seen in the data, which is important for this tree based simulation of HLA-associated evolution. Simulation study 3: the effect of population differentiation. Differentiation between the query and reference data sets can potential lead to reduced performance of estimators due to two factors: confounding between covariates that are non causal (for example differences in both HLA allele frequency and viral genetic diversity due to genetic drift) and relatedness within the query population leading to poorly calibrated estimates. To assess the impact of population differentiation on performance of our estimator we carried out a parametric bootstrap simulation, using viral sequence data from the Botswana study (n = 343, protease only) to simulate ancestors infecting a set of hosts with HLA allele frequencies drawn from the Botswana population. We used the evolutionary parameters estimated within this study (including the HLA-associated selection profiles, dN dS , and recombination probabilities) and performed 100 independent simulations of 1,500 query sequences with associated HLA information. For each simulation we then performed inference using a range of reference data sets and also considered a leaveone-out (LOO) strategy in which the reference data are augmented by all sequences from the query data set except for the sequence under consideration. These will typically be the most closely related to the query data. The reference data sets we consider are: a. D B = The sequences actually simulated from, under the model (Botswana sequence data). This represents a gold-standard reference data set. b. D B = All sequence data available in public databases for which no HLA information is available (n = 162,901). c. D B = The simulated sequences, using a LOO strategy for each query. d. D B = a) + b), using a LOO strategy. We display plots of inference results for a common and rare HLA type for each HLA class I molecule (A-C) in Supplementary Figs. 9-11. To compare the impact of relatedness on our ability to perform inference, we compare the mean RMSE of the median HLA-associated selection estimates across sites, weighted by the frequency of the HLA types in our simulated data sets. Results are displayed in Supplementary Table 9 . As expected, the gold standard D B , a) is the most accurate. We find that the reference data set that we have aggregated, b) performs almost as well, with the addition of the simulated sequences to the reference data set performing worse. This is likely due to the approximate nature of the model used to simulate the sequence data, but nevertheless is encouraging to see that our current approach recapitulates parameters almost as well as if we had access to the best possible query data set, a). We also examined the effect of restricting the reference data set to the subset Los Alamos reference data (where we had sampling country information). We then checked to see if removal of all Botswana samples (n ¼ 73) from this Los Alamos reference set dramatically reduced our accuracy. We saw similar results for inference using these two reference sets. These results indicate that our method is robust to population differentiation and relatedness within the query data set. Importantly, the effect of removing all reference data from Botswana has only a marginal impact on accuracy. The LOO strategy does not typically improve performance, though clearly enables use of the method when no (or only very distantly related) reference data is available. Users of our software (available at https://github.com/astheeggeggs/mcqueen) can set D B to be created using a LOO approach by using the -q or -separate_reference_fasta flags. Testing overlap with A-list and B-list epitopes. We permute the labels of HLA types for a class I gene 1,000,000 times, and count the number of overlaps with the putative epitope sets for each permutation. This leads to an estimate of an alternative null distribution (by shuffling we account for possibility that parts of the region may be epitope rich across HLA types). We then compare this distribution of counts of overlapping sites to the observed number of epitope overlaps with our putative selected sites to obtain p values, by determining the proportion of the shuffled sets with at least as many overlaps as the real data. The impact of HLA on HIV-1 sequence evolution. To investigate the contribution of diversifying selection due to HLA pressure, we first evaluate the average HLAassociated selection away from consensus at each site i, for each individual j in the sample using the median estimates from the MCMC analysis where α S,i and α V,i are the number of non-synonymous transitions and nonsynonymous transversions from the consensus codon at site i, respectively. We then determine the collection of A j,i for which there is increased selection away from consensus due to HLA-associated selection: Q h2H j γ h;i > 1. We then evaluate the fraction of the total mutation rate away from consensus that this  We find that this represents 18 and 28% of all mutations (59% and 77% of nonsynonymous substitutions) away from subtype B and C consensus in protease, respectively. In reverse transcriptase this represented 18% and 32% of all mutations (61% and 78% of non-synonymous substitutions) away from subtype B and C consensus, respectively. Testing the impact of HLA on HIV-1 subtype differentiation. We wish to examine whether amino-acid differences between HIV subtype B and C may have been driven by differences in HLA frequency distributions. To do this, we first use RIP 53 to determine, for each query sample, the viral subtype within each of the genomic regions analysed. At each site we then calculate (using the inferred evolutionary parameters) the average selection away from each subtype consensus in those hosts harbouring the subtype B and C viruses separately. In this way, we obtain an approximation of the average HLA-associated selective pressure away from the subtype B/C consensus in the geographic regions in which subtype B and subtype C viral sequences predominantly reside. For example, letting S C be the set of subtype C viral samples, H j be the HLA profile of the host in which viral sequence j resides, and γ B h;i denote HLA h associated selection away from subtype B at site i is the selective effect away from subtype B consensus at site i of HLA alleles averaged over regions in which subtype C predominates. Results are shown in Supplementary Fig. 20 . To determine if there is an elevated HLA-associated selective effect on sites that differ between subtypes B and C, we performed permutation tests. For example, consider selection away from subtype B consensus. We evaluate X where D is the set of sites at which subtype B and subtype C differ at the aminoacid level. We then randomly shuffled site labels and re-evaluated this quantity 1,000,000 times to obtain a p value. Resultant p values for protease and reverse transcriptase are shown in Supplementary Table 8 . Reporting summary. Further information on research design is available in the Nature Research Reporting Summary linked to this article. 