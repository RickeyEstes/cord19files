We used the systematic RAND modified Delphi method to develop and select -in a multistep approach (see Step1 through 5 below)-a set of key recommendations representing good quality infectious disease outbreak response [15] . In this iterative method the individual opinion of experts is aggregated into group consensus. Recommendations for infectious disease outbreak response were extracted from the literature, and presented to a multidisciplinary expert panel. The panel achieved consensus on a set of key recommendations during two questionnaire rounds and two face-to face consensus meetings. Formal ethical approval from a medical ethical committee was not required for this research in the Netherlands since it does not entail subjecting participants to medical treatment or imposing specific rules of conduct on participants. All the experts consented to participate in the study and were aware that their responses would be used for research purposes. Step 1 -Literature search and extraction of recommendations We performed a literature search using the Medline database to review the international literature for information about quality indicators and recommendations for good quality response to an infectious disease outbreak from the year 2007 (search executed 4 th week of February 2012). Table 1 shows the search strategy in which we combined the gold standard search strategy of the Cochrane Effective Practice and Organisation of Care Group to identify quality improvement studies and combined these (http://epoc.cochrane.org/) with terms on outbreaks and performance measurement. Two researchers (EB and AT) independently examined title and abstract of the publications to include any publication (for example outbreak reports, evaluations, health services research studies, guidelines) potentially describing recommendations for ID-control professionals and disaster emergency responders. Exclusion criteria were: publications that were not about infectious disease outbreaks (non outbreak setting or no acute outbreak like HIV), publications describing recommendations for a hospital setting, publications that were setting/region or patient specific, and publications that described simulations or mathematical models of outbreaks. Next, we collected grey literature, i.e. Dutch documents on good quality response including national guidance, national outbreak advice, contracts between health care organizations and disaster care plans. We also included national evaluations of recent infectious disease crises such as Q-fever and the 2009 flu pandemic. The inclusion of grey literature was made on the basis of recommendations from national specialists on infectious disease preparedness-and control who were asked to judge appropriateness. Two researchers (EB and MHi) performed the extraction of recommendations independently on a sample consisting of 25% of all selected sources (literature review and grey literature). The researchers extracted good quality response recommendations from the selected literature. Discrepancies between the two researchers were discussed until consensus was reached. After reaching consensus on this 25% sample, one researcher continued to extract recommendations from the remaining selected literature (EB). The two researchers examined the total set of recommendations to remove identical recommendations. All recommendations were discussed with the main researchers involved in this study (MHu, JH, AT, EB) in two meetings. In these meetings we selected in consensus and while applying the inclusion criteria, existing generic recommendations or aggregated pathogen and disease specific recommendations, which were subsequently presented to the participants in the expert panels during the next stages. Step 2 -First questionnaire round The consensus procedure took place between September 2012 and May 2013. We approached all 25 public health regions from the Netherlands by e-mail and invited public health infectious disease experts from their region to participate in the expert group. Our expert panels consisted of 48 Dutch experts in public health (28 ID-control professionals and 20 disaster emergency responders) who all had experience in the preparedness and/or control of an infectious disease outbreak. All regions were represented. Two digital Limesurvey (a digital open source survey application) questionnaires were composed, one for the ID-control professionals and one for the disaster emergency responders. In this process, recommendations were assigned to the responsible organization in the Netherlands: logistical support recommendations were presented to disaster emergency responders and infectious disease control recommendations were presented to ID-control professionals. In the Netherlands, the disaster emergency responder tasks lay with charge of logistical support of outbreak control while the coordination of outbreak measures is a responsibility of the ID-control experts. This, of course, can be different in other countries. Both expert groups followed a parallel, methodologically identical path: each expert group assessed the recommendations regarding their expertise on relevance. Relevance was graded by the experts in response to the following question; "To what extent do you consider this recommendation as a relevant element for measuring the quality of infectious disease outbreak response?" on a 9point Likert scale (1 = totally disagree, 9 = totally agree). Experts could comment on recommendations and could add recommendations. Recommendations were accepted or further processed based on the RAND/University of California at Los Angeles agreement criteria [15] . Relevance scores were calculated for each item. If the recommendation had a median of 8 or 9 and >70% of the experts scored in the top tertile, then the recommendation was marked as "accepted". If the recommendation had a median <8 and <70% scored in the top tertile, then the recommendation was marked as "not accepted" and was excluded. If the recommendation had a median <8 and >70% of the experts scored in the top tertile or the median was 8 or 9 and <70% of the experts scored in the top tertile, then the recommendation was marked as "to be discussed". In the second part of the questionnaire we checked whether we assigned recommendations to the correct responsible organization (disaster emergency responders or ID-control experts). If more than 33% of the responders questioned the attribution of responsibility for the action to a certain party, then the recommendation was presented to the responsible organization in the second questionnaire round. Step 3 -Consensus meeting Both expert groups were invited for a separate face-toface consensus meeting in October 2012. The results of the analysis of the questionnaires were sent to the experts in advance of the consensus meeting. During the meeting, the expert panels could comment on recommendations with the label "to be discussed". As a result, the discussed recommendations were found to be not relevant or were modified and found relevant. Step 4 -Second questionnaire round In step 4, two responsible organization specific questionnaires were composed of all recommendations. To categorize the recommendations, we combined two frameworks which incorporate the main domains of emergency response [16, 17] . The recommendations were categorized into 35 categories (25 for ID-control experts and 10 for disaster emergency responders) which described each step in the process of infectious disease outbreak response. These 35 categories or subdomains represented 10 main domains: "Scale of the outbreak and epidemiology", "Control measures", "Diagnostics", "Logistic support", "Aftercare and conclusion", "Communication", "Logistics", "Upscaling", "Coordination of the chain of outbreak control" and "Continuity of care". Corrections on the assigned responsible organization based on the first questionnaire were processed in this second questionnaire. Doubles were removed if there was too much resemblance of the recommendations within one category. If a number of recommendations represented the same recommendation, but for different patient groups (for example, confirmed case, contact of cases) the recommendations were merged. We asked both expert groups to prioritize the most important recommendation per category, and we calculated the percentage of experts that selected a recommendation. If more than 15 percent of the experts selected a recommendation, the recommendation was considered prioritized. Each group only prioritized recommendations regarding their own expertise. Step 5 -Second consensus meeting In a final, combined face-to-face expert meeting the experts were presented the combined selected sets of quality indicators from step 4. Experts were asked to judge the completeness of the selected recommendations. As a result, recommendations were textually modified, merged or deleted.  