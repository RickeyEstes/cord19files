The analysis framework based on Pfeiffer et al. (2008a) , presented in a slightly updated format in Fig. 3 , is still relevant for structuring the different spatial and spatio-temporal epidemiological analytical methods. These are based primarily on classical statistical theory, with the addition of Bayesian methods to address the issue of spatial and temporal dependence. However, the assumptions, in particular, of frequentist statistical methods are usually not met for Big Data, and therefore analytical algorithms are required which are statistically robust (i.e. non-parametric) and also are capable of efficiently analysing very large datasets. The developments for epidemiological analyses have, so far, been primarily through the inclusion of machine learning regression amongst the modelling methods, whereas in visualisation and exploration it has been primarily through more effective use of interfaces and flexible software environments. It needs to be emphasised that data analysis plays an important role also in dealing with the five Vs of Big Data (i.e. volume, velocity, variety, veracity and value). The first four attributes refer to areas which are subject to significant research aimed at optimisation of data utilisation. A particularly difficult aspect is the challenge presented by differences in data quality, including the ubiquitous presence and heterogeneity of bias. Below, we discuss developments for each of the three analysis categories of the framework. 


Section:the development of spatial analytical methods