Since FðqÞ defined in (2.8) is a non-linear operator, the regularization needs to be combined with a robust problemoriented numerical algorithm capable of producing an accurate approximation to the unknown parameters. If one solves (2.7) by a classical Gauss-Newton method and drives a to 0 as iterations progress, then one gets what is known as iteratively regularized Gauss-Newton (IRGN) scheme (Bakushinsky, 1993; Bakushinsky & Kokurin, 2005)  where F 0Ã ðqÞ is the adjoint to F 0 ðqÞ. In (3.1), a k and l k execute regularization and line search, respectively. While this method is generally efficient, for our model one is forced to sacrifice too much accuracy to stabilize the process, and even with a relatively large regularization parameter the uncertainty in the computed solution remains high. Hence our goal is to modify IRGN (3.1) by truncating a "non-essential" part of the Hessian approximation in order to bring down its condition number. To that end, consider the gradient of f, Vf ðqÞ ¼ F 0Ã ðqÞðFðqÞ À DÞ; where  : This permits to lower the condition number and to enforce the symmetric non-negative definite structure. Dividing both sides of the modified linear system by K 2 ðq k Þ, which enables us to move all noise from the matrix to the right-hand side, one arrives at what we call Reduced IRGN (RIRGN) (Smirnova et al., 2017) ½A 0Ã ðq k ÞA 0 ðq k Þ þã k L Ã Lp k ¼ À½A 0Ã ðq k ÞðAðq k Þ À D=Kðq k ÞÞ þã k L Ã Lðq k ÀqÞ; (3.4) where AðqÞ :¼ dH dt ðqÞ, andã k :¼ a k =K 2 ðq k Þ: 


Section:numerical optimization method with hessian reduction