The previous section discussed the use of MCDA models to aggregate multiple dimensions of value into a single metric. The commonly used models such as MAUT and AHP have specific methods embodied in them to elicit the needed value trade-offsprimarily arising from the work of people in the field of decision science. These methods have their own strengths and weaknesses (as discussed earlier), but other approaches may prove fruitful, some of which arise from the methods of economics. Because health itself cannot be bought and sold in a market setting, and because health care markets are distorted by insurance or government subsidies, direct valuation of a health intervention or a health insurance product as a differentiated good through observed market prices-as economists might normally do-is difficult. In a recent article, Basu and Sullivan [37] discussed the rationale of using stated preference methods for developing "hedonic" value frameworks for health insurance products to inform the decision on whether a product should be covered or subsidized by insurance, given its price. They propose that discrete choice experiments in a nationally representative sample be used to elicit WTP for health insurance products that would cover a new health intervention with specific attributes. These elicitations should be carried out among the patients who are the direct beneficiaries of this intervention as they are diagnosed with the specific clinical condition as well as the healthy individuals who do not have that specific clinical condition but face varying risks of being diagnosed with that condition in a given year. This combination of values from both patients and nonpatients would reflect the true value of a health care intervention because it would incorporate the value of health insurance covering that intervention [38] . On the basis of these elicitations, a WTP value index could be developed relating to each of the dimensions of a health care intervention. This value index will not reflect marginal value at market equilibrium, as would appear in hedonic pricing estimates, but it would capture the distribution of marginal value in the population. This approach can inform two specific decision-making processes: 1) whether a health insurance budget could be expanded to cover a new technology and 2) which existing technology can be displaced to accommodate the new technology that maximizes value in the health plan population. If either or both cannot accommodate the budget impact of the new technology, then coverage may not be feasible. Basu and Sullivan [37] lay out a research agenda that can help develop this concept of hedonic valuation for health care value frameworks. Both the use of MCDA models and formal deliberative methods require that groups agree on choices. For example, AHP requires a series of N*(N-1) pairwise votes to choose the more important of each possible pair of N value dimensions, and then another vote to specify the relative importance (ranging from 1 to 9 typically). MAUT using the SMARTER process requires that the group agree on a rank-order listing of the importance of the N value dimensions [13] . Multiple voting techniques are available to accomplish these tasks, and they (not uncommonly) give different answers from the same group of voters. Formal deliberative processes also require group agreement to choose among alternatives. When three or more choices exist, no ranking method exists that meets four simple criteria [32] and all available voting methods to choose among three or more choices are subject to strategic voting manipulation [33, 34] . Even if the choices are reduced to pairwise comparisons using some structured technique as Roberts' Rules of Order, the opportunity for strategic manipulation of the outcome through agenda control looms in many settings [35] . While we have no particular recommendation about choice of voting rules, we believe that groups undertaking such votes either with MCDA models or deliberative processes should carefully consider the voting methods they adopt and understand the potential consequences for their choices. A large literature on social choice theory (too large to reference here) can help guide these choices. adequately explored. This can be improved, both by the introduction of cost-per-QALY evidence and by the use of more structured decision making to take account of preferences about the weight to be given to health gain-for example, about disease severity, equity of access, or unmet need. A systematic comparison of the processes used by various private and public pharmacy and therapeutic committees and HTA programs may further help others determine best practices for their own setting. MCDA models may provide the best opportunity for improvement, but they have not yet been perfected. To improve these methods, we urge progress on two fronts. First, we must expand the use of MCDA models in real-life decision settings and learn from these experiences how well they work. We may learn that they seldom differ from standard CEA in the investment advice they give, or we may learn that formally incorporating these "other issues" importantly changes many decisions. We cannot know until we "run the experiment." Second, we also need more research on key aspects of MCDA modeling and use. Just as the current "criterion standard" of CEA did not begin in its current form, we can expect that MCDA will evolve for the better in the future. In CEA, both for lack of the proper conceptual framework and for lack of data, earlier efforts focused on things that were easily measurable. These first included "deaths averted" or similar measures, and soon expanded to "life-years saved" or similar measures. Then came the notion of quality adjustment, leading to the current metric of the QALY based on work that relies on population-based estimates of reported quality adjustments for different health-related conditions. A similar but not identical measure-DALY-is used by the World Health Organization, the World Bank, and others: for this measure, expert judgment has been used (at least initially) rather than population survey data to create the adjustment factors [17] , although DALY estimates increasingly turn to population-based metrics when available. A third related measure is the capabilitiesadjusted life-year, using a capabilities index instead of a health state utility, initially proposed by Amartya Sen, progressed by Nussbaum [39] , and operationalized by Anand et al. [40] . We likely stand at a similar point in the evolution of MCDA models with important issues to resolve before they reach their full potential. Some have issues in ease of use. Some have methodological flaws such as the risk of "rank reversal" as new technology options emerge. Little is known about important human factor issues associated with the use of various MCDA models, including ease of use, susceptibility to strategic manipulation, and ease of comprehension of the methods (and hence acceptance of the results). And finally, these approaches are quite data-intensive compared with CEA modeling because they require measuring each candidate technology on multiple dimensions of value rather than on the single dimension of QALYs. We recommend greater testing and use of MCDA models, pushing the frontiers of their use and continuously comparing their results with those of standard CEA and similar models. Using ECEA or even more broadly-ACEA-models may provide a halfway-house step to MCDA by facilitating data acquisition and refinement. But ECEA provides no way to combine multiple dimensions of value into a single index of merit. MCDA provides the logical basis for this next step. An important missing element is a universally acceptable method to elicit value weights. Current approaches have known defects (as discussed earlier), but have nevertheless been demonstrated to assist in decision making in complex health care settings, but further improvement is needed to bring MCDA models to full flower. What are the best methods for acquiring value weights, particularly in settings with groups acting as decision makers? AHP and MAUT offer different approaches with different strengths and weaknesses. Discrete choice experiments using representative populations offer another approach to establishing proper weights [37] . Other approaches may emerge as well. All should be tested and compared both for methodological soundness and for human factors (ease of use etc.). Source of financial support: The authors did not receive any funding for this work other than reimbursement from the International Society for Pharmacoeconomics and Outcomes Research for travel expenses, as needed, for two Special Task Force meetings. 


Section:other value elicitation methods
Section:box 2-the choice of formal voting methods