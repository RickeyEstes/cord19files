This proposal presents a ranking algorithm which orders documents following two main ideas taken from [ 18 , 23 ] : the relevance of the documents is ranked according to the needs of the user and the quality of the documents retrieved. The first aspect refers to the textual content of the documents. The relevance of the documents depends on the ability of the system to represent, save and retrieve relevant documents with respect to a user query. And the second aspect refers to the quality of the content of the retrieved documents. It considers that documents should be ranked by considering parameters such as the importance of the authors, the publication date or the type of publication. Merging both these aspects, the system should be able to retrieve better documents than systems like Pubmed, which are mainly based on Boolean searches. In this case, the automatic classifiers used in [18] , are replaced by clustering algorithms, because it is not always possible to have access to collections such as the Clinical Hedges Database. Moreover, the use of these automatic classifiers involves spending time on training them, which may not be always possible, desirable or useful. And furthermore, the clustering processes simplify the task of searching because they work as filters, reducing the number of documents to be analyzed. The clinician thus receives a list of labeled clusters and needs only select those which are best suited to his/her needs. Hence, this proposal facilitates the tasks of clinicians through the interactive way in which the results are grouped and presented, saving time and effort. To sum up, the main contributions of this paper are: a new algorithm to measure the quality of docu-ments in the field of Medicine and a ranking strategy for retrieving high-quality and relevant documents, which has been tested working with real databases such as Medline and Cochrane. To drive the experiments, the methodology used is the same as in [18] . This will also be used to compare the results by using the same evaluation measures. Medline was indexed for 60 days by using a shallow parser to preprocess each document thanks to the LingPipe library [31] . The fields indexed were: abstract, author, body, keywords, title and type of document. Furthermore, author quality values (see Algorithm 1 ) have been precomputed, since it is very time-consuming process to compute them in real time. Once the database for experimentation is ready, it is necessary to prepare the queries and expected results. The Cochrane collection was used for this purpose. Forty titles of documents from Cochrane were gathered manually (see Table 1 ), and the documents have been extracted through the service Cochrane PLUS, a translation of the Cochrane Library for Spain and Latin American countries. Table 1 Titles of all documents. 1. Acellular vaccines for preventing whooping cough in children 2. Acetylcysteine and carbocysteine for acute upper and lower respiratory tract infections in paediatric patients without chronic broncho-pulmonary disease 3. Acyclovir for treating varicella in otherwise healthy children and adolescents 4. Amantadine and rimantadine for influenza A in adults 5. Amantadine and rimantadine for influenza A in children and the elderly 6. Antibiotic prophylaxis for preventing meningitis in patients with basilar skull fractures 7. Antibiotic prophylaxis to reduce respiratory tract infections and mortality in adults receiving intensive care 8. Antibiotics for acute bronchitis 9. Antibiotics for acute laryngitis in adults 10. Antibiotics for acute maxillary sinusitis 11. Antibiotics for acute otitis media in children 12. Antibiotics for community acquired pneumonia in adult outpatients 13. Antibiotics for community-acquired pneumonia in children 14. Antibiotics for preventing complications in children with measles 15. Antibiotics for preventing meningococcal infections 16. Antibiotics for sore throat 17. Antibiotics for the common cold and acute purulent rhinitis 18. Antibiotics for the prevention of acute and chronic suppurative otitis media in children 19 Analyzing each document, the references included were extracted manually. These references are not necessarily all present in Medline; therefore, it was necessary to implement an automatic process to check which references were available in Medline. The forty titles collected from Cochrane are the queries that will be submitted to our system and the references available in Medline associated with each query will be the gold standard used to assess the performance of our approach. Each query will be submitted to retrieve the documents which represent L1. After retrieving these documents, the system will execute the clustering process to group them. As the assessment process is automatic, i.e., there is no user who selects the most suitable cluster according to his needs, it was decided to work with the biggest cluster, i.e., the cluster with most documents. As previously mentioned, the clustering algorithm should be dealing with small amounts of information, due to the information available for each Medline document and because the selection of the labels which describe each cluster is very important. Ideally, clinicians should be the ones who choose the best cluster for their interests. From these two ideas, the algorithm chosen for this experiment can be found in [32] , because it was designed to work with small amounts of information as snippets, and the use of Latent Semantic Indexing [33] allows a human-perceivable cluster label to be created and documents assigned to it. Therefore, once the cluster has been chosen, its documents are ordered according to Algorithm 2 , generating L2; after this step, both L1 and L2 are merged using different typical formulas for metasearch [20] . And finally, L3 will be assessed through the measures set out in the previous subsection. 


Section:methods and materials
Section:methodology