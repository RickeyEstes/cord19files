Participants and setting. Schools in three countries participated in this nonrandomized intervention study: four in the Netherlands, a high-income country in Europe; one in Suriname, an upper middle-income country in Latin-America; and one in Indonesia, a lower middle income country in southeast Asia. 18 The effect of the education module was measured per country, by comparing the results of a pre-and posttest. The situations per country, for example, culture and school system, were too different to make a fair comparison between countries. However, the target group for the education module is the same in each country and the concept of the module and measurements were as comparable as possible. Secondary schools in the Netherlands, Suriname, and Indonesia had been invited to apply to participate in the education module with their 10th grade students (generally 14 or 15 years of age). All schools were well-known public schools for students with an above-average socioeconomic status. The school in Suriname that participated had about 840 students and was located in Paramaribo, the capital and largest city of the country in inhabitants. The Indonesian school that participated was located in Surabaya, the second largest city in the country. This was a senior high school (grade [10] [11] [12] and had about 1,200 students. The four schools in the Netherlands ranged in number of students from 1,600 to 2,400 and were from different regions but all in the Dutch urban agglomeration, including one school from Amsterdam, the capital city of the Netherlands. The 10th grade is the final stage of the junior high school in the Netherlands, which means that all students have, until then, followed the same subjects and have expressed their interest in the choice for a special curriculum. For example, a beta scientific curriculum, which includes the following subjects: biology, physics, chemistry, and mathematics. In the Netherlands, the schools that were invited to participate were all schools that offer students an option for Technasium, which is an elective course for students interested in beta scientific subjects. 19 The participating students had all chosen this special curriculum with additional technical courses. Information about the module was disseminated via the project website and the Technasium network coordinator. A control group for the Dutch intervention group was selected at one of the participating Dutch schools. Thus, although they had not opted for the Technasium curriculum, they do have a similar background and social environment. School curricula are defined differently in each country. In the Netherlands, students choose a profile and we defined "nature and science" and "nature and health" as scientific profiles. In Suriname, students can choose biology, and we defined this as a scientific profile. Indonesian students can choose between a social profile (Ilmu Pengetahuan Sosial [IPS]) and a science profile (Ilmu Pengetahuan Alam [IPA]). We defined IPA as a scientific profile. In both Suriname and Indonesia, schools that matched most closely, in terms of grade and education level, with the Dutch intervention group were invited to participate in the study. Of the Dutch schools, two were preuniversity education level (known in the Netherlands as "VWO") and two were mixed preuniversity education level and advanced general secondary education (known in the Netherlands as "HAVO"). The Surinamese participants were from one VWO school, which is comparable with the Dutch VWO education level. These Surinamese participants can therefore be seen as preuniversity education level. 20 The Indonesian participants were from one Sekolah Menengah Atas (SMA) (high school), which is comparable with HAVO in the Netherlands and internationally known as advanced general secondary education. 21 The Dutch control group consisted of students with preuniversity education level and advanced general secondary education level. Design of the intervention. The Viruskenner education module is based on the "learning-by-doing" principle. Students are challenged to create a prevention tool for a specific virus infection. By involving students in real-life science-based problems and stimulating active learning (searching for information, test possible solutions and present their idea) a high impact can be achieved. [22] [23] [24] In each country, the 2-month module started with a national opening day, during which all participants of that country were introduced to the field of infectious diseases and viruses by means of four short lectures from experts in the field of virology, public health, and infectious diseases. An optimal learning effect can be reached by bringing students in contact with experts. 25 So, in all countries one or two Dutch experts from the department of Viroscience in the Erasmus Medical Center in Rotterdam were assigned to a class to coach them during the project. The students were supposed to work in groups of four to six students in competition with the other groups. 22, 26 Each group worked on one of the viruses of the subject list including HIV, dengue, hantavirus, chikungunya, MERS coronavirus, HPV, norovirus, viral hepatitis, measles, and influenza. Students developed a prevention tool to disseminate this knowledge among their peers and, in doing so, help prevent virus infections that impact local or global health. During the three national final days (one in each country), the best groups per class, selected by the teachers and coach during a school final, presented their results and final product to their peer students and a jury. This independent jury was selected per country and based on proven expertise in virology, communication strategy, and/or overall creativity. In each country, the jury chose two winners: the most informative presented prevention tool and the most creative prevention tool. The study was conducted between April and August 2015. A pretest was performed 1 or 2 days before the start of the module to assess their basic knowledge, attitude, and behavior; a posttest 5-7 days after its completion to let the information settle in their memory and give the students some time to evaluate their attitude and behavior a few days after the final day. Other measurement instruments were used to get additional information ( Figure 1 ). During the intervention, students could use the modules' website (www.viruskenner.nl) and other supportive resources, like a YouTube channel and a Facebook page (all in Dutch and English and available for all participating countries), to find more information on the project and on virus infections and to disseminate information about their prevention tools. [27] [28] [29] Instruments. The effect of the education module was measured by the KAB model. Given that there was no validated instrument to assess knowledge, attitude, and behavior regarding several viral infections, we used a self-designed questionnaire (Supplemental Table 1 ). The questionnaire was based on 5 years' experience with the education module. A team comprising two senior virologists, a communication scientist, and an education expert developed the questionnaire, which was refined after a pilot with a group of 60 students from a school similar to the participating schools. The questionnaires used for the Dutch and Surinamese schools were in Dutch. The questionnaires for the Indonesian students were first translated into English by a Dutch researcher and then into Indonesian by a native speaker of the language. The pre-and posttest questionnaires addressed five areas: 1) sociodemographic factors, 2) stigma and fear, 3) attitude and behavior, 4) knowledge on viruses and infectious diseases in general, and 5) the opportunity to write down questions or comments about the questionnaire or module. The posttest had an additional category-6) perceptions of the project. A principal component analysis (PCA) with varimax rotation was performed for the attitude and behavioral questions on the results of the pretest questionnaires, as suggested in literature. 30 Varimax was the preferred rotation because this results in a small number of factors per variable and a small number of variables per factor. This is the most popular type of rotation because it makes the interpretation of the data more reliable and easier. 31 One of the behavior items ("I do not use a condom when I have sexual intercourse") was excluded because of more than 10% missing values. The remaining missing values were randomly spread over the sample population. The sample size was big enough to delete these cases list wise. The Kaiser-Meyer-Olkin (KMO) value is a statistic that measures how much two random variables correlate. A KMO value greater than 0.8 represents a small partial correlation which makes a factor analysis more useful. In this study, the KMO value was 0.849, which means there were relatively compact patterns of correlations and the factor analysis would provide reliable components. 32 The number of extracted factors was based on the objective and interpretability criteria mentioned in SchÃ¶nrock-Adema and others: 1) the screen test, 2) eigenvalues > 1.5, 3) > 5% of the variance explained by all factors, and 4) interpretability. However, the criterion of eigenvalue > 1.5 led to only two components, which was not interpretable. Therefore, we set the norm of an eigenvalue back to greater than one (Kaiser's criterion). 33, 34 The PCA with varimax rotation finally resulted in four components. The reliability per component was calculated by Cronbach's alpha (Table 1 ). Internal consistency for the components "attitude and awareness" and "behavior and life science" was above 0.7 and therefore acceptable. The components "attitude and risk infections" and "behavior and risk infection" should be interpreted with caution, because of the diversity of the constructs. 35 An additional instrument to measure knowledge was a live multiple-choice quiz, which was implemented at the end of the final day. In the Netherlands and Suriname, portable electronic devices (keypad and software from Interactive Voting System Â® ) were used by the students to answer 40 knowledge questions. In Indonesia, these portable electronic devices were not available, so the knowledge quiz was done by voting with colored papers; therefore, recording these results was not possible. To obtain more information about factors that influenced the impact of the education module, teachers of all four participating schools in the Netherlands were interviewed when they had completed the education module. The aim of this additional qualitative component was to determine possible confounders which might have influenced the difference in outcomes between the pre-and posttests and to find out whether the teachers noticed increased knowledge or improved attitude and/or behavior among their students. Although the teacher interviews were carried out in the Netherlands only, the module was evaluated in each country. In Suriname and Indonesia, the project was evaluated with the local organizing teams but not per individual teacher. In the Indonesian and Surinamese culture, hierarchy is strong and extensive evaluation uncommon. Therefore, the teachers preferred a general evaluation with the head of the school. However, we do feel these interviews were less helpful because the heads of the schools were not closely involved in the project. The Dutch teacher interviews were semistructured and took about 30 minutes each. Questions that were asked included "how was the contact with the coaches?" and "what have the students learned during the project?" Teachers were interviewed in their classrooms after the classes had filled out the posttest questionnaire. Finally, user data from the website and social media were analyzed after the completion of the module to find out which supportive resources were most popular during the education module (Supplemental Figure 1) . Outcomes. The primary outcomes in this study were knowledge, attitude, and behavior and stigma and fear. Stigma and fear, attitude, behavior were measured on a 5point Likert scale. All these outcomes ranged from 1 (strongly disagree) to 5 (strongly agree). Stigma and fear were measured with two questions and mean values were calculated. The outcome "stigma" was used in this study to describe a negative thought regarding people with a HIV infection. The stigma was expected to be high before the module started. By gaining knowledge, the stigma could be decreased. The outcome "fear" in this study aims to measure how afraid people are to get infected in case of a large outbreak; at the time of this study, Ebola was the best example. The attitude and behavior questions were subdivided into four components by the factor analysis and the mean score per component was calculated. (Table 1) . Unstandardized coefficients (B) as outcomes of the regression analysis showed which factors contribute significantly to these four attitude and behavior components and to knowledge. The outcome knowledge represented the student's knowledge regarding infectious diseases in general and the viruses in specific that were included in the education module. Knowledge was measured in the questionnaire by means of the responses to 32 questions, which had to be answered with "true" or "false." Each correct answer resulted in one point, an incorrect answer in zero points. The mean percentage of all knowledge questions that were answered correctly was calculated per group and ranged from 0% to 100%. Knowledge outcomes from the quiz were calculated in percentages. As a secondary endpoint, the perceptions of the students about their participation in the project were evaluated. Ten statements measured if students enjoyed working on the project and if they thought the project was informative. This was scored on a 5-point Likert scale and ranged from 1 (strongly disagree) to 5 (strongly agree). Data management and analysis. The questionnaires were read by the open source optical mark recognition program SDAPS (Benjamin Berg, Karlsruhe). Correct reading was checked manually by two different persons. All data were imported into one database and analyzed with IBM SPSS version 21. All questionnaires in which less than 90% of the knowledge questions had been answered were excluded. Cases that showed a variance equal to zero in the Likert scale questions were excluded for analysis on these outcomes. Items with more than 10% missing values were deleted. In all analyses, P < 0.05 was considered significant. Descriptive analyses were performed to calculate the frequencies of students' characteristics and Pearson's Ï 2 test was used to identify significant differences between the characteristics of the groups in the pre-and posttest. Correlations between knowledge, attitude, and behavior were calculated for all students in the intervention group, with a Pearson's coefficient. The average knowledge per country in the pre-and posttest situations was compared by an independent sample T-test. Effect sizes (ES) were calculated with Cohen's d. Effect sizes greater than or equal to 0.30 were considered medium, and those greater than or equal to 0.50 as large. 36 Multiple linear regression analysis was used to find factors that influenced the knowledge, attitude, and behavior outcomes. Time point (pre-and posttest) and participation (intervention and control group) and the interaction between these two variables were added as independent variables, as well as gender, age, education level, school, and country. Tolerance values were computed to assess multicollinearity. Values below 0.2 were viewed as potentially problematic. 30 Stigma and fear were compared between pre-and posttest with a one-way analysis of variance (ANOVA). The sample size allowed us to calculate differences between the components of the factor analysis in pre-and posttest per country with a one-way ANOVA test. Perceptions of the project were measured only after the module had finished. Means and standard deviation were summarized per country. The data set is provided in the supplementary materials. Ethics. The study was carried out in accordance with the Declaration of Helsinki. According to Dutch law, this study was exempt from medical ethical approval requirements. The Technasium Network in the Netherlands approved this study to be performed at the Dutch Technasium schools and informed the students and parents. In Suriname and Indonesia, the headmasters of the schools approved conducting the Viruskenner module and evaluations at their schools and informed the students and their parents. Participation was voluntary and anonymity was guaranteed. 


Section:materials and methods