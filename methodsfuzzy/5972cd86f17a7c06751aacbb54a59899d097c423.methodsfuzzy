Some methods are compared for identifying hoaxes with different kind of texts (Table 1 ) such as Facebook, Twitter, Wikipedia, and article news. Recent researches give more attentions to word-embedding techniques, which need no knowledge about the language of hoax texts [14] [15] . The weight value of term vector is no longer occurrences based but also considering positions of phrase texts like word embedding. However, the text source influences methods of feature selection and classifier. For example, in Wikipedia articles [16] there are appearance features like word counting, content ratio of texts & non-texts, and links within articles. Another kind of feature for Wikipedia articles is network-based coefficients like clustering coefficient to differentiate legitimate and hoax articles. Unique characteristic of Facebook posts create user categories [17] , which are user who like hoaxes, user who like non-hoaxes, and user who like both posts. Those categories have an influence in preparing data collection. For Twitter allegedly hoaxes [18] , retweeting topology network can be a network feature for hoax analysis to verify the credibility of text source. This paper showed experiments with steps are directly taken from the approaches of stance classification [19] (Fig.  3) . The purpose of our experiments is to show how stance classification implemented in hoax analysis especially with medial contents. The first step of our experiments is collecting data come from medical archives of snopes.com (http://www.snopes.com/category/facts/medical/). The articles are categorized as true, false, and unverified facts. For our Snopes small dataset, we have articles of 19 true claims, 42 false claims, and 17 unverified texts. Then we find 400 related headlines of news texts as stance articles from the search results which have states of for when the claim is true, against when the claim is false, and observing when it merely repeats the claim but uses hedging or vague language. Because of the possibilities for hedging texts, there are two kinds of features: headlines and claim-headlines. Headlines features are common bag-of-words representation from term frequency until distance between root word and refuting word in a sentence that needs a process of analyzing grammatical structure. Whereas, claim-headline features need aligning process between words in a claim with its parallel headline, i.e. Paraphrase Database (PPDB). After aligning words and know their positions, the similarity between vectors of the claim and the headline uses wordembedding results. 


Section:methodology