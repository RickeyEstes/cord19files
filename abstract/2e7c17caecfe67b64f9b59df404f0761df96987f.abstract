Health planners use forecasts of key metrics associated with influenza-like-illness (ILI); near-term weekly incidence, week of season onset, week of peak, and intensity of peak. Here, we describe our participation in a weekly prospective ILI forecasting challenge for the United States for the 2016-17 season and subsequent evaluation of our performance. We implemented a metapopulation model framework with 32 model variants. Variants differed from each other in their assumptions about: the force-of-infection (FOI); use of uninformative priors; the use of discounted historical data for not-yet-observed time points; and the treatment of regions as either independent or coupled. Individual model variants were chosen subjectively as the basis for our weekly forecasts; however, a subset of coupled models were only available part way through the season. Most frequently, during the 2016-17 season, we chose; FOI variants with both school vacations and humidity terms; uninformative priors; the inclusion of discounted historical data for not-yet-observed time points; and coupled regions (when available). Our near-term weekly forecasts substantially over-estimated incidence early in the season when coupled models were not available. However, our forecast accuracy improved in absolute terms and relative to other teams once coupled solutions were available. In retrospective analysis, we found that the 2016-17 season was not typical: on average, coupled models performed better when fit without historically augmented data. Also, we tested a simple ensemble model for the 2016-17 season and found that it underperformed our subjective choice for all forecast targets. In this study, we were able to improve accuracy during a prospective forecasting exercise by coupling dynamics between regions. Although reduction of forecast subjectivity should be a long-term goal, some degree of human intervention is likely to improve forecast accuracy in the medium-term in parallel with the systematic consideration of more sophisticated ensemble approaches. It is estimated that there are between 3 and 5 million worldwide annual seasonal cases 1 of severe influenza illness, and between 290 000 and 650 000 respiratory deaths [1]. 2 Influenza-like-illness (ILI) describes a set of symptoms and is a practical way for 3 health-care workers to easily estimate likely influenza cases. The Centers for Disease 4 Control (CDC) collects and disseminates ILI information, and has, for the last several 5 years, run a forecasting challenge (the CDC Flu Challenge) for modelers to predict 6 near-term weekly incidence, week of season onset, week of peak, and intensity of peak. 7 We have developed a modeling framework that accounts for a range of mechanisms 8 thought to be important for influenza transmission, such as climatic conditions, school 9 vacations, and coupling between different regions. In this study we describe our forecast 10 procedure for the 2016-17 season and highlight which features of our models resulted in 11 better or worse forecasts. Most notably, we found that when the dynamics of different 12 regions are coupled together, the forecast accuracy improves. We also found that the 13 most accurate forecasts required some level of forecaster interaction, that is, the 14 procedure could not be completely automated without a reduction in accuracy. PLOS 2/43 . CC-BY 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/309021 doi: bioRxiv preprint Infectious pathogens with short generation times pose public health challenges because 17 they generate substantial near-term uncertainty in the risk of disease. This uncertainty 18 is most acute and shared globally during the initial stages of emergence of novel human 19 pathogens such as SARS [2], pandemic influenza [3], or the Zika virus [4] . However, at 20 national and sub-national levels, uncertainty arises frequently for epidemic pathogens 21 such as seasonal influenza, dengue, RSV and rotavirus; causing problems both for 22 health planners and at-risk individuals who may consider changing their behavior to 23 mitigate their risk during peak periods. 24 Seasonal influenza affects populations in all global regions and is forecast annually in 25 temperate populations, either implicitly or explicitly [5]. Peak demand for both 26 outpatient and inpatient care is driven by peak incidence of influenza in many years [6]. 27 Therefore, the efficient provision of elective procedures and other non-seasonal health 28 care can be improved by accurate forecasts of seasonal influenza. Implicitly, most 29 temperate health systems use knowledge of historical scenarios with which to plan for 30 their influenza season. The current situation is then assessed against the deviation from 31 the historical averages and worst-cases as observed in their own surveillance system. The United States Centers for Disease Control (CDC) has sought to formalize regional 33 and national forecasts by introducing an annual competition [7] . Each week, 34 participating teams submit weekly estimates of incidence for the next four weeks, season 35 onset, and timing and intensity of the peak. Methods used by teams include purely 36 statistical models, [8-10] mechanistic models [11, 12] machine learning and hybrid 37 approaches [13-15]. Expert-opinion surveys have also been used and performed well. 38 Some teams augment their forecasts of the official ILI data with the use of potentially 39 faster or less-noisy datasets such as google flu trends [16]. 40 Here we describe a our mechanistic-model-supported participation in the 2016-17 CDC 41 influenza forecasting challenge, as an example of a disease forecasting process. We 42 emphasize a subjective human component of this process and also describe a 43 retrospective evaluation of the models for the previous six seasons. All the models 44 PLOS 3/43 . CC-BY 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/309021 doi: bioRxiv preprint described are implemented in the R package Dynamics of Interacting Community 45 Epidemics (DICE, https://github.com/predsci/DICE). 46 Methods 47 Data 48 The CDC Influenza-like-illness Surveillance Network (ILINet) Human and Health 49 Services (HHS) region and national data were downloaded from the CDC-hosted web 50 application FluView [17] and used to create a historic database of ILI cases. Fig S1 51 shows which states are grouped into each HHS region, along with the population of each 52 region. Because we require an absolute number of cases per week, the CDC ILINet data 53 is converted from percent ILI cases per patient to ILI cases. We estimate the absolute 54 number of weekly ILI cases by dividing the weighted percent of ILI cases in the CDC 55 data by 100 and multiplying it by the total weekly number of patients. We assume two 56 outpatient visits per person per year so that the total weekly number of patients is 57 estimated as: (total regional population)x(2 outpatient visits per person per year)x(1 58 year/52 weeks). 59 The estimate of two outpatient visits per year is based on two studies. In 2006 60 Schappert and Burt [18] studied the National Ambulatory Medical Care Surveys 61 (NAMCS) and the National Hospital Ambulatory Medical Care Surveys (NHAMCS) 62 and calculated an ambulatory rate of 3.8 visits per capita-year. The 2011 NAMCS [19] 63 and NHAMCS surveys [20] estimated ambulatory visit rates of 3.32 visits per capita per 64 year for physician's offices, 0.43 for hospital emergency departments and 0.33 hospital 65 Outpatient Departments. We sum these rates to get an outpatient visit per capita-year 66 of 4.08. We further estimate from the surveys that only half of these outpatient clinics 67 are sites that report to ILINet, and hence we rounded to our two outpatient visits per 68 year estimate. 69 Specific humidity (SH) is measured in units of kg per kg and is defined as the ratio of 70 PLOS 4/43 . CC-BY 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/309021 doi: bioRxiv preprint water vapor mass to total moist air mass. Two other measurements of humidity are 71 absolute humidity and relative humidity. SH is included in DICE as a potential modifier 72 of transmissibility for this time period and uses Phase-2 of the North American Land 73 Data Assimilation System (NLDAS-2) data base provided by NASA [21-23]. The 74 NLDAS-2 data base provides hourly specific humidity (measured 2-meters above the 75 ground) for the continental US at a spatial grid of 0.125 â€¢ which we average to daily and 76 weekly values. The weekly data is then spatially-averaged for the states and CDC 77 regions. 78 School vacation schedules were collected for the 2014-15 and 2015-16 academic years for 79 every state. For each state, a school district was identified to represent each of the three 80 largest cities. Vacation schedules were then collected directly from the district websites. 81 These three school vacation schedules were first processed to a weekly schedule with a 82 value of 0 indicating class was in session all five weekdays and a 1 indicating five 83 vacation days. Next, the representative state schedule was produced by averaging the 84 three weekly district schedules. Region schedules are obtained by a population-weighted 85 average of the state schedules. Similarly, the national schedule is generated by a 86 population-weighted average of the regions. 87 For the 2016-17 season we determine start and end times as well as spring and fall 88 breaks from the previous years schedules. Thanksgiving and winter vacation timing was 89 taken from the calendar where the winter break is assumed to be the last two calendar 90 weeks of the year. Based on the proportion of schools closed and number of days closed, 91 p(t) is assigned a value in the range [0, 1]. For example in week t i , if all schools are 92 closed for the entire week then we define the proportion of open schools p(t i ) = 1. 93 However, if all schools have Monday and Tuesday off (missing 2 of 5 days), then 94 p(t i ) = 0.4. Similarly, if 3 of 10 schools have spring break (entire week off), but the 95 other 7 schools have a full week of class then p(t i ) = 0.3. If all schools have a full week 96 of class then p(t i ) = 0. 