As stated by John Naisbitt in his bestseller "Megatrends" [1] , published in 1982, about the new trends and directions transforming our lives: "We are drowning in information but starved for knowledge. This level of information is clearly impossible to be handled by present means. Uncontrolled and unorganized information is no longer a resource in an information society, instead it becomes the enemy." This successful sentence can be taken as a statement of the problem of information fusion: how can knowledge, awareness and decision making capability be achieved starting from the available information? This chapter is intended as an attempt to technical and mathematical answer to the previous question; in particular it addresses the application of data and information fusion to the design of integrated systems in the Homeland Protection (HP) domain. HP refers to the broad civilian and military effort produced by a Country to protect its territory-including citizens, assets and activities which are vital and fundamental for its growth and prosperity-against internal and external hazards and to reduce its vulnerability to attacks, whatever their origin, as well as natural disasters. HP is therefore a wide and complex domain: systems in this domain are large, to mean that size and scope of such systems are conspicuous and that system boundaries may not be easy to identify; systems are integrated, to mean that it is generally not sufficient to study each subsystem in isolation; systems are different in purpose and require a multidisciplinary approach for their design and analysis. The design and analysis of such systems devoted to operate in such scenarios are necessarily required to provide data and information fusion in the most general sense. Information fusion is about combining, or fusing, information from different sources to provide knowledge that is not evident from individual sources. Numerous real world problems benefit from the combination of heterogeneous information sources, for instance, as depicted in Figure 22 .1, multi-sensor data fusion is naturally performed by animals and humans to access more accurately the surrounding environment and to identify threats or food, thereby improving their chances of survival. The field of information fusion is commonly characterized as multidisciplinary research area and includes and/or overlaps with a number of other areas. The information fusion at sensor level includes signal processing; at data level data processing; at meta-data level it overlaps with knowledge representation and, finally, at the decision level it involves the decision making capability. Data fusion has been defined in [2] as "the process of combining evidence to support intelligence generation." Mainly the methods Academic Press Library in Signal Processing. http://dx. 1245 FIGURE 22.1 Why information fusion. (Kindly provided by Dr. A. Benavoli-IDSIA, Istituto Dalle Molle di Studi sull'Intelligenza Artificiale, Switzerland.) employed to achieve this scope can be divided into two general classes: quantitative and qualitative. The former are based on numerical techniques, the latter ones are based on symbolic representation of information. Examples of quantitative methods can be found in stochastic estimation theory, that aim to estimate the state of a system, using all available information, and to characterize the fusion uncertainty in the framework of probability theory. Most of the algorithms developed for quantitative fusion are based on Bayes filter [3], as Kalman filter [4], information filter [5] and neural networks. The application of these algorithms is employed usually to perform multi-target and multi-sensor tracking. The new generation methods, applying a qualitative approach, are based on a symbolic representation of information. They are, of course, based on mathematical models and their output is numeric, however they can be employed to model qualitative information (e.g., fuzzy). They include expert systems, heuristic, behavioral and structural modeling. Qualitative methods are based on artificial intelligence techniques, such fuzzy logic [6], Dempster-Shafer theory [7, 8] Dezert-Smarandache theory [9,10] and rules based-methods. The first data fusion algorithms employed in real systems in the radar field go back to the early seventies, when they had been developed for multi-radar tracking (MRT) for netted sensors. It was late 1970s, beginning 1980s when these new algorithms and the corresponding means to mitigate unavoidable sources of errors due to practical world (e.g., the time synchronization, the radar alignment to the North, the inaccurate knowledge of coordinates of radar sites) were provided. Probably one of the first MRT system for Air Traffic Control (ATC) ever installed was the system operating in the center and South of Italy [11] . When the competence on tracking was so mature, it was collected in a brand new book on radar data processing [12, 13] , translated also in Russian and Chinese. Later in 1990s further advancements were done in the field of multi-sensor fusion for Airborne Early Warning (AEW) systems, setting up an algorithm suite to track targets on the basis of the data provided by surveillance radar, an Identification Friend or Foe (IFF), an Electronic Support Measurement (ESM) connected to the centralized model. In addition to these problems, there are some disadvantages related to the resource allocation balancing and the vulnerability to communication bottlenecks. In certain cases the traditional data fusion algorithms may still be valid; however, in some cases the great variety of sub-systems and the complexity of interconnections may require new approaches. Most of the drawbacks of centralized and hierarchical architectures can be overcame by decentralized architectures. The trend in surveillance today is towards Network Centric Operation (NCO) [20] . The vision for NCO is to provide seamless access to timely information to all operators (e.g., soldier, officer) and decision-makers at every echelon in the military hierarchy. The goal is to enable all elements, including individual infantry soldiers, ground vehicles, command centers, aircraft and naval vessels, to share the collected information and to combine it into a coherent, accurate picture of the battlefield. The same approach can be followed in the organization of a sensor network. In recent years the decreasing sensor cost and the development of telecommunication technology have made possible the deployment of networks with a huge number of sensors; in this case the use of information fusion centers is unpractical. Consequently a new class of sensor networks, whose way of functioning is called network centric, has emerged. These networks do not have a fusion center and their functioning is based on the information exchange between near-by sensors. Under this approach the information can be considered as a property of the network rather than of the own sensor. This solution is strongly advocated for its robustness and ease of implementation, but it might suffer when the number of sensors grows very much. It has a broad range of potential applications in the field of Homeland Protection: surveillance of habitat and environmental monitoring, structural monitoring (e.g., bridges), contaminants, smart roads, intruder detection, battlefield. It is complementary to the classical surveillance with few large-costly sensors hierarchically organized. The network of numerous sensors and communication nodes (for instance: peer to peer networks) may have link topology varying with time due to natural interferences, electromagnetic propagation masked by the terrain surface, meteorological conditions, dust and smoke which might be present in the environment, allowing therefore modularity, robustness and flexibility. These networks should be designed to be resilient to Electronic Counter Measures (ECM), cyber attacks and should be able to manage increasing and highly variable flow of data. The satisfaction of such demanding requirements, maintaining however the limitation of resources such as energy, bandwidth and node complexity, can be achieved borrowing from biological systems several mechanism. For example bio-inspired sensor networks employ decentralized decisions through the self-synchronization mechanism observed in nature that allows forcing every single node of the network to reach the globally optimal decision, without the need of any fusion center. However there are also drawbacks associated to these architectures: in fully decentralized systems, communication issues are more complex and depend on the topology of the network; generally, communication overheads are higher than in centralized systems. In this chapter these aspects will be investigated in depth for networks respectively of homogeneous and heterogeneous sensors with the description of real study cases applied to real world problems of Homeland Protection. In particular the possibility of netting different sensors operating with different characteristics of domain, coverage, frequency and resolution allows a multi-scale 1 approach. 1 In engineering, mathematics, physics, meteorology and computer science, multi scale modeling is the field of solving physical problems which have important features at multiple scales, particularly multiple spatial and (or) temporal scales. (http://en.wikipedia.org/wiki/Multiscale_modeling). This approach is particularly suitable for the surveillance of wide areas such as national borders or critical strategic regions. The chapter is organized as follows: Section 2.22.2 illustrates the Homeland Protection domain and highlights some of the characteristics of systems in this specific domain; Section 2.22.3 briefly reviews the development of data fusion and gives references to new emerging trends in the domain of high level data fusion. Section 2.22.4 gives a broad and very general description of the basic categories of intelligence that are the source of data and information employed to perform the fusion process. The Sections 2.22.5 and 2.22.6 tackle different aspects related to homogeneous sensor networks. The former proposes several issues from a theoretical point of view, illustrating, next to traditional approaches, the new trends of Collaborative Signal and Information Processing (CSIP), self-organizing and selfsynchronizing sensor network; Section 2.22.5 proposes also some remarks about real applications and the need to rethink some mathematical algorithms to overcome the network centric approach. The latter, Section 2.22.6, proposes three real study cases where the novel approaches give significant results. Likewise Section 2.22.7 tackles the aspects related to heterogeneous sensor networks, dealing with the problems of deployment, behavior assignment and coordination of the different sensors. Also in this case a special attention is focused on the mathematical issues related to these new approaches. Real applications of this kind of sensor networks are described in Sections 2.22.8 and 2.22.9, respectively for the border control problem and the forecasting and estimation of an epidemics. Finally Section 2.22.9, with the concluding remarks, follows. 