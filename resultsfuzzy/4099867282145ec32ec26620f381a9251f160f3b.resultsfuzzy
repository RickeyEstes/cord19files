We performed 10-fold cross validation of the SVM model with several datasets which contain different ratios (1 : 1, 1 : 2, and 1 : 3) of positive to negative PPIs between +ssRNA viruses and human. As shown in Table 1 , the best performance of the SVM model was observed in the balanced dataset with 1 : 1 ratio of positive to negative data. As expected, running the SVM model on unbalanced datasets resulted in lower performances than running it on the balanced dataset with 1 : 1 ratio of positive to negative data. Datasets are available in Additional file 3. We also examined the contribution of the features to the prediction performance of the SVM model. Table 2 shows the results of using different combinations of features in 10fold cross validation of the SVM model with the 1 : 1 dataset of Table 1 . Among the single features, F3, which is the local composition of amino acids, was the best in all performance measures. With F3 alone, the SVM model achieved an accuracy above 92% and an MCC above 0.86, indicating that F3 is a very powerful feature in predicting virus-host PPIs. e best performance of the SVM model was observed when F1 and F3 were used. We also examined this work with different combinations of features. We used double amino acid repeats (DARs) for F1 and F2 instead of single amino acid repeats (SARs), but here for F2, we used a window size of 10 residues not 6 residues because we are working with DAR, so a window size of 10 residues is the biggest available window size that obtain a different value for every double amino acid repeat in it, but a window size of 6 residues does the same thing for the single amino acid repeat. For features F1 and F2, we tried both single amino acid repeats (SARs) and double amino acid repeats (DARs) along with different partitions of a protein sequence. As shown in Table 3 , SAR resulted in a better performance than DAR. For feature F3, we tried several different partitions of a protein sequence in several datasets. Table 4 shows the performance of our SVM model in three different datasets of virus-host PPIs. All the results shown in Table 4 were obtained by using SAR for features F1 and F2, but with different partitions for feature F3. On average, partitioning a protein sequence into 5 segments showed the best performance in all performance measures except sensitivity. In addition to the performance gain, partitioning a protein sequence into 5 segments is more advantageous than 7 or 9 segments with respect to the size of a feature vector that represents the sequence. When we partition a protein sequence into 5 segments, every pair of virus and host proteins is encoded in a feature vector with 280 elements (20 elements for F1, 20 elements for F2, and 20 × 5 � 100 elements for F3 for each of the virus and host proteins). If we partition a protein sequence into 7 or 9 partitions, a feature vector will require 360 elements (20 elements for F1, 20 elements for F2, and 20 × 7 � 140 elements for F3 for each of the virus and host proteins) or 440 elements (20 elements for F1, 20 elements for F2, and 20 × 9 � 180 elements for F3 for each of the virus and host proteins). However, the larger feature vectors did not result in performance improvement in predicting virus-host PPIs. As discussed earlier, we trained the SVM model with the training dataset TR1 consisting of PPIs of human with +ssRNA viruses except hepatitis C virus (HCV) and SARS [20] to assess the independence of the test data from the training data. As shown in Table 5 , target virus proteins in the test datasets showed a very low average sequence similarity in the range (3.12% to 5.20%) to the virus proteins in the training dataset (see Additional file 4 for the similarity of every sequence pair between the training and test datasets). Table 6 shows the results of testing the prediction model on 5 independent datasets of PPIs of new viruses. Despite such a low sequence similarity and species difference, the SVM model showed a high performance in independent testing. In particular, the SVM model showed a higher sensitivity (94.37% and 96.67%) for HCV and SARS virus, which are +ssRNA viruses. It is interesting to note that HPV-16, which is a dsDNA virus, showed the highest specificity of 94.04% and accuracy of 87.93%. Figure 4 shows the ROC curves of independent testing of the SVM model on PPIs of five new viruses. In order to examine the applicability of the SVM model to new hosts, we tested it on PPIs of viruses with new hosts, which were not used in training the model. As described earlier, the model trained with PPIs of human with +ssRNA viruses was tested on PPIs of five new hosts (Mus musculus, Bos taurus, Rattus norvegicus, Sus scrofa, and Escherichia coli K-12) with the viruses. As shown earlier in Table 5 , the average sequence similarity of the human proteins in the training dataset to the new hosts is low, ranging between 8.04% and 9.76%. Despite the low sequence similarity and species difference, testing the model on PPIs of new hosts showed a relatively good performance (Table 7 ). Figure 5 shows the ROC curves of independent testing of the SVM model on PPIs of five new hosts. It is interesting to note that proteins of new hosts have a higher average sequence similarity to those in training datasets than proteins of new viruses, but the SVM model showed a lower performance for new hosts. is can be explained by the number of partner proteins of the target proteins shared by training and test datasets. As shown in Table 8 , the number of common proteins between the test datasets for new viruses (TS1-TS5) and their training dataset TR1 is larger than the number of common proteins between the test datasets for new hosts (TS6-TS10) and their training dataset TR2. us, the SVM model showed a better performance for new viruses than for new hosts. ese results corroborate the known problem with pairinput methods, which was first reported by Park and Marcotte [21] . According to their study [21] , prediction methods that operate on pairs of objects such as PPIs perform much better for test pairs that share components with a training set than for those that do not. us, our prediction model showed a better performance in testing for new viruses which share more partner proteins (i.e., host proteins) with training datasets than in testing for new hosts which share fewer partner proteins (i.e., virus proteins) with training datasets. 


Section:results of cross validation.
Section:results of independent testing on ppis of new viruses.
Section:results of independent testing on ppis of new hosts.