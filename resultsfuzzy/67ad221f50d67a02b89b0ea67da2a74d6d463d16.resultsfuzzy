Spatiotemporal analysis of mononucleotide composition in ebolavirus genomes. Because of the recent major threat to public health in West Africa, more than 1000 genomes of Zaire ebolavirus (EBOV) strains, isolated from humans from 2014 to 2015, have been sequenced, and the sequences are available from the NCBI Virus Variation Database 24 (http://www.ncbi.nlm.nih.gov/genome/viruses/variation/ebola/). To study molecular evolutionary changes in EBOV genomes in the current epidemic, we obtained 1020 strains, for which the isolated dates are given. Although we focused on full-length genomes, a minor portion was relatively short in length, or many unidentified "N" bases were included, partly because of the stringent sterilization treatment obligated by the local government 3 . Because these will give odd values of mono-and oligonucleotide compositions, we focused on 935 genomes longer than 18.5 kb after omitting N bases, which were derived from 244 Guinea, 156 Liberia and 535 Sierra Leone strains. To conduct the present spatiotemporal analysis, 15 strains isolated from several other geographic areas were omitted. We first analyzed time-series change in mononucleotide composition for strains isolated in the three areas separately. Figure 1a plots four mononucleotide compositions (%) in each genome according to the isolated day, which started on March 17, 2014 . Because mutations occur primarily as random processes, mononucleotide compositions for strains isolated even around the same day clearly differed from each other, which resulted in evident compositional diversity. Despite this diversity, which should also be due to sequencing uncertainty, linear regression lines appear to show a time-dependent increasing or decreasing trend, a possible increase for C% and G% and a possible decrease for A% and U%. This is consistent with the excess U-to-C mutations found by two groups 2,3 . 24 . Data and regression lines separately analyzed for different geographic areas are differentially colored: Guinea (blue), Liberia (brown) and Sierra Leone (green). (b) Averaged mononucleotide compositions for strains in each month are plotted according to the elapsed months from March 2014. Data and regression lines for the elapsed months are colored as described in (a). A separate and additional regression analysis for data without the averaging (a) that can examine time-series changes from the epidemic start for all three areas showed that the null hypothesis (i.e. no correlation) was rejected for all mononucleotides in the three areas (12 cases) at the significance level of 0.01, except for T% and G% for Guinea; this was rejected for the T% for Guinea at the significance level of 0.05. For data after averaging (b), the null hypothesis was rejected at the significance level of 0.05 for mononucleotides in the three areas, except for G% and T% in Guinea. Scientific RepoRts | 6:36197 | DOI: 10.1038/srep36197 The present study focused on time-series changes, but not on data variations caused largely by random mutations and sequencing uncertainty, and therefore, average characteristics of strains isolated in a similar period were analyzed, summing up the sequences isolated in one month and calculating an averaged mononucleotide composition for each month (Fig. 1b) . This could be done because the genome sequence data were distributed rather evenly by area and month; the average number of strains per month was 22.2, 41.2 and 17.3 for Guinea (blue), Sierra Leone (green) and Liberia (brown), respectively. We omitted the data for a few months, for which no more than 5 strains were available in the respective area. Figure 1b shows a more conspicuous increasing or decreasing trend than Fig. 1a , and the time-series increasing or decreasing trend revealed by the regression line for the elapsed months was the same among the three areas for all nucleotides, except for an ambiguous case of G% for Guinea. In more detail, positive and negative directions of the regression line were primarily common among the three areas, although the slope angle appear to differ; Table 1 lists Pearson's correlation coefficients calculated separately for the three areas. The highest negative (− 0.94) or positive (0.92) correlation among mononucleotides was observed for A% or C%, respectively, in Liberia, which corresponded to a decrease of 10.2 As or an increase of 11.4 Cs per genome at the final stage of the current outbreak. Notably, the increasing or decreasing trend detected by these averaged data for one month (Fig. 1b) is common to the result without averaging (Fig. 1a) . In these regression analyses, the strains that were isolated in the three areas were independently analyzed. A separate regression analysis that could examine the statistical significance of directional changes from the epidemic start for all three areas, was conducted, by including the data of strains isolated at or near the beginning of the current epidemic (i.e., 2014 March strains in Guinea) in Liberia and Sierra Leone data. The results thus obtained by the latter analysis were consistent with those obtained by the former, and the null hypothesis (i.e. no correlation) was rejected at statistically significant levels in most cases, as described in Figure legend Short oligonucleotide composition in ebolavirus genomes. Next, we analyzed each dinucleotide composition in the genomes grouped for each month. The results presented in Fig. 2a , Table 1 and Supplementary  Fig. 1a show that a common increasing or decreasing trend was observed among the three areas for more than half of the sixteen dinucleotides. Correlation coefficients higher than 0.8 or less than − 0.8 are colored in Table 1 . For nine of the ten colored dinucleotides, the coefficient in the other two areas primarily shows the common directional trend. These high correlation coefficients should reflect the evolutionary dependence of the genome sequences. A decrease in UU and AU and an increase in CC (Fig. 2a) are predictable, even as a cumulative effect of their constituent mononucleotides (Fig. 1b) , but an increase in AC, CU, GU and UG is not predictable as a simple cumulative effect and may indicate the characteristics of the contiguous sequence itself. We thus calculated the ratio of the observed dinucleotide occurrence to that expected from the mononucleotide composition (obs/exp) and found a decrease for UU and GC and an increase for GU, UG, AC and UA, which was common among the three areas ( Fig. 2b and Supplementary Fig. 1a) . The slope direction of the regression line was common among the three areas, but the slope angle appeared to differ among the areas for a wide range of dinucleotides, as well as for tri-and tetranucleotides (data not shown). A spatiotemporal word count can be conducted without specific assumptions or prior knowledge and visualizes viral evolutionary changes in an easily understandable way. Two distinct models can explain the common increasing or decreasing trend among the three areas, which was observed for a wide range of mono-and oligonucleotides. [Model 1] Throughout the current EBOV epidemic, virus movement between the three areas was extensive; therefore, the time-dependent trend of directional changes in oligonucleotide composition was common among the areas. [Model 2] Even without the extensive mixing of viruses, common directional changes can occur. For example, viruses inevitably depend on many host factors for their growth, but human cells may not provide an ideal growth environment for invading viruses; therefore, common directional changes occur after invasions from nonhumans for supporting more efficient growth in human cells. In this connection, Park et al. 3 reported there was no clear evidence for import or export of EBOV across national borders after its initial introduction. Furthermore, although an increasing or decreasing trend for a wide range of mono-and oligonucleotides is common among the three areas, their actual composition (%) and the slope angle of the directional change often differ among the areas. This observation is consistent with Model 2 and the report by Park et al. 3 but not with Model 1, as discussed below from various aspects. When considering the cellular environment differences between natural hosts (bats) and humans, not only the low-molecular substances (e.g., nucleotide pool) but also the macromolecules (e.g., proteins) involved in viral growth must be considered. Additionally, antiviral mechanisms 7-10 should differ between humans and natural hosts. Host macromolecules involved in viral growth (either supporting or inhibiting) should primarily recognize oligonucleotides, such as several nucleotides or longer, rather than mononucleotides. Hence, we analyzed time-series changes in pentanucleotide (5-mer) occurrences. We first calculated correlation coefficients for all 1024 (= 4 5 ) 5-mers and sorted them by the averaged correlation coefficients for the three areas. Figure 3a and Supplementary Fig. 1b show time-series patterns of 5-mers with evidently high or low correlation coefficients; 384 or 50 (of 1024 types) 5-mers showed a common decreasing or increasing trend among the areas, respectively. Examination of the ratio of the observed occurrences to those expected from the mononucleotide composition (obs/exp) showed that directional changes of many 5-mers cannot be explained by a cumulative effect of mononucleotide changes (data not shown), as found for various dinucleotides. When further examining the 5-mers showing the common directional change in more detail, their actual occurrence level and slope of Supplementary Fig. 1b) , and the difference often became clearer compared to that for mono-and dinucleotides. This cannot be explained by the aforementioned Model 1. If the time-series directional change in mono-and oligonucleotide composition found for EBOV is actually due to the necessity of supporting efficient growth in human cells (Model 2), such directional changes should be observed for other zoonotic RNA viruses. Directional change in MERS virus genomes. We next analyzed MERS coronaviruses isolated in the recent epidemic starting in April 2012 in the Middle East 25, 26 . The EBOV outbreak analyzed above was initiated by a single virus strain being introduced from a nonhuman animal; this virus was then transmitted among humans during the outbreak. In contrast, MERS viruses were repeatedly transmitted from nonhumans, mainly camels, in this epidemic 25 , although its original natural host is thought to be bats 26 . Because direct nonhuman hosts for different human isolates differ among isolates, information on camel-derived strains in the current epidemic is important. From the NCBI Virus Variation Database 24 , we found 91 and 16 strains from humans and camels, respectively, with known isolated dates. The total number of MERS virus genomes is approximately one tenth of EBOV genomes, but their sequence length, even after omitting N bases, is mostly similar to its genome size (ca. 30 kb); only one sequence that was evidently short (29.3 kb) was omitted from this analysis. We grouped sequences in each month and analyzed the averaged mono-and oligonucleotides (from 2 to 5-mers) for each month and host. Clear time-dependent increasing or decreasing trends were observed for a wide range of mono-and dinucleotides (Fig. 4a,b) , but the increasing or decreasing trend found for actual mono-and oligonucleotides clearly differed from EBOV; e.g., C% and G% decrease and U% increases in MERS viruses. EBOV is a negative-sense single-stranded RNA virus, and the sequences registered in the database and analyzed here were complementary to viral genome sequences, but MERS virus is a positive-sense single-stranded RNA virus and, therefore, genome sequences were analyzed. This difference, however, cannot explain differences in directional changes in monoand oligonucleotide composition of EBOV and MERS viruses. Figure 3b presents four 5-mers with a high increasing or decreasing trend; e.g., during this 38-month epidemic, approximately six UUUUUs or four CCACUs have been gained or lost per genome, respectively. The time-dependent gain of U 5 (Fig. 3b) clearly differs from its loss for EBOV (Fig. 3a) . Although the regression lines (blue lines in Figs 3b and 4) were calculated only for human strains, occurrence data for camel strains (brown) were primarily positioned around the regression line, thus fitting the previous report that MERS viruses were repeatedly transmitted between camels and humans in the present epidemic 25 . Because time-series directional changes in mono-and oligonucleotide compositions were observed for both EBOV and MERS viruses, the directional change should occur for other zoonotic RNA viruses. Mononucleotide composition in influenza virus genomes. We next analyzed influenza viruses, for which a large number of sequences are available from the Influenza Research Database 27 for different human A subtypes, epidemics of which have started independently at long intervals, such as several decades. Importantly, the aforementioned Model 2, in which the common directional change between different viral populations is expected without extensive virus mixing, is testable more rigorously than for the EBOV outbreak, which started from a single invasion in Guinea and expanded to other countries. Furthermore, we may examine the following important issue. If a common directional change is observed, what types of changes likely reoccur in future epidemics caused by invasions from natural reservoir hosts? In addition to human A subtypes, genome sequences of human B type, which can currently infect humans but not birds, and of various avian A subtypes were available. The genomes of influenza A and B are composed of eight segments, and we first selected ca. 25,000 strains with a full set of eight sequences, categorized the full genome sequences according to host and serological type, and grouped them in each year. The sequence length cut-off was not included because the genome is composed of eight segments of various lengths and a simple, satisfactory criterion for length cut-off could not be set. Alternatively, because 20 times more sequences are available than for EBOV, we selected years with at least ten strains of one category to reduce the artefactual effects derived from sequencing uncertainty. Then, to analyze time-series changes, we selected human or avian A subtypes with more than five years fulfilling the above threshold (≥ten strains per year); the human B type also fitted these criteria. In the case of H1N1/09 [16] [17] [18] (starting from 2009 and abbreviated pH1N1 in the database), a sufficient number of sequences fulfilling the above threshold was available even per month and, therefore, pH1N1 sequences in each month were analyzed; importantly, this allowed the study of changes occurring within one outbreak in detail. Collectively, we focused on thirteen subtypes (three human and nine avian A subtypes and a human B type), and first analyzed time-series changes in mononucleotide compositions. Three human subtypes of influenza A virus (human H1N1, H3N2 and pH1N1) changed their A%, C% and G% with common increasing or decreasing trends among the three subtypes (Fig. 5a) , despite different epidemics having started by independent invasions from nonhumans; the G+ C% increase in human A subtypes was previously reported by Rabadan et al. 10 . Figure 5a shows that the A%, C% and G% move time-dependently apart from those of avian A subtypes (sky blue) and toward those of the human B type (violet). Because the B type can currently infect humans, but not birds, this type has possibly adapted better to growth in human cells than A subtypes. The directional change of human A subtypes "apart from avian A subtypes and toward the human B type" may visualize their evolutionary journey from each start of human-to-human transmission. In the case of U%, human H1N1 (blue) and H3N2 (brown) have already reached the B's level, and only pH1N1 (green) shows an increasing trend toward B. 


Section:results and discussion