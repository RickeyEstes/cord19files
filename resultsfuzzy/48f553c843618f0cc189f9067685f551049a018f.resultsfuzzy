We analysed simulated outbreaks to assess the performance of our method under a variety of conditions, including different basic reproduction numbers (R 0 ), sampling coverage, rates of evolution, and generation time distributions, with our base scenario resembling an influenza-like illness ( Table 1 ). The outbreak size varied from 10 to nearly 200 infections in a fixed population of 200 susceptible hosts (plus imported cases), with a median sample size of 110 (quartile range: [66-132], Fig. S1 ). Wherever applicable, reported results refer to the marginal distributions. Transmission trees were overall very well reconstructed, with 70% to 90% of true ancestries being recovered in most simulation settings ( Fig. 1 and Table S1 in Text S1). Better results were achieved when the sampling coverage was high (compare settings 'Base' to 75%, 50% and 25% of missing cases). In the absence of genetic information, the transmission tree was very difficult to infer (setting 'No mutation'). Differences in basic reproduction numbers (settings 'Low R' and 'High R') and in the shape of the generation time distribution (settings 'Short generation' and 'Long generation') induced some variation in the proportions of successfully recovered ancestries, although these remained satisfying in every case ( Fig. 1 and Table S1 in Text S1). Dates of infections were inferred with accuracy in most settings ( Fig. S2 and Table S1 in Text S1). However, this result was mostly driven by the shape of the generation time distribution, with broader distributions leading to greater uncertainty in the dates of infection (Fig. S2 ). While perfectly inferred in fully sampled outbreaks, the number of generations between ancestor and descendents became ambiguous as the proportion of missing cases increases (Table S1 in Text S1). Mutation rates were also mostly well estimated (Table S1 in Text S1, Fig. S3 ), albeit with a tendency to over-estimation. This bias was stronger when sampling grew sparser (settings with 75% and 50% missing cases), and to a lesser extent when the number of imported cases grew large (setting 'Many imports'). Detailed investigation of individual simulations suggested that misdetection of imported cases and increased numbers of erroneous ancestries may be responsible for over-estimating the mutation rates in these settings. The inference of sampling coverage varied largely amongst different simulation settings (Table S1 in Text S1, Fig.  S4 ): well recovered in fully sampled outbreaks, it was largely overestimated in sparse samples (settings with 75%, 50% and 25% missing cases), and slightly underestimated with longer generation time. The detection of imported cases showed excellent specificity and good sensitivity pooling results across the simulated datasets examined, with a majority of simulations exhibiting perfect results (Fig. 2) . However, substantial variations were observed between simulation settings (Fig. S5 , Table S1 in Text S1). Unsurprisingly, detection of imported cases was more difficult when imported cases were more frequent and when a higher fraction of cases was unobserved. With longer generation times, the larger numbers of mutations accumulated between ancestors and descendents made the detection of genetic outliers, and thus of imported cases, nearly impossible (Fig. S2 ). 


Section:general results on simulated data