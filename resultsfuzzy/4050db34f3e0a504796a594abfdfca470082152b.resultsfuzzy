As mentioned before, our experiments are based on the automatic online news classification component. We tested the classification performance of different feature subsets on different machine learning algorithms as summarized in Table 6 . The four classification algorithms we used, including KNN (k = 10), LBN, NB, and SVM are from the Weka Data Mining Package [147] . For each classifier, we used 90% of the news articles in the testbed for training, and predicted the class labels of the remaining 10% news articles as testing. We repeated this process one hundred times by randomly splitting the testbed for statistical analysis. For each feature subset with each classification algorithm, we report in Table 6 the accuracy, the average precision, the average recall, and the average F-measure values on the three FMD news categories. The values in bold fonts denote the best performances. In our experiments, the classifier using SVM upon feature subset FeatureSFS-Comb achieved the best performance. It achieved the highest accuracy of 77.04%, the highest average precision of 77.10%, the highest average recall of 77.05%, and the highest average F-measure of 77.08%. We can also see from Table 6 that in most cases, the two combination feature subsets worked better than the two Bag of Words feature subsets. Specifically, in most cases, FeatureBFS-Comb had higher evaluation values than FeatureBFS-BW, and FeatureSFS-Comb had higher evaluation values than FeatureSFS-BW. By conducting feature selection, the average accuracy of Bag of Words features increased from 70.66% to 73.27%, and the average accuracy of the combination features increased from 72.13% to 74.96%. The errors in classification were mainly caused by such news that has information related to more than one category. For example, some news articles mentioned both FMD outbreaks which belong to category 1, and plans on how to control the outbreaks which belong to category 2. Some other news articles first talked different control programs on FMD which belong to category 2, and then compared them in terms of their social and economic influences which belong to category 3. In this case, to decide which category a news article belongs to, the domain experts from the FMD Lab at UC-Davis read the content to see which topic the large portion of the article is about. However, for automatic classifiers, the results sometimes were inconsistent with the golden standard provided by domain experts. Furthermore, in order to test our hypotheses, we conducted pair wise single-sided t tests on accuracy and average F-measure. The p values and results for the tests of our hypotheses are presented in Table 7 , where p values with ⁎ and ⁎⁎ indicate significant differences at the levels of α = 0.05 and 0.01, respectively. The underlined p values indicate that the results contradict the hypotheses. Overall, most of our hypotheses were supported by our experiments. For Hypothesis 1a, FeatureBFS-Comb significantly outperformed FeatureBFS-BW on accuracy for each of the four classification algorithms. Although Hypothesis 1a on the average F-measure was not confirmed for KNN (p = 0.0550 N 0.05), it was confirmed for the other three algorithms with p values less than or equal to 0.001. For Hypothesis 1b, FeatureSFS-Comb significantly outperformed Fea-tureSFS-BW with most p values less than or equal to 0.001, except for the accuracy of KNN (p = 0.1260 N 0.05). Overall, the combination features achieved better performance than Bag of Words features, because the combination features capture not only the common words but also some important noun phrases and named entities. For Hypothesis 2a, FeatureSFS-BW significantly outperformed FeatureBFS-BW with most p values less than 0.0001, except for the average F-measure of SVM (p = 0.4968 N 0.05). For Hypothesis 2b, six out of the eight p values were less than 0.0001, although it was not confirmed on the average F-measure for SVM (p = 0.1499 N 0.05). Overall, the feature subsets conducted feature selection outperformed the baseline feature subsets. For Hypothesis 3, all six sub hypotheses were confirmed for accuracy, and four of them were confirmed on the average F-measure. Overall, SVM was the best performer with selected feature subsets. The feature subsets FeatureBFS-BW, FeatureBFS-Comb, FeatureSFS-BW, and FeatureSFS-Comb contain 1473 features, 2130 features, 48 features and 56 features respectively. As shown above, FeatureSFS-Comb performed best in FMD news classification. The feature subset size was reduced significantly by using CFS + Best First Search described before. With fewer features, the performance speed of FMD news classification increased dramatically. 


Section:experiment results