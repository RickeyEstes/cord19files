The primary assay results obtained from the transcriptomic and proteomic experiments were processed to identify specific RNAs or peptides that were differentially expressed under a particular set of conditions (e.g. virus amount, time post infection, virus strain, etc.) in comparison with relevant control samples to derive so called 'Host Factor Biosets'. Another measure of technical validity of the combined laboratory and analytical workflow is that the Host Factor Biosets derived from similar experiment samples treated in a similar way should have similar membership, thereby indicating experimental reproducibility. To examine experimental reproducibility, we determined the overlap that was observed between all experiments that used the same virus strains in the same infection system. In the evaluation reported here, we used datasets reporting results from wild-type A/California/04/2009 (H1N1), A/Viet Nam/1203/04 (H5N1), and SARS-CoV as being representatives of all experiments. In order to avoid complications related to slight differences in infection kinetics, we took the union of all biosets across the entire time course from each experiment (i.e. the non-redundant set of differentially expressed genes) for comparison. This approach can lead to a discrepancy between the total number of genes in each experiment due to differences in number of time points sampled. As an alternative strategy, the data could also be more strictly paired using specific time points and dosages. Seven situations in which the same treatment conditions (viral strain and viral amount) were reproduced in separate experiments were identified. Since the magnitude of the responses and the number of time points differ between experiments, we calculated the percentage overlap of the number of host factors using the smallest set as the denominator for the sake of comparison. The smallest set was chosen as the denominator to calculate percentage overlap, which may not be an ideal comparison since this would tend to result in higher reproducibility values than if the largest set was used as the denominator. However, since we are primarily interested in measuring the commonality between similar experiments that have slight variations in study designs and are inherently noisy, we chose to focus on determining if the smaller set is largely a subset of the larger sets, which would demonstrate that the these significant hits are reproducible even in the presence of confounding variables such as biological and technical variation. For transcriptomic experiments the following overlap was observed: 83% for A/California/04/2009 in Calu-3 (Fig. 2a) , 91% for A/Viet Nam/1203/2004 in Calu-3 (Fig. 2b, 3-way comparison) , 62% for A/California/04/2009 in C57BL/6 ( Fig. 2c) , 77% for A/Viet Nam/1203/2004 in C57BL/6 ( Fig. 2d) , 72% for A/California/04/2009 in HAE cells (Fig. 2e) , and 40% for SARS-CoV in HAE cells (Fig. 2f) . For the one replicated proteomic experiment, in which A/Viet Nam/1203/2004 was used to infect Calu-3, 43% overlap was observed (Fig. 2g) . The reproducibility of host responses to both pandemic and highly pathogenic avian influenza viruses was high in both the Calu-3 cell line and mouse infection systems. Reproducibility using HAE was somewhat lower both in terms of the absolute number of host factor responding (Fig. 2e ) and the percentage overlap (only 39% in Fig. 2f) , perhaps due to the variability in establishing similar cell culture conditions using primary epithelial cells. Reproducibility of proteomic results was also somewhat lower with an overlap of 43% following infection of Calu-3 with A/Viet Nam/1203/2004 (Fig. 2g) . In general, the reproducibility of this collection of experiments using well-controlled standard operating procedures was quite high. In other microarray studies it has been shown that technical variability can result in 10% difference between replicate RNA samples 46, 47 , while biological variability can cause anywhere from 10% to 30% differences depending on the biological system sampled 48 . In addition, variability in stimulation conditions has been found to have an even more profound impact than either technical or biological variability 47 Overall, the results from the independent in vitro and in vivo validation experiments and the high degree of reproducibility of the derived host factor lists show that the datasets described here are of high quality and can be useful for in-depth investigation and hypothesis generation in follow-up analyses. 


Section:reproducibility of derived results